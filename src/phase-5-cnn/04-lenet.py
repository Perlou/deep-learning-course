"""
04-lenet.py - LeNet ç½‘ç»œå®ç°

æœ¬èŠ‚å­¦ä¹ å†…å®¹ï¼š
1. LeNet çš„å†å²æ„ä¹‰
2. LeNet-5 æ¶æ„è¯¦è§£
3. PyTorch å®ç° LeNet
4. åœ¨ MNIST ä¸Šè®­ç»ƒå’Œæµ‹è¯•
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt

print("=" * 60)
print("ç¬¬4èŠ‚: LeNet æ¶æ„")
print("=" * 60)

# ============================================================
# 1. LeNet å†å²èƒŒæ™¯
# ============================================================
print("\nğŸ“Œ 1. LeNet å†å²æ„ä¹‰")
print("-" * 40)

print("""
LeNet-5 (1998, Yann LeCun)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ† ç¬¬ä¸€ä¸ªæˆåŠŸçš„å·ç§¯ç¥ç»ç½‘ç»œ
ğŸ“‹ ç”¨äºæ‰‹å†™æ•°å­—è¯†åˆ«ï¼ˆé‚®æ”¿ç¼–ç è¯†åˆ«ï¼‰
ğŸ¯ å¥ å®šäº†ç°ä»£ CNN çš„åŸºç¡€

å…³é”®åˆ›æ–°:
1. å·ç§¯å±‚æå–å±€éƒ¨ç‰¹å¾
2. æ± åŒ–å±‚é™ç»´
3. ç«¯åˆ°ç«¯è®­ç»ƒ

æ¶æ„å›¾:
  è¾“å…¥      C1        S2       C3        S4       C5      F6     Output
 32Ã—32   28Ã—28Ã—6   14Ã—14Ã—6  10Ã—10Ã—16   5Ã—5Ã—16  1Ã—1Ã—120   84      10
   â”‚        â”‚         â”‚        â”‚         â”‚        â”‚       â”‚       â”‚
   â””â”€â”€Convâ”€â”€â”´â”€â”€Poolâ”€â”€â”€â”´â”€â”€Convâ”€â”€â”´â”€â”€Poolâ”€â”€â”€â”´â”€â”€Convâ”€â”€â”´â”€â”€FCâ”€â”€â”€â”´â”€â”€FCâ”€â”€â”€â”˜
      5Ã—5     2Ã—2       5Ã—5      2Ã—2       5Ã—5
""")

# ============================================================
# 2. LeNet-5 æ¶æ„å®ç°
# ============================================================
print("\nğŸ“Œ 2. LeNet-5 PyTorch å®ç°")
print("-" * 40)

class LeNet5(nn.Module):
    """
    ç»å…¸ LeNet-5 å®ç°
    è¾“å…¥: 1Ã—32Ã—32 æˆ– 1Ã—28Ã—28 (MNIST)
    è¾“å‡º: 10 ç±»
    """
    def __init__(self, num_classes=10):
        super(LeNet5, self).__init__()
        
        # å·ç§¯å±‚
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)  # ä¿æŒ32Ã—32
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)
        self.conv3 = nn.Conv2d(16, 120, kernel_size=5, stride=1)
        
        # å…¨è¿æ¥å±‚
        self.fc1 = nn.Linear(120, 84)
        self.fc2 = nn.Linear(84, num_classes)
        
        # æ± åŒ–å±‚
        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)
    
    def forward(self, x):
        # C1: å·ç§¯å±‚ + æ¿€æ´» + æ± åŒ–
        # è¾“å…¥: 1Ã—32Ã—32 â†’ è¾“å‡º: 6Ã—14Ã—14
        x = self.pool(torch.tanh(self.conv1(x)))
        
        # C3: å·ç§¯å±‚ + æ¿€æ´» + æ± åŒ–
        # è¾“å…¥: 6Ã—14Ã—14 â†’ è¾“å‡º: 16Ã—5Ã—5
        x = self.pool(torch.tanh(self.conv2(x)))
        
        # C5: å·ç§¯å±‚ + æ¿€æ´»
        # è¾“å…¥: 16Ã—5Ã—5 â†’ è¾“å‡º: 120Ã—1Ã—1
        x = torch.tanh(self.conv3(x))
        
        # å±•å¹³
        x = x.view(x.size(0), -1)
        
        # F6: å…¨è¿æ¥å±‚
        x = torch.tanh(self.fc1(x))
        
        # è¾“å‡ºå±‚
        x = self.fc2(x)
        
        return x

# æ‰“å°æ¨¡å‹ç»“æ„
model = LeNet5()
print(model)

# æµ‹è¯•å‰å‘ä¼ æ’­
dummy_input = torch.randn(1, 1, 32, 32)
output = model(dummy_input)
print(f"\nè¾“å…¥å½¢çŠ¶: {dummy_input.shape}")
print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")

# è®¡ç®—å‚æ•°é‡
total_params = sum(p.numel() for p in model.parameters())
print(f"æ€»å‚æ•°é‡: {total_params:,}")

# ============================================================
# 3. ç°ä»£åŒ–çš„ LeNet (ä½¿ç”¨ ReLU å’Œ MaxPool)
# ============================================================
print("\nğŸ“Œ 3. ç°ä»£åŒ– LeNet")
print("-" * 40)

class LeNetModern(nn.Module):
    """
    ç°ä»£åŒ–çš„ LeNet å®ç°
    - ä½¿ç”¨ ReLU æ›¿ä»£ Tanh
    - ä½¿ç”¨ MaxPool æ›¿ä»£ AvgPool
    - æ·»åŠ  Dropout
    """
    def __init__(self, num_classes=10):
        super(LeNetModern, self).__init__()
        
        self.features = nn.Sequential(
            # ç¬¬ä¸€ä¸ªå·ç§¯å—
            nn.Conv2d(1, 6, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # ç¬¬äºŒä¸ªå·ç§¯å—
            nn.Conv2d(6, 16, kernel_size=5),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(16 * 5 * 5, 120),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(120, 84),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(84, num_classes),
        )
    
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

model_modern = LeNetModern()
print("ç°ä»£åŒ– LeNet ç»“æ„:")
print(model_modern)

# ============================================================
# 4. åœ¨ MNIST ä¸Šè®­ç»ƒ
# ============================================================
print("\nğŸ“Œ 4. MNIST æ•°æ®é›†å‡†å¤‡")
print("-" * 40)

# æ•°æ®é¢„å¤„ç†
transform = transforms.Compose([
    transforms.Resize((32, 32)),  # LeNet éœ€è¦ 32Ã—32 è¾“å…¥
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

# æ£€æŸ¥æ˜¯å¦å¯ä»¥åŠ è½½æ•°æ®é›†
try:
    # åŠ è½½ MNIST æ•°æ®é›†
    train_dataset = datasets.MNIST(
        root='./data', train=True, download=True, transform=transform
    )
    test_dataset = datasets.MNIST(
        root='./data', train=False, download=True, transform=transform
    )
    
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)
    
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"æµ‹è¯•é›†å¤§å°: {len(test_dataset)}")
    
    # æŸ¥çœ‹ä¸€äº›æ ·æœ¬
    sample_images, sample_labels = next(iter(train_loader))
    print(f"æ‰¹æ¬¡å½¢çŠ¶: {sample_images.shape}")
    print(f"æ ‡ç­¾ç¤ºä¾‹: {sample_labels[:10]}")
    
    DATA_LOADED = True
except Exception as e:
    print(f"æ•°æ®åŠ è½½å¤±è´¥ (è¿™åœ¨é¦–æ¬¡è¿è¡Œæ—¶æ˜¯æ­£å¸¸çš„): {e}")
    print("è¯·ç¡®ä¿ç½‘ç»œè¿æ¥ï¼Œæˆ–æ‰‹åŠ¨ä¸‹è½½ MNIST æ•°æ®é›†")
    DATA_LOADED = False

# ============================================================
# 5. è®­ç»ƒå‡½æ•°
# ============================================================
print("\nğŸ“Œ 5. è®­ç»ƒä¸è¯„ä¼°å‡½æ•°")
print("-" * 40)

def train_one_epoch(model, train_loader, optimizer, criterion, device):
    """è®­ç»ƒä¸€ä¸ª epoch"""
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        pred = output.argmax(dim=1, keepdim=True)
        correct += pred.eq(target.view_as(pred)).sum().item()
        total += target.size(0)
    
    return total_loss / len(train_loader), 100. * correct / total


def evaluate(model, test_loader, criterion, device):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            total_loss += criterion(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
            total += target.size(0)
    
    return total_loss / len(test_loader), 100. * correct / total

# ============================================================
# 6. è¿è¡Œè®­ç»ƒ
# ============================================================
print("\nğŸ“Œ 6. è®­ç»ƒ LeNet (ç®€çŸ­æ¼”ç¤º)")
print("-" * 40)

if DATA_LOADED:
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model = LeNetModern().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    # è®­ç»ƒ 2 ä¸ª epoch ä½œä¸ºæ¼”ç¤º
    num_epochs = 2
    for epoch in range(num_epochs):
        train_loss, train_acc = train_one_epoch(
            model, train_loader, optimizer, criterion, device
        )
        test_loss, test_acc = evaluate(model, test_loader, criterion, device)
        
        print(f"Epoch {epoch+1}/{num_epochs}")
        print(f"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
        print(f"  Test Loss:  {test_loss:.4f}, Test Acc:  {test_acc:.2f}%")
else:
    print("è·³è¿‡è®­ç»ƒæ¼”ç¤º (æ•°æ®æœªåŠ è½½)")

# ============================================================
# 7. å±‚æ¬¡ç‰¹å¾å¯è§†åŒ–
# ============================================================
print("\nğŸ“Œ 7. ç†è§£ LeNet çš„ç‰¹å¾æå–")
print("-" * 40)

print("""
LeNet çš„å±‚çº§ç‰¹å¾æå–è¿‡ç¨‹:

Layer 1 (Conv1 + Pool1):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è¾“å…¥: 32Ã—32 ç°åº¦å›¾                      â”‚
â”‚  è¾“å‡º: 6ä¸ª 14Ã—14 ç‰¹å¾å›¾                  â”‚
â”‚  å­¦ä¹ : è¾¹ç¼˜ã€ç®€å•çº¹ç†                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
Layer 2 (Conv2 + Pool2):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è¾“å…¥: 6Ã—14Ã—14                          â”‚
â”‚  è¾“å‡º: 16ä¸ª 5Ã—5 ç‰¹å¾å›¾                   â”‚
â”‚  å­¦ä¹ : ç¬”ç”»ç»„åˆã€å±€éƒ¨å½¢çŠ¶                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
Layer 3 (Conv3):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è¾“å…¥: 16Ã—5Ã—5                           â”‚
â”‚  è¾“å‡º: 120ä¸ª 1Ã—1 ç‰¹å¾                    â”‚
â”‚  å­¦ä¹ : æ•°å­—çš„æ•´ä½“ç‰¹å¾                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
Classifier (FC):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  120 â†’ 84 â†’ 10                          â”‚
â”‚  åˆ†ç±»å†³ç­–                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# ============================================================
# 8. LeNet vs ç°ä»£ CNN
# ============================================================
print("\nğŸ“Œ 8. LeNet vs ç°ä»£ CNN å¯¹æ¯”")
print("-" * 40)

print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ç‰¹æ€§      â”‚    LeNet-5      â”‚    ç°ä»£ CNN     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   æ¿€æ´»å‡½æ•°    â”‚    Tanh         â”‚    ReLU         â”‚
â”‚   æ± åŒ–æ–¹å¼    â”‚    AvgPool      â”‚    MaxPool      â”‚
â”‚   æ­£åˆ™åŒ–      â”‚    æ—            â”‚    Dropout/BN   â”‚
â”‚   ç½‘ç»œæ·±åº¦    â”‚    5å±‚          â”‚    æ•°ååˆ°æ•°ç™¾å±‚ â”‚
â”‚   å‚æ•°é‡      â”‚    çº¦6ä¸‡        â”‚    æ•°ç™¾ä¸‡åˆ°äº¿çº§ â”‚
â”‚   è¾“å…¥å°ºå¯¸    â”‚    32Ã—32        â”‚    224Ã—224+     â”‚
â”‚   ä»»åŠ¡        â”‚    æ‰‹å†™æ•°å­—     â”‚    å¤æ‚åœºæ™¯     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LeNet çš„å†å²è´¡çŒ®:
âœ… è¯æ˜äº† CNN çš„æœ‰æ•ˆæ€§
âœ… å»ºç«‹äº† Conv-Pool-FC çš„ç»å…¸æ¶æ„
âœ… å¯å‘äº†åç»­æ‰€æœ‰ CNN çš„è®¾è®¡
""")

# ============================================================
# ç»ƒä¹ é¢˜
# ============================================================
print("\n" + "=" * 60)
print("ğŸ’¡ ç»ƒä¹ é¢˜")
print("=" * 60)

print("""
1. ä¿®æ”¹ LeNet ä½¿å…¶æ¥å— CIFAR-10 çš„ 3Ã—32Ã—32 RGB å›¾åƒ

2. å°è¯•å¢åŠ å·ç§¯å±‚çš„é€šé“æ•°ï¼ˆå¦‚ 6â†’32, 16â†’64ï¼‰,
   è§‚å¯Ÿå‡†ç¡®ç‡å’Œå‚æ•°é‡çš„å˜åŒ–

3. åœ¨ LeNet ä¸­æ·»åŠ  BatchNorm å±‚ï¼Œè§‚å¯Ÿè®­ç»ƒæ•ˆæœ

4. å°†æ± åŒ–å±‚ä» AvgPool æ”¹ä¸º MaxPoolï¼Œæ¯”è¾ƒç»“æœ
""")

# ============================================================
# æ€»ç»“
# ============================================================
print("\n" + "=" * 60)
print("ğŸ“ æœ¬èŠ‚è¦ç‚¹æ€»ç»“")
print("=" * 60)

print("""
1. LeNet-5 æ˜¯ç¬¬ä¸€ä¸ªæˆåŠŸçš„ CNNï¼Œç”¨äºæ‰‹å†™æ•°å­—è¯†åˆ«

2. æ¶æ„: Conv â†’ Pool â†’ Conv â†’ Pool â†’ Conv â†’ FC â†’ FC

3. åŸå§‹ç‰ˆæœ¬ä½¿ç”¨ Tanh å’Œ AvgPool

4. ç°ä»£æ”¹è¿›:
   - ReLU æ›¿ä»£ Tanh
   - MaxPool æ›¿ä»£ AvgPool
   - æ·»åŠ  Dropout å’Œ BatchNorm

5. LeNet å‚æ•°é‡çº¦ 6 ä¸‡ï¼Œåœ¨ MNIST ä¸Šå¯è¾¾ 99%+ å‡†ç¡®ç‡

ä¸‹ä¸€èŠ‚: AlexNet æ¶æ„
""")
