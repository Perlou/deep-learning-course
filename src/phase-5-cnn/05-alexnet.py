"""
05-alexnet.py - AlexNet æ¶æ„è¯¦è§£

æœ¬èŠ‚å­¦ä¹ å†…å®¹ï¼š
1. AlexNet çš„å†å²æ„ä¹‰ï¼ˆ2012 ImageNet çªç ´ï¼‰
2. AlexNet æ¶æ„è¯¦è§£
3. AlexNet çš„å…³é”®åˆ›æ–°
4. PyTorch å®ç°
"""

import torch
import torch.nn as nn

print("=" * 60)
print("ç¬¬5èŠ‚: AlexNet æ¶æ„")
print("=" * 60)

# ============================================================
# 1. AlexNet å†å²æ„ä¹‰
# ============================================================
print("\nğŸ“Œ 1. AlexNet çš„å†å²æ„ä¹‰")
print("-" * 40)

print("""
AlexNet (2012, Krizhevsky, Sutskever, Hinton)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ† ImageNet ILSVRC 2012 å† å†›
ğŸ“Š Top-5 é”™è¯¯ç‡: 15.3% (ç¬¬äºŒå 26.2%)
ğŸ’¥ å¼€å¯æ·±åº¦å­¦ä¹ é©å‘½!

å…³é”®æ•°æ®:
- 8 å±‚ç½‘ç»œ (5 å·ç§¯ + 3 å…¨è¿æ¥)
- 6000 ä¸‡å‚æ•°
- ä½¿ç”¨ 2 ä¸ª GTX 580 GPU è®­ç»ƒ
- è®­ç»ƒæ—¶é—´: 5-6 å¤©

ä¸ºä»€ä¹ˆ AlexNet å¦‚æ­¤é‡è¦:
1. é¦–æ¬¡è¯æ˜æ·±åº¦ CNN åœ¨å¤§è§„æ¨¡å›¾åƒè¯†åˆ«ä¸­çš„ä¼˜åŠ¿
2. æ¨åŠ¨äº† GPU è®¡ç®—çš„å‘å±•
3. å¼€å¯äº†æ·±åº¦å­¦ä¹ å•†ä¸šåŒ–æµªæ½®
""")

# ============================================================
# 2. AlexNet æ¶æ„è¯¦è§£
# ============================================================
print("\nğŸ“Œ 2. AlexNet æ¶æ„å›¾è§£")
print("-" * 40)

print("""
AlexNet å®Œæ•´æ¶æ„ (è¾“å…¥: 227Ã—227Ã—3):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                            â”‚
â”‚  è¾“å…¥    Conv1    Pool1   Conv2    Pool2   Conv3  Conv4  Conv5â”‚
â”‚ 227Ã—227  55Ã—55    27Ã—27   27Ã—27    13Ã—13   13Ã—13  13Ã—13  13Ã—13â”‚
â”‚    Ã—3     Ã—96      Ã—96    Ã—256     Ã—256    Ã—384   Ã—384   Ã—256 â”‚
â”‚                                                            â”‚
â”‚    â”‚       â”‚        â”‚       â”‚        â”‚       â”‚      â”‚      â”‚  â”‚
â”‚    â””â”€11Ã—11â”€â”´â”€3Ã—3â”€pâ”€â”´â”€5Ã—5â”€â”€â”€â”´â”€3Ã—3â”€pâ”€â”€â”´â”€3Ã—3â”€â”€â”€â”´â”€3Ã—3â”€â”€â”´â”€3Ã—3â”€â”€â”˜  â”‚
â”‚      s=4     s=2      s=1     s=2      s=1     s=1    s=1    â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
                     Pool5 (3Ã—3)
                       6Ã—6Ã—256
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FC1         FC2         FC3                    â”‚
â”‚             9216 â†’ 4096 â†’ 4096 â†’ 1000                       â”‚
â”‚                                                            â”‚
â”‚  Flatten â†’ [Dropout] â†’ [Dropout] â†’ Softmax                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# è¯¦ç»†å‚æ•°è¡¨
print("""
å±‚çº§è¯¦è§£:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer â”‚ Input Size â”‚ Kernel  â”‚ Stride  â”‚ Output  â”‚ Parameters   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv1 â”‚ 227Ã—227Ã—3  â”‚ 11Ã—11   â”‚ 4       â”‚ 55Ã—55Ã—96â”‚ 34,944       â”‚
â”‚ Pool1 â”‚ 55Ã—55Ã—96   â”‚ 3Ã—3     â”‚ 2       â”‚ 27Ã—27Ã—96â”‚ 0            â”‚
â”‚ Conv2 â”‚ 27Ã—27Ã—96   â”‚ 5Ã—5     â”‚ 1, p=2  â”‚ 27Ã—27Ã—256â”‚ 614,656     â”‚
â”‚ Pool2 â”‚ 27Ã—27Ã—256  â”‚ 3Ã—3     â”‚ 2       â”‚ 13Ã—13Ã—256â”‚ 0           â”‚
â”‚ Conv3 â”‚ 13Ã—13Ã—256  â”‚ 3Ã—3     â”‚ 1, p=1  â”‚ 13Ã—13Ã—384â”‚ 885,120     â”‚
â”‚ Conv4 â”‚ 13Ã—13Ã—384  â”‚ 3Ã—3     â”‚ 1, p=1  â”‚ 13Ã—13Ã—384â”‚ 1,327,488   â”‚
â”‚ Conv5 â”‚ 13Ã—13Ã—384  â”‚ 3Ã—3     â”‚ 1, p=1  â”‚ 13Ã—13Ã—256â”‚ 884,992     â”‚
â”‚ Pool5 â”‚ 13Ã—13Ã—256  â”‚ 3Ã—3     â”‚ 2       â”‚ 6Ã—6Ã—256 â”‚ 0            â”‚
â”‚ FC1   â”‚ 9216       â”‚ -       â”‚ -       â”‚ 4096    â”‚ 37,752,832   â”‚
â”‚ FC2   â”‚ 4096       â”‚ -       â”‚ -       â”‚ 4096    â”‚ 16,781,312   â”‚
â”‚ FC3   â”‚ 4096       â”‚ -       â”‚ -       â”‚ 1000    â”‚ 4,097,000    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ€»å‚æ•°é‡: çº¦ 6200 ä¸‡
""")

# ============================================================
# 3. AlexNet çš„å…³é”®åˆ›æ–°
# ============================================================
print("\nğŸ“Œ 3. AlexNet çš„å…³é”®åˆ›æ–°")
print("-" * 40)

print("""
åˆ›æ–°1: ReLU æ¿€æ´»å‡½æ•°
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ æ›¿ä»£ Sigmoid/Tanh
â€¢ è§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
â€¢ è®­ç»ƒé€Ÿåº¦æå‡çº¦ 6 å€

åˆ›æ–°2: Dropout æ­£åˆ™åŒ–
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ é˜²æ­¢è¿‡æ‹Ÿåˆ
â€¢ åœ¨å…¨è¿æ¥å±‚ä½¿ç”¨ p=0.5
â€¢ è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒç¥ç»å…ƒ

åˆ›æ–°3: å±€éƒ¨å“åº”å½’ä¸€åŒ– (LRN)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ æ¨¡æ‹Ÿç”Ÿç‰©ç¥ç»å…ƒçš„ä¾§æŠ‘åˆ¶
â€¢ åæ¥è¢« BatchNorm å–ä»£
â€¢ å…¬å¼: b_{x,y}^i = a_{x,y}^i / (k + Î±âˆ‘a_{x,y}^j)^Î²

åˆ›æ–°4: é‡å æ± åŒ–
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ kernel=3, stride=2 (æœ‰é‡å )
â€¢ æ¯” kernel=2, stride=2 æ›´æœ‰æ•ˆ
â€¢ è½»å¾®æå‡å‡†ç¡®ç‡ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ

åˆ›æ–°5: æ•°æ®å¢å¼º
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ éšæœºè£å‰ª 224Ã—224 from 256Ã—256
â€¢ æ°´å¹³ç¿»è½¬
â€¢ PCA é¢œè‰²å¢å¼º
â€¢ æµ‹è¯•æ—¶ 10-crop å¹³å‡

åˆ›æ–°6: å¤š GPU è®­ç»ƒ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ æ¨¡å‹å¹¶è¡Œï¼šä¸åŒå±‚åœ¨ä¸åŒ GPU
â€¢ å¼€å¯äº†å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ è®­ç»ƒ
""")

# ============================================================
# 4. PyTorch å®ç°
# ============================================================
print("\nğŸ“Œ 4. AlexNet PyTorch å®ç°")
print("-" * 40)

class AlexNet(nn.Module):
    """
    AlexNet å®ç°
    è¾“å…¥: 3Ã—227Ã—227 (æˆ– 3Ã—224Ã—224)
    è¾“å‡º: 1000 ç±» (ImageNet)
    """
    def __init__(self, num_classes=1000):
        super(AlexNet, self).__init__()
        
        self.features = nn.Sequential(
            # Conv1
            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            
            # Conv2
            nn.Conv2d(96, 256, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            
            # Conv3
            nn.Conv2d(256, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            
            # Conv4
            nn.Conv2d(384, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            
            # Conv5
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
        )
        
        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))
        
        self.classifier = nn.Sequential(
            nn.Dropout(p=0.5),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )
    
    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

# åˆ›å»ºæ¨¡å‹å¹¶æ‰“å°ä¿¡æ¯
model = AlexNet(num_classes=1000)
print(model)

# æµ‹è¯•å‰å‘ä¼ æ’­
dummy_input = torch.randn(1, 3, 224, 224)
output = model(dummy_input)
print(f"\nè¾“å…¥å½¢çŠ¶: {dummy_input.shape}")
print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")

# å‚æ•°ç»Ÿè®¡
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"\næ€»å‚æ•°é‡: {total_params:,}")
print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

# ============================================================
# 5. ä½¿ç”¨ torchvision çš„é¢„è®­ç»ƒæ¨¡å‹
# ============================================================
print("\nğŸ“Œ 5. ä½¿ç”¨é¢„è®­ç»ƒçš„ AlexNet")
print("-" * 40)

print("""
# ä½¿ç”¨ torchvision é¢„è®­ç»ƒæ¨¡å‹
from torchvision.models import alexnet, AlexNet_Weights

# åŠ è½½é¢„è®­ç»ƒæƒé‡
model = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)

# ç”¨äºè¿ç§»å­¦ä¹ 
model.classifier[6] = nn.Linear(4096, num_your_classes)

# å†»ç»“ç‰¹å¾æå–å±‚
for param in model.features.parameters():
    param.requires_grad = False
""")

# ============================================================
# 6. å„å±‚çš„ç‰¹å¾å¯è§†åŒ–ç†è§£
# ============================================================
print("\nğŸ“Œ 6. AlexNet ç‰¹å¾å±‚æ¬¡")
print("-" * 40)

print("""
ç‰¹å¾æå–å±‚æ¬¡:

Layer 1 (Conv1):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  96 ä¸ª 11Ã—11 å·ç§¯æ ¸                     â”‚
â”‚  å­¦ä¹ : è¾¹ç¼˜ã€é¢œè‰²å—ã€ç®€å•çº¹ç†            â”‚
â”‚  ç±»ä¼¼ Gabor æ»¤æ³¢å™¨                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
Layer 2 (Conv2):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  256 ä¸ª 5Ã—5 å·ç§¯æ ¸                      â”‚
â”‚  å­¦ä¹ : çº¹ç†ã€ç®€å•å½¢çŠ¶ç»„åˆ                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
Layer 3-4 (Conv3, Conv4):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  384 ä¸ª 3Ã—3 å·ç§¯æ ¸                      â”‚
â”‚  å­¦ä¹ : å¤æ‚çº¹ç†ã€éƒ¨ä»¶                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
Layer 5 (Conv5):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  256 ä¸ª 3Ã—3 å·ç§¯æ ¸                      â”‚
â”‚  å­¦ä¹ : ç‰©ä½“éƒ¨ä»¶ã€é«˜çº§ç‰¹å¾                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
FC Layers:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4096 â†’ 4096 â†’ 1000                     â”‚
â”‚  ç»„åˆç‰¹å¾è¿›è¡Œåˆ†ç±»                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# ============================================================
# 7. AlexNet vs LeNet å¯¹æ¯”
# ============================================================
print("\nğŸ“Œ 7. AlexNet vs LeNet å¯¹æ¯”")
print("-" * 40)

print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ç‰¹æ€§      â”‚    LeNet-5      â”‚    AlexNet      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   å¹´ä»½        â”‚    1998         â”‚    2012         â”‚
â”‚   æ·±åº¦        â”‚    5å±‚          â”‚    8å±‚          â”‚
â”‚   å‚æ•°é‡      â”‚    6ä¸‡          â”‚    6200ä¸‡       â”‚
â”‚   è¾“å…¥å°ºå¯¸    â”‚    32Ã—32        â”‚    227Ã—227      â”‚
â”‚   æ¿€æ´»å‡½æ•°    â”‚    Tanh         â”‚    ReLU         â”‚
â”‚   æ± åŒ–æ–¹å¼    â”‚    AvgPool      â”‚    MaxPool      â”‚
â”‚   æ­£åˆ™åŒ–      â”‚    æ—            â”‚    Dropout      â”‚
â”‚   è®­ç»ƒè®¾å¤‡    â”‚    CPU          â”‚    GPU          â”‚
â”‚   æ•°æ®é›†      â”‚    MNIST        â”‚    ImageNet     â”‚
â”‚   ç±»åˆ«æ•°      â”‚    10           â”‚    1000         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä» LeNet åˆ° AlexNet çš„è¿›æ­¥:
âœ… æ›´å¤§çš„è¾“å…¥å°ºå¯¸ â†’ å¤„ç†çœŸå®å›¾åƒ
âœ… æ›´æ·±çš„ç½‘ç»œ â†’ å­¦ä¹ å¤æ‚ç‰¹å¾
âœ… ReLU â†’ æ›´å¿«è®­ç»ƒ
âœ… Dropout â†’ é˜²æ­¢è¿‡æ‹Ÿåˆ
âœ… GPU è®­ç»ƒ â†’ æ›´å¤§è§„æ¨¡
""")

# ============================================================
# 8. CIFAR-10 ç‰ˆæœ¬çš„ AlexNet
# ============================================================
print("\nğŸ“Œ 8. é€‚ç”¨äº CIFAR-10 çš„ AlexNet")
print("-" * 40)

class AlexNetCIFAR(nn.Module):
    """
    é€‚ç”¨äº CIFAR-10 (32Ã—32) çš„ç®€åŒ– AlexNet
    """
    def __init__(self, num_classes=10):
        super(AlexNetCIFAR, self).__init__()
        
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            nn.Conv2d(64, 192, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            nn.Conv2d(192, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(256 * 4 * 4, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )
    
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

model_cifar = AlexNetCIFAR()
test_input = torch.randn(1, 3, 32, 32)
test_output = model_cifar(test_input)
print(f"CIFAR-10 ç‰ˆæœ¬è¾“å…¥: {test_input.shape}")
print(f"CIFAR-10 ç‰ˆæœ¬è¾“å‡º: {test_output.shape}")

# ============================================================
# ç»ƒä¹ é¢˜
# ============================================================
print("\n" + "=" * 60)
print("ğŸ’¡ ç»ƒä¹ é¢˜")
print("=" * 60)

print("""
1. è®¡ç®— AlexNet ç¬¬ä¸€ä¸ªå·ç§¯å±‚çš„å‚æ•°é‡ (11Ã—11Ã—3Ã—96 + 96)

2. ä¸ºä»€ä¹ˆ AlexNet ä½¿ç”¨ 3Ã—3 é‡å æ± åŒ–è€Œä¸æ˜¯ 2Ã—2ï¼Ÿ

3. å¦‚ä½•ä¿®æ”¹ AlexNet ç”¨äºäºŒåˆ†ç±»ä»»åŠ¡ï¼Ÿ

4. å°è¯•ç§»é™¤ Dropout å±‚ï¼Œè§‚å¯Ÿè¿‡æ‹Ÿåˆç°è±¡
""")

# ============================================================
# æ€»ç»“
# ============================================================
print("\n" + "=" * 60)
print("ğŸ“ æœ¬èŠ‚è¦ç‚¹æ€»ç»“")
print("=" * 60)

print("""
1. AlexNet åœ¨ 2012 å¹´å¼€å¯äº†æ·±åº¦å­¦ä¹ é©å‘½

2. å…³é”®åˆ›æ–°:
   - ReLU æ¿€æ´»å‡½æ•°
   - Dropout æ­£åˆ™åŒ–
   - æ•°æ®å¢å¼º
   - GPU è®­ç»ƒ

3. æ¶æ„: 5 å·ç§¯å±‚ + 3 å…¨è¿æ¥å±‚

4. å‚æ•°é‡: çº¦ 6200 ä¸‡ï¼Œå¤§éƒ¨åˆ†åœ¨å…¨è¿æ¥å±‚

5. ä» AlexNet å¼€å§‹ï¼ŒCNN æˆä¸ºå›¾åƒè¯†åˆ«çš„ä¸»æµæ–¹æ³•

ä¸‹ä¸€èŠ‚: VGGNet æ¶æ„
""")
