"""
11-feature-visualization.py - ç‰¹å¾å›¾å¯è§†åŒ–

æœ¬èŠ‚å­¦ä¹ : å¦‚ä½•å¯è§†åŒ– CNN å„å±‚çš„ç‰¹å¾å›¾
"""
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from torchvision import models, transforms
from PIL import Image
import numpy as np

print("=" * 60)
print("ç¬¬11èŠ‚: ç‰¹å¾å›¾å¯è§†åŒ–")
print("=" * 60)

print("""
ğŸ“Œ ä¸ºä»€ä¹ˆè¦å¯è§†åŒ–ç‰¹å¾å›¾?
1. ç†è§£ CNN åœ¨"çœ‹ä»€ä¹ˆ"
2. è°ƒè¯•å’Œæ”¹è¿›æ¨¡å‹
3. è§£é‡Šæ¨¡å‹å†³ç­–

å¯è§†åŒ–æ–¹æ³•:
- ä¸­é—´å±‚ç‰¹å¾å›¾
- å·ç§¯æ ¸æƒé‡
- æ¿€æ´»æœ€å¤§åŒ–
- Grad-CAM (ä¸‹ä¸€èŠ‚)
""")

# ç‰¹å¾æå–å™¨
class FeatureExtractor(nn.Module):
    def __init__(self, model, layers):
        super().__init__()
        self.model = model
        self.layers = layers
        self.features = {}
        self._register_hooks()
    
    def _register_hooks(self):
        def hook_fn(name):
            def hook(module, input, output):
                self.features[name] = output.detach()
            return hook
        
        for name, module in self.model.named_modules():
            if name in self.layers:
                module.register_forward_hook(hook_fn(name))
    
    def forward(self, x):
        self.features.clear()
        _ = self.model(x)
        return self.features

# åˆ›å»ºæ¨¡å‹
model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
model.eval()

# æŒ‡å®šè¦æå–çš„å±‚
layers = ['layer1.0.conv1', 'layer2.0.conv1', 'layer3.0.conv1', 'layer4.0.conv1']
extractor = FeatureExtractor(model, layers)

# åˆ›å»ºéšæœºè¾“å…¥æµ‹è¯•
x = torch.randn(1, 3, 224, 224)
features = extractor(x)

print("å„å±‚ç‰¹å¾å›¾å½¢çŠ¶:")
for name, feat in features.items():
    print(f"  {name}: {feat.shape}")

def visualize_features(features, layer_name, num_channels=16):
    """å¯è§†åŒ–ç‰¹å¾å›¾"""
    if layer_name not in features:
        print(f"å±‚ {layer_name} ä¸å­˜åœ¨")
        return
    
    feat = features[layer_name][0]  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
    num_channels = min(num_channels, feat.shape[0])
    
    fig, axes = plt.subplots(4, 4, figsize=(8, 8))
    for i, ax in enumerate(axes.flat):
        if i < num_channels:
            ax.imshow(feat[i].cpu().numpy(), cmap='viridis')
            ax.set_title(f'Ch {i}')
        ax.axis('off')
    plt.suptitle(f'Feature Maps: {layer_name}')
    plt.tight_layout()
    return fig

# å¯è§†åŒ–å·ç§¯æ ¸
def visualize_conv_weights(model, layer_name='conv1'):
    """å¯è§†åŒ–ç¬¬ä¸€å±‚å·ç§¯æ ¸"""
    for name, module in model.named_modules():
        if name == layer_name and isinstance(module, nn.Conv2d):
            weights = module.weight.data.cpu()
            print(f"å·ç§¯æ ¸å½¢çŠ¶: {weights.shape}")
            
            # åªå±•ç¤ºå‰ 16 ä¸ªæ ¸
            n = min(16, weights.shape[0])
            fig, axes = plt.subplots(4, 4, figsize=(6, 6))
            for i, ax in enumerate(axes.flat):
                if i < n:
                    w = weights[i]
                    if w.shape[0] == 3:  # RGB
                        w = w.permute(1, 2, 0)
                        w = (w - w.min()) / (w.max() - w.min())
                        ax.imshow(w.numpy())
                    else:
                        ax.imshow(w[0].numpy(), cmap='gray')
                ax.axis('off')
            plt.suptitle(f'Conv Kernels: {layer_name}')
            return fig
    return None

print("""
ğŸ“Œ ä½¿ç”¨ç¤ºä¾‹:

# åŠ è½½çœŸå®å›¾ç‰‡
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
img = Image.open('your_image.jpg')
x = transform(img).unsqueeze(0)

# æå–ç‰¹å¾
features = extractor(x)

# å¯è§†åŒ–
fig = visualize_features(features, 'layer1.0.conv1')
plt.savefig('features.png')
""")

print("""
ğŸ“ è¦ç‚¹æ€»ç»“:
1. ä½¿ç”¨ forward hook æå–ä¸­é—´å±‚ç‰¹å¾
2. æµ…å±‚: è¾¹ç¼˜ã€é¢œè‰²ç­‰ä½çº§ç‰¹å¾
3. æ·±å±‚: ç‰©ä½“éƒ¨ä»¶ã€è¯­ä¹‰ç­‰é«˜çº§ç‰¹å¾
4. å¯è§†åŒ–å¸®åŠ©ç†è§£å’Œè°ƒè¯•æ¨¡å‹
""")
