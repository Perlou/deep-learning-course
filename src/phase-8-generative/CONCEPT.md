# 生成模型完全解析：从零开始理解

---

## 目录

1. [什么是生成模型](#1-什么是生成模型)
2. [判别模型 vs 生成模型](#2-判别模型-vs-生成模型)
3. [生成模型的发展历程](#3-生成模型的发展历程)
4. [主要生成模型类型](#4-主要生成模型类型)
5. [核心数学原理](#5-核心数学原理)
6. [实际应用场景](#6-实际应用场景)
7. [代码示例](#7-代码示例)
8. [总结与展望](#8-总结与展望)

---

## 1. 什么是生成模型

### 1.1 基本定义

**生成模型 (Generative Model)** 是一类能够学习数据分布并生成新数据的机器学习模型。

```
简单理解：
┌─────────────────────────────────────────────────────────┐
│                                                         │
│   训练数据 ──→ 生成模型学习数据规律 ──→ 生成新的相似数据  │
│                                                         │
│   例如：                                                │
│   1000张猫图片 ──→ 模型学习"猫长什么样" ──→ 生成新猫图片  │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

### 1.2 核心目标

生成模型的核心目标是**学习数据的概率分布** $P(X)$：

| 目标           | 描述                             |
| -------------- | -------------------------------- |
| **密度估计**   | 学习数据的真实分布 $P_{data}(x)$ |
| **采样生成**   | 从学到的分布中采样生成新数据     |
| **隐空间学习** | 学习数据的低维表示               |

---

## 2. 判别模型 vs 生成模型

```
┌─────────────────────────────────────────────────────────────┐
│                        判别模型                              │
│  ┌─────────┐                           ┌─────────┐          │
│  │  输入X   │ ──→ 学习 P(Y|X) ──→       │  标签Y  │          │
│  │ (图片)   │     条件概率              │ (猫/狗)  │          │
│  └─────────┘                           └─────────┘          │
│                                                             │
│  目标：给定输入，预测类别                                     │
│  例子：分类器、回归模型                                       │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│                        生成模型                              │
│  ┌─────────┐                           ┌─────────┐          │
│  │ 随机噪声 │ ──→ 学习 P(X) ──→         │  新数据  │          │
│  │    z    │     数据分布              │ (新图片) │          │
│  └─────────┘                           └─────────┘          │
│                                                             │
│  目标：学习数据分布，生成新样本                               │
│  例子：GAN、VAE、扩散模型                                     │
└─────────────────────────────────────────────────────────────┘
```

### 对比表格

| 特性         | 判别模型                  | 生成模型           |
| ------------ | ------------------------- | ------------------ |
| **学习目标** | $P(Y\|X)$                 | $P(X)$ 或 $P(X,Y)$ |
| **主要任务** | 分类、回归                | 生成、采样         |
| **典型例子** | SVM、逻辑回归、CNN 分类器 | GAN、VAE、GPT      |
| **数据理解** | 学习边界                  | 学习分布           |

---

## 3. 生成模型的发展历程

```
时间线
──────────────────────────────────────────────────────────────────────→

2013        2014        2017         2020         2022         2023
 │           │           │            │            │            │
 ▼           ▼           ▼            ▼            ▼            ▼
VAE         GAN      Transformer   GPT-3      ChatGPT      GPT-4
变分自      生成对抗   注意力机制    大语言      扩散模型     多模态
编码器      网络                    模型        DALL-E 2     Sora
                                               Stable
                                               Diffusion
```

### 里程碑事件

| 年份     | 事件        | 意义                   |
| -------- | ----------- | ---------------------- |
| **2013** | VAE 提出    | 引入隐变量和变分推断   |
| **2014** | GAN 提出    | 对抗训练范式革命       |
| **2017** | Transformer | 自注意力机制，奠定基础 |
| **2020** | GPT-3       | 展示大规模语言模型能力 |
| **2020** | DDPM        | 扩散模型复兴           |
| **2022** | ChatGPT     | AI 对话革命            |
| **2023** | GPT-4       | 多模态大模型           |

---

## 4. 主要生成模型类型

### 4.1 自回归模型 (Autoregressive Models)

#### 核心思想

将联合概率分解为条件概率的乘积：

$$P(x) = \prod_{i=1}^{n} P(x_i | x_1, x_2, ..., x_{i-1})$$

```
生成过程示意：
┌─────────────────────────────────────────────────────────┐
│                                                         │
│    起始 → 生成第1个 → 生成第2个 → ... → 生成第n个        │
│                                                         │
│    <s> →    "今天"   →   "天气"   → "很好" → </s>        │
│              ↑            ↑         ↑                   │
│           P(x₁|<s>)   P(x₂|x₁)   P(x₃|x₁,x₂)            │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

#### 代表模型

- **GPT 系列**：GPT-1, GPT-2, GPT-3, GPT-4
- **PixelCNN**：逐像素生成图像
- **WaveNet**：生成音频

#### 优缺点

| 优点              | 缺点                  |
| ----------------- | --------------------- |
| ✅ 精确的似然估计 | ❌ 生成速度慢（串行） |
| ✅ 训练稳定       | ❌ 无法并行生成       |
| ✅ 支持条件生成   | ❌ 长序列依赖困难     |

---

### 4.2 变分自编码器 (VAE)

#### 核心思想

通过编码器-解码器结构学习数据的隐空间表示。

```
VAE 架构：
┌────────────────────────────────────────────────────────────┐
│                                                            │
│   输入x     编码器          隐空间z         解码器     重构x' │
│  ┌───┐    ┌───────┐       ┌───────┐      ┌───────┐   ┌───┐ │
│  │ 🖼️ │ →  │Encoder│ → μ,σ │采样 z │  →   │Decoder│ → │ 🖼️ │ │
│  └───┘    └───────┘       └───────┘      └───────┘   └───┘ │
│                              ↑                             │
│                      重参数化技巧                           │
│                   z = μ + σ * ε                            │
│                   (ε ~ N(0,1))                             │
│                                                            │
└────────────────────────────────────────────────────────────┘
```

#### 损失函数

$$\mathcal{L} = \underbrace{-\mathbb{E}_{q(z|x)}[\log p(x|z)]}_{\text{重构损失}} + \underbrace{D_{KL}(q(z|x) \| p(z))}_{\text{KL散度正则化}}$$

#### 优缺点

| 优点                  | 缺点                |
| --------------------- | ------------------- |
| ✅ 学习有意义的隐空间 | ❌ 生成图像模糊     |
| ✅ 训练稳定           | ❌ 后验假设过于简单 |
| ✅ 支持插值操作       | ❌ 生成质量有限     |

---

### 4.3 生成对抗网络 (GAN)

#### 核心思想

通过**生成器**和**判别器**的对抗训练来生成逼真数据。

```
GAN 架构：
┌────────────────────────────────────────────────────────────────┐
│                                                                │
│   随机噪声 z                        真实数据                    │
│      ↓                                 ↓                       │
│  ┌─────────┐                      ┌─────────┐                  │
│  │ Generator │ ──→ 假数据 ──→     │Discriminator│ ──→ 真/假?   │
│  │   生成器  │        ↑          │   判别器     │              │
│  └─────────┘         │          └─────────┘                  │
│       ↑               │               ↓                       │
│       └───────────────┴───────── 反馈信号                      │
│                                                                │
│   生成器目标：生成以假乱真的数据，骗过判别器                       │
│   判别器目标：准确区分真假数据                                    │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

#### 目标函数（极小极大博弈）

$$\min_G \max_D \mathbb{E}_{x \sim p_{data}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1-D(G(z)))]$$

#### GAN 变体发展

```
GAN 家族进化树：
                     ┌─── DCGAN (2015) ──── 卷积架构
                     │
                     ├─── WGAN (2017) ──── Wasserstein距离
                     │
Original GAN ────────├─── StyleGAN (2018) ──── 风格控制
   (2014)            │
                     ├─── BigGAN (2018) ──── 大规模训练
                     │
                     └─── StyleGAN2/3 ──── 图像质量巅峰
```

#### 优缺点

| 优点            | 缺点            |
| --------------- | --------------- |
| ✅ 生成质量高   | ❌ 训练不稳定   |
| ✅ 生成速度快   | ❌ 模式崩塌问题 |
| ✅ 无需显式密度 | ❌ 难以评估     |

---

### 4.4 扩散模型 (Diffusion Models)

#### 核心思想

通过**逐步添加噪声**（前向过程）和**逐步去噪**（反向过程）来生成数据。

```
扩散模型过程：

前向过程（加噪）：
清晰图像 ──→ 轻微噪声 ──→ 更多噪声 ──→ ... ──→ 纯噪声
   x₀    q(x₁|x₀)   x₁    q(x₂|x₁)   x₂           xₜ

反向过程（去噪）：神经网络学习
纯噪声 ──→ 略清晰 ──→ 更清晰 ──→ ... ──→ 清晰图像
  xₜ   p(xₜ₋₁|xₜ)  xₜ₋₁  p(xₜ₋₂|xₜ₋₁)          x₀


可视化：
┌──────────────────────────────────────────────────────────┐
│                                                          │
│  🖼️ ──→ 🖼️+📊 ──→ 📊+🖼️ ──→ 📊 ──→ 📊📊 ──→ 📊📊📊          │
│  (清晰)                                    (纯噪声)       │
│                                                          │
│  前向过程：逐步添加高斯噪声                                 │
│                                                          │
│  📊📊📊 ──→ 📊📊 ──→ 📊 ──→ 🖼️+📊 ──→ 🖼️ ──→ 🖼️             │
│  (纯噪声)                                    (清晰)       │
│                                                          │
│  反向过程：神经网络学习去噪                                 │
│                                                          │
└──────────────────────────────────────────────────────────┘
```

#### 数学表达

**前向过程**：
$$q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t I)$$

**反向过程**：
$$p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$$

#### 代表模型

- **DDPM** (2020)：扩散模型复兴
- **DALL-E 2** (2022)：文本到图像
- **Stable Diffusion** (2022)：开源图像生成
- **Midjourney**：艺术图像生成
- **Sora** (2024)：视频生成

#### 优缺点

| 优点            | 缺点              |
| --------------- | ----------------- |
| ✅ 生成质量极高 | ❌ 采样速度慢     |
| ✅ 训练稳定     | ❌ 需要多步迭代   |
| ✅ 模式覆盖好   | ❌ 计算资源需求大 |
| ✅ 理论基础扎实 |                   |

---

### 4.5 Transformer 与大语言模型 (LLM)

#### 核心思想

基于**自注意力机制**，通过预测下一个 token 来学习语言规律。

```
Transformer 架构简图：

┌─────────────────────────────────────────────────────────────┐
│                                                             │
│   输入: "今天天气"                                           │
│          ↓                                                  │
│   ┌───────────────┐                                         │
│   │   Embedding   │  ← 词嵌入                                │
│   └───────────────┘                                         │
│          ↓                                                  │
│   ┌───────────────┐                                         │
│   │  Positional   │  ← 位置编码                              │
│   │   Encoding    │                                         │
│   └───────────────┘                                         │
│          ↓                                                  │
│   ┌───────────────┐                                         │
│   │    Multi-Head │  ← 多头自注意力                          │
│   │   Attention   │    (每个词关注其他词)                     │
│   └───────────────┘                                         │
│          ↓                                                  │
│   ┌───────────────┐                                         │
│   │  Feed Forward │  ← 前馈网络                              │
│   └───────────────┘                                         │
│          ↓                                                  │
│   × N层 Transformer Block                                   │
│          ↓                                                  │
│   ┌───────────────┐                                         │
│   │   Output      │  → 预测: "很好"                          │
│   └───────────────┘                                         │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

#### 自注意力机制

$$\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

```
注意力计算示意：

Query(查询) × Key(键)ᵀ = 注意力分数 → softmax → 权重 × Value(值)

      "今"  "天"  "天"  "气"
"今"  0.8   0.1   0.05  0.05    每个词与其他词的相关性
"天"  0.1   0.6   0.2   0.1
"天"  0.05  0.2   0.5   0.25
"气"  0.05  0.1   0.25  0.6
```

#### LLM 发展

```
规模演进：
┌────────────────────────────────────────────────────────────┐
│                                                            │
│   GPT-1      GPT-2      GPT-3       GPT-4                  │
│   117M  →   1.5B   →   175B    →   ?T                      │
│   2018      2019       2020       2023                     │
│                                                            │
│                        参数量指数增长                        │
│                                                            │
└────────────────────────────────────────────────────────────┘
```

---

### 4.6 模型对比总结

| 模型类型      | 生成质量   | 训练稳定性 | 速度       | 多样性     | 应用场景         |
| ------------- | ---------- | ---------- | ---------- | ---------- | ---------------- |
| **自回归**    | ⭐⭐⭐⭐   | ⭐⭐⭐⭐⭐ | ⭐⭐       | ⭐⭐⭐⭐   | 文本、音频       |
| **VAE**       | ⭐⭐⭐     | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐     | 图像压缩、隐空间 |
| **GAN**       | ⭐⭐⭐⭐⭐ | ⭐⭐       | ⭐⭐⭐⭐⭐ | ⭐⭐⭐     | 图像生成         |
| **Diffusion** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐       | ⭐⭐⭐⭐⭐ | 图像、视频       |
| **LLM**       | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐   | ⭐⭐⭐     | ⭐⭐⭐⭐⭐ | 文本、对话       |

---

## 5. 核心数学原理

### 5.1 最大似然估计 (MLE)

生成模型的基本目标是最大化数据的对数似然：

$$\theta^* = \arg\max_\theta \sum_{i=1}^{N} \log p_\theta(x_i)$$

### 5.2 KL 散度

衡量两个分布之间的差异：

$$D_{KL}(P \| Q) = \sum_x P(x) \log \frac{P(x)}{Q(x)}$$

```
KL散度直观理解：
┌─────────────────────────────────────────────────┐
│                                                 │
│   P(x)           Q(x)         D_KL(P||Q)       │
│    ▲              ▲                            │
│   / \            / \                           │
│  /   \    vs    /   \     →    差异度量         │
│ ───────        ───────                         │
│                                                 │
│ 当 P = Q 时，KL散度 = 0                         │
│ 分布越不同，KL散度越大                           │
│                                                 │
└─────────────────────────────────────────────────┘
```

### 5.3 重参数化技巧 (VAE)

使随机采样可导：

$$z = \mu + \sigma \odot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)$$

```
为什么需要重参数化？

问题：采样操作不可导，无法反向传播
      z ~ N(μ, σ²)  ← 这一步梯度无法传递

解决：把随机性转移到与参数无关的ε上
      ε ~ N(0, 1)   ← 随机性来源
      z = μ + σ·ε   ← 确定性变换，可导！
```

---

## 6. 实际应用场景

### 6.1 图像领域

```
┌────────────────────────────────────────────────────────────┐
│                      图像应用                               │
├──────────────┬─────────────────────────────────────────────┤
│ 文本生成图像 │ DALL-E, Midjourney, Stable Diffusion        │
├──────────────┼─────────────────────────────────────────────┤
│ 图像修复     │ 填补缺失区域、去除水印                        │
├──────────────┼─────────────────────────────────────────────┤
│ 风格迁移     │ 将照片转为艺术风格                           │
├──────────────┼─────────────────────────────────────────────┤
│ 超分辨率     │ 提升图像分辨率                               │
├──────────────┼─────────────────────────────────────────────┤
│ 图像编辑     │ 根据文本指令编辑图像                         │
└──────────────┴─────────────────────────────────────────────┘
```

### 6.2 文本领域

```
┌────────────────────────────────────────────────────────────┐
│                      文本应用                               │
├──────────────┬─────────────────────────────────────────────┤
│ 对话系统     │ ChatGPT, Claude, 文心一言                   │
├──────────────┼─────────────────────────────────────────────┤
│ 内容创作     │ 文章、故事、诗歌生成                         │
├──────────────┼─────────────────────────────────────────────┤
│ 代码生成     │ GitHub Copilot, CodeLlama                   │
├──────────────┼─────────────────────────────────────────────┤
│ 翻译         │ 多语言翻译                                   │
├──────────────┼─────────────────────────────────────────────┤
│ 摘要         │ 文档摘要、信息提取                           │
└──────────────┴─────────────────────────────────────────────┘
```

### 6.3 多模态应用

```
┌────────────────────────────────────────────────────────────┐
│                     多模态应用                              │
├──────────────┬─────────────────────────────────────────────┤
│ 视频生成     │ Sora, Runway Gen-2                         │
├──────────────┼─────────────────────────────────────────────┤
│ 音乐生成     │ MusicLM, Suno AI                           │
├──────────────┼─────────────────────────────────────────────┤
│ 语音合成     │ TTS, 声音克隆                               │
├──────────────┼─────────────────────────────────────────────┤
│ 3D生成       │ 3D模型、场景生成                            │
└──────────────┴─────────────────────────────────────────────┘
```

---

## 7. 代码示例

### 7.1 简单 VAE 实现 (PyTorch)

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class VAE(nn.Module):
    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):
        super(VAE, self).__init__()

        # 编码器
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)      # 均值
        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)  # 对数方差

        # 解码器
        self.fc3 = nn.Linear(latent_dim, hidden_dim)
        self.fc4 = nn.Linear(hidden_dim, input_dim)

    def encode(self, x):
        """编码器：输入 → 隐变量分布参数"""
        h = F.relu(self.fc1(x))
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar

    def reparameterize(self, mu, logvar):
        """重参数化技巧：使采样可导"""
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)  # 从标准正态采样
        return mu + eps * std

    def decode(self, z):
        """解码器：隐变量 → 重构输出"""
        h = F.relu(self.fc3(z))
        return torch.sigmoid(self.fc4(h))

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        x_recon = self.decode(z)
        return x_recon, mu, logvar

def loss_function(x_recon, x, mu, logvar):
    """VAE损失 = 重构损失 + KL散度"""
    # 重构损失 (BCE)
    recon_loss = F.binary_cross_entropy(x_recon, x, reduction='sum')

    # KL散度: D_KL(N(μ,σ²) || N(0,1))
    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())

    return recon_loss + kl_loss
```

### 7.2 简单 GAN 实现 (PyTorch)

```python
import torch
import torch.nn as nn

class Generator(nn.Module):
    """生成器：噪声 → 假图像"""
    def __init__(self, latent_dim=100, img_dim=784):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 1024),
            nn.LeakyReLU(0.2),
            nn.Linear(1024, img_dim),
            nn.Tanh()
        )

    def forward(self, z):
        return self.model(z)

class Discriminator(nn.Module):
    """判别器：图像 → 真假概率"""
    def __init__(self, img_dim=784):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(img_dim, 512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, img):
        return self.model(img)

# 训练循环伪代码
def train_gan(generator, discriminator, dataloader, epochs):
    criterion = nn.BCELoss()
    optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002)
    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002)

    for epoch in range(epochs):
        for real_imgs in dataloader:
            batch_size = real_imgs.size(0)

            # 真假标签
            real_labels = torch.ones(batch_size, 1)
            fake_labels = torch.zeros(batch_size, 1)

            # ====== 训练判别器 ======
            z = torch.randn(batch_size, 100)
            fake_imgs = generator(z)

            real_loss = criterion(discriminator(real_imgs), real_labels)
            fake_loss = criterion(discriminator(fake_imgs.detach()), fake_labels)
            d_loss = real_loss + fake_loss

            optimizer_D.zero_grad()
            d_loss.backward()
            optimizer_D.step()

            # ====== 训练生成器 ======
            z = torch.randn(batch_size, 100)
            fake_imgs = generator(z)
            g_loss = criterion(discriminator(fake_imgs), real_labels)

            optimizer_G.zero_grad()
            g_loss.backward()
            optimizer_G.step()
```

### 7.3 使用 Hugging Face 调用预训练模型

```python
# 文本生成 (GPT-2)
from transformers import pipeline

generator = pipeline('text-generation', model='gpt2')
result = generator("Once upon a time", max_length=50)
print(result[0]['generated_text'])

# 图像生成 (Stable Diffusion)
from diffusers import StableDiffusionPipeline
import torch

pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
)
pipe = pipe.to("cuda")

prompt = "a beautiful sunset over mountains, digital art"
image = pipe(prompt).images[0]
image.save("generated_image.png")
```

---

## 8. 总结与展望

### 8.1 核心要点回顾

```
┌─────────────────────────────────────────────────────────────┐
│                    生成模型核心要点                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  1. 目标：学习数据分布 P(X)，生成新样本                       │
│                                                             │
│  2. 主要范式：                                               │
│     • 自回归：逐步生成，概率链式分解                          │
│     • VAE：编码器-解码器，隐空间学习                          │
│     • GAN：生成器-判别器对抗博弈                              │
│     • Diffusion：加噪-去噪过程                               │
│     • Transformer：自注意力，大规模预训练                     │
│                                                             │
│  3. 评估指标：FID, IS, 困惑度, 人工评估                      │
│                                                             │
│  4. 应用：图像/文本/音频/视频生成                             │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 8.2 未来发展趋势

| 方向           | 描述                             |
| -------------- | -------------------------------- |
| **多模态融合** | 统一的图文音视频生成模型         |
| **更高效架构** | 降低计算成本，提升速度           |
| **可控生成**   | 更精确的控制生成内容             |
| **世界模型**   | 理解物理规律，生成符合现实的内容 |
| **个性化**     | 根据用户偏好定制生成             |
| **安全可信**   | 减少幻觉，提高可靠性             |

### 8.3 学习资源推荐

```
📚 推荐学习路径：
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  入门阶段：                                                  │
│  ├── 《Deep Learning》- Goodfellow                          │
│  ├── 李宏毅机器学习课程                                       │
│  └── 3Blue1Brown 神经网络可视化                              │
│                                                             │
│  进阶阶段：                                                  │
│  ├── 原始论文：VAE, GAN, Transformer, DDPM                  │
│  ├── Stanford CS236: Deep Generative Models                │
│  └── Hugging Face 官方教程                                  │
│                                                             │
│  实践阶段：                                                  │
│  ├── Kaggle 竞赛                                            │
│  ├── GitHub 开源项目                                        │
│  └── 复现经典论文                                           │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 附录：术语表

| 术语     | 英文                       | 解释                                   |
| -------- | -------------------------- | -------------------------------------- |
| 隐变量   | Latent Variable            | 不可直接观测的变量，表示数据的低维表示 |
| 隐空间   | Latent Space               | 隐变量所在的低维空间                   |
| 模式崩塌 | Mode Collapse              | GAN 训练中生成器只生成少量模式的现象   |
| 困惑度   | Perplexity                 | 语言模型的评估指标                     |
| FID      | Fréchet Inception Distance | 图像生成质量评估指标                   |
| 自注意力 | Self-Attention             | Transformer 的核心机制                 |
| 扩散过程 | Diffusion Process          | 逐步添加噪声的马尔可夫过程             |
| Token    | Token                      | 文本的基本单位（词或子词）             |

---
