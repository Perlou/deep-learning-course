"""
10-model-save-load.py
Phase 3: PyTorch æ ¸å¿ƒæŠ€èƒ½

æ¨¡å‹ä¿å­˜ä¸åŠ è½½ - æŒä¹…åŒ–è®­ç»ƒæˆæœ

å­¦ä¹ ç›®æ ‡ï¼š
1. æŒæ¡æ¨¡å‹ä¿å­˜å’ŒåŠ è½½çš„æ–¹æ³•
2. ç†è§£ state_dict çš„æ¦‚å¿µ
3. äº†è§£ checkpoint çš„æœ€ä½³å®è·µ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import os

print("=" * 60)
print("PyTorch æ ¸å¿ƒæŠ€èƒ½ - æ¨¡å‹ä¿å­˜ä¸åŠ è½½")
print("=" * 60)

# =============================================================================
# 1. ä¿å­˜å’ŒåŠ è½½çš„ä¸¤ç§æ–¹å¼
# =============================================================================
print("\nã€1. ä¿å­˜å’ŒåŠ è½½çš„ä¸¤ç§æ–¹å¼ã€‘")

print("""
æ–¹å¼ 1: ä¿å­˜æ•´ä¸ªæ¨¡å‹ (ä¸æ¨è)
    torch.save(model, 'model.pth')
    model = torch.load('model.pth')

æ–¹å¼ 2: åªä¿å­˜å‚æ•° (æ¨è)
    torch.save(model.state_dict(), 'model_weights.pth')
    model.load_state_dict(torch.load('model_weights.pth'))

æ¨èæ–¹å¼ 2 çš„åŸå› :
- æ›´çµæ´» (å¯ä»¥ç”¨äºä¸åŒçš„æ¨¡å‹å®šä¹‰)
- æ›´å°çš„æ–‡ä»¶
- æ›´å¥½çš„å…¼å®¹æ€§
""")

# =============================================================================
# 2. åŸºæœ¬ç¤ºä¾‹
# =============================================================================
print("\n" + "=" * 60)
print("ã€2. åŸºæœ¬ç¤ºä¾‹ã€‘")

# åˆ›å»ºæ¨¡å‹
class SimpleNet(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        return self.fc2(x)

model = SimpleNet(10, 20, 5)

# æŸ¥çœ‹ state_dict
print("state_dict å†…å®¹:")
for name, param in model.state_dict().items():
    print(f"  {name}: {param.shape}")

# åˆ›å»ºä¿å­˜ç›®å½•
save_dir = 'outputs/models'
os.makedirs(save_dir, exist_ok=True)

# ä¿å­˜å‚æ•°
save_path = os.path.join(save_dir, 'simple_net.pth')
torch.save(model.state_dict(), save_path)
print(f"\næ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")

# åŠ è½½å‚æ•°
new_model = SimpleNet(10, 20, 5)
new_model.load_state_dict(torch.load(save_path, weights_only=True))
print("æ¨¡å‹å·²åŠ è½½")

# éªŒè¯
x = torch.randn(3, 10)
with torch.no_grad():
    y1 = model(x)
    y2 = new_model(x)
print(f"è¾“å‡ºä¸€è‡´: {torch.allclose(y1, y2)}")

# =============================================================================
# 3. ä¿å­˜å®Œæ•´ Checkpoint
# =============================================================================
print("\n" + "=" * 60)
print("ã€3. ä¿å­˜å®Œæ•´ Checkpointã€‘")

print("""
Checkpoint åº”åŒ…å«:
- æ¨¡å‹å‚æ•° (model.state_dict())
- ä¼˜åŒ–å™¨çŠ¶æ€ (optimizer.state_dict())
- å½“å‰ epoch
- æœ€ä½³æŒ‡æ ‡
- å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€
- éšæœºæ•°çŠ¶æ€ (å¯é€‰)
""")

# ç¤ºä¾‹
model = SimpleNet(10, 20, 5)
optimizer = optim.Adam(model.parameters(), lr=0.001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10)

# æ¨¡æ‹Ÿè®­ç»ƒ
epoch = 25
best_val_acc = 0.95
train_loss = 0.123

# ä¿å­˜ checkpoint
checkpoint = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'scheduler_state_dict': scheduler.state_dict(),
    'best_val_acc': best_val_acc,
    'train_loss': train_loss,
}

checkpoint_path = os.path.join(save_dir, 'checkpoint.pth')
torch.save(checkpoint, checkpoint_path)
print(f"Checkpoint å·²ä¿å­˜: {checkpoint_path}")

# åŠ è½½ checkpoint
checkpoint = torch.load(checkpoint_path, weights_only=False)

new_model = SimpleNet(10, 20, 5)
new_optimizer = optim.Adam(new_model.parameters(), lr=0.001)
new_scheduler = optim.lr_scheduler.StepLR(new_optimizer, step_size=10)

new_model.load_state_dict(checkpoint['model_state_dict'])
new_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
new_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
start_epoch = checkpoint['epoch'] + 1

print(f"æ¢å¤è®­ç»ƒä» Epoch {start_epoch}")
print(f"ä¹‹å‰çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {checkpoint['best_val_acc']}")

# =============================================================================
# 4. GPU/CPU ä¹‹é—´çš„è½¬æ¢
# =============================================================================
print("\n" + "=" * 60)
print("ã€4. GPU/CPU ä¹‹é—´çš„è½¬æ¢ã€‘")

print("""
# GPU ä¸Šä¿å­˜ï¼ŒCPU ä¸ŠåŠ è½½
model.load_state_dict(torch.load('model.pth', map_location='cpu'))

# CPU ä¸Šä¿å­˜ï¼ŒGPU ä¸ŠåŠ è½½
model.load_state_dict(torch.load('model.pth', map_location='cuda:0'))

# è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.load_state_dict(torch.load('model.pth', map_location=device))
model.to(device)
""")

# =============================================================================
# 5. éƒ¨åˆ†åŠ è½½
# =============================================================================
print("\n" + "=" * 60)
print("ã€5. éƒ¨åˆ†åŠ è½½ (è¿ç§»å­¦ä¹ )ã€‘")

# åˆ›å»ºä¸€ä¸ªä¸å®Œå…¨åŒ¹é…çš„æ¨¡å‹
class LargerNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(10, 20)  # åŒ¹é…
        self.fc2 = nn.Linear(20, 5)   # åŒ¹é…
        self.fc3 = nn.Linear(5, 2)    # æ–°å¢å±‚
    
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        return self.fc3(x)

larger_model = LargerNet()

# åŠ è½½éƒ¨åˆ†æƒé‡
pretrained_dict = torch.load(save_path, weights_only=True)
model_dict = larger_model.state_dict()

# è¿‡æ»¤æ‰ä¸åŒ¹é…çš„é”®
pretrained_dict = {k: v for k, v in pretrained_dict.items() 
                   if k in model_dict and model_dict[k].shape == v.shape}

print(f"å¯åŠ è½½çš„å±‚: {list(pretrained_dict.keys())}")

# æ›´æ–°å½“å‰æ¨¡å‹çš„ state_dict
model_dict.update(pretrained_dict)
larger_model.load_state_dict(model_dict)
print("éƒ¨åˆ†æƒé‡å·²åŠ è½½")

# =============================================================================
# 6. ä¿å­˜ç”¨äºæ¨ç†çš„æ¨¡å‹
# =============================================================================
print("\n" + "=" * 60)
print("ã€6. ä¿å­˜ç”¨äºæ¨ç†çš„æ¨¡å‹ã€‘")

print("""
æ–¹å¼ 1: åªä¿å­˜å‚æ•°
    torch.save(model.state_dict(), 'model_inference.pth')

æ–¹å¼ 2: TorchScript (æ¨èç”¨äºéƒ¨ç½²)
    scripted = torch.jit.script(model)
    scripted.save('model_scripted.pt')
    
    # æˆ–ä½¿ç”¨ trace
    traced = torch.jit.trace(model, example_input)
    traced.save('model_traced.pt')

æ–¹å¼ 3: ONNX æ ¼å¼ (è·¨å¹³å°)
    torch.onnx.export(model, example_input, 'model.onnx')
""")

# TorchScript ç¤ºä¾‹
model.eval()
scripted_model = torch.jit.script(model)
scripted_path = os.path.join(save_dir, 'model_scripted.pt')
scripted_model.save(scripted_path)
print(f"TorchScript æ¨¡å‹å·²ä¿å­˜: {scripted_path}")

# åŠ è½½ TorchScript æ¨¡å‹
loaded_scripted = torch.jit.load(scripted_path)
x = torch.randn(3, 10)
with torch.no_grad():
    y = loaded_scripted(x)
print(f"TorchScript æ¨ç†è¾“å‡º: {y.shape}")

# =============================================================================
# 7. æœ€ä½³å®è·µ
# =============================================================================
print("\n" + "=" * 60)
print("ã€7. æœ€ä½³å®è·µã€‘")

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ä¿å­˜/åŠ è½½æœ€ä½³å®è·µ                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  1. ä½¿ç”¨ .pth æˆ– .pt æ‰©å±•å                               â•‘
â•‘  2. ä¿å­˜å®Œæ•´ checkpointï¼Œä¸åªæ˜¯ state_dict                â•‘
â•‘  3. è®°å½•æ¨¡å‹é…ç½®ï¼ˆç‰ˆæœ¬ã€è¶…å‚æ•°ç­‰ï¼‰                        â•‘
â•‘  4. ä¿å­˜å‰è°ƒç”¨ model.eval()                               â•‘
â•‘  5. ä½¿ç”¨ map_location å¤„ç†è®¾å¤‡å·®å¼‚                        â•‘
â•‘  6. éƒ¨ç½²æ—¶ä½¿ç”¨ TorchScript æˆ– ONNX                        â•‘
â•‘  7. å®šæœŸä¿å­˜ checkpoint (æ¯ N ä¸ª epoch)                   â•‘
â•‘  8. ä¿ç•™æœ€ä½³æ¨¡å‹å’Œæœ€æ–°æ¨¡å‹                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

# å®ç”¨çš„ä¿å­˜å‡½æ•°
def save_checkpoint(model, optimizer, scheduler, epoch, best_acc, path):
    """ä¿å­˜è®­ç»ƒ checkpoint"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
        'best_acc': best_acc,
        'pytorch_version': torch.__version__,
    }
    torch.save(checkpoint, path)
    print(f"Checkpoint saved: {path}")

def load_checkpoint(path, model, optimizer=None, scheduler=None, device='cpu'):
    """åŠ è½½è®­ç»ƒ checkpoint"""
    checkpoint = torch.load(path, map_location=device, weights_only=False)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    if optimizer and 'optimizer_state_dict' in checkpoint:
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    
    if scheduler and 'scheduler_state_dict' in checkpoint:
        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
    
    return checkpoint.get('epoch', 0), checkpoint.get('best_acc', 0)

print("å®ç”¨å‡½æ•° save_checkpoint() å’Œ load_checkpoint() å·²å®šä¹‰")

# =============================================================================
# 8. ç»ƒä¹ é¢˜
# =============================================================================
print("\n" + "=" * 60)
print("ã€ç»ƒä¹ é¢˜ã€‘")
print("=" * 60)

print("""
1. ä¿å­˜ä¸€ä¸ªæ¨¡å‹å¹¶åœ¨æ–°è„šæœ¬ä¸­åŠ è½½

2. å®ç°å®šæœŸä¿å­˜ checkpoint çš„åŠŸèƒ½ (æ¯ 5 ä¸ª epoch)

3. å°†æ¨¡å‹è½¬æ¢ä¸º TorchScript æ ¼å¼

4. å®ç°åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œå†»ç»“éƒ¨åˆ†å±‚ï¼Œåªè®­ç»ƒæœ€åä¸€å±‚

5. è§£é‡Šä¸ºä»€ä¹ˆä¸æ¨èä½¿ç”¨ torch.save(model, ...)
""")

# === ç»ƒä¹ ç­”æ¡ˆ ===
# 1
# torch.save(model.state_dict(), 'model.pth')
# # æ–°è„šæœ¬
# model = SimpleNet(10, 20, 5)
# model.load_state_dict(torch.load('model.pth'))

# 2
# for epoch in range(100):
#     train(...)
#     if (epoch + 1) % 5 == 0:
#         save_checkpoint(model, optimizer, scheduler, epoch, best_acc,
#                        f'checkpoint_epoch{epoch+1}.pth')

# 3
# model.eval()
# scripted = torch.jit.script(model)
# scripted.save('model.pt')

# 4
# model = PretrainedModel()
# model.load_state_dict(torch.load('pretrained.pth'))
# for param in model.parameters():
#     param.requires_grad = False
# model.fc = nn.Linear(512, 10)  # æ›¿æ¢æœ€åä¸€å±‚
# optimizer = optim.Adam(model.fc.parameters(), lr=0.001)

# 5
# ç­”æ¡ˆ: 
# - ä¿å­˜æ•´ä¸ªæ¨¡å‹ä¼šåºåˆ—åŒ–ç±»å®šä¹‰
# - ä¾èµ–äºå…·ä½“çš„ç›®å½•ç»“æ„å’Œç±»è·¯å¾„
# - åŠ è½½æ—¶å¦‚æœç±»å®šä¹‰æ”¹å˜ä¼šå¤±è´¥
# - æ–‡ä»¶æ›´å¤§ï¼Œä¸å¤Ÿçµæ´»

# æ¸…ç†
import shutil
if os.path.exists(save_dir):
    shutil.rmtree(save_dir)
    print(f"\nå·²æ¸…ç†ä¸´æ—¶ç›®å½•: {save_dir}")

print("\nâœ… æ¨¡å‹ä¿å­˜ä¸åŠ è½½å®Œæˆï¼")
print("ğŸ‰ Phase 3 å…¨éƒ¨æ¨¡å—å®Œæˆï¼")
print("\nä¸‹ä¸€æ­¥ï¼šå®Œæˆ MNIST å®æˆ˜é¡¹ç›®ï¼Œç„¶åè¿›å…¥ Phase 4")
