"""
è¯­ä¹‰åˆ†å‰² (Semantic Segmentation)
=================================

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£è¯­ä¹‰åˆ†å‰²ä¸å…¶ä»–åˆ†å‰²ä»»åŠ¡çš„åŒºåˆ«
    2. æŒæ¡ FCN å’Œç¼–ç å™¨-è§£ç å™¨æ¶æ„
    3. äº†è§£å¸¸ç”¨çš„åˆ†å‰²æŸå¤±å‡½æ•°
    4. ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè¯­ä¹‰åˆ†å‰²

æ ¸å¿ƒæ¦‚å¿µï¼š
    - è¯­ä¹‰åˆ†å‰²: å¯¹æ¯ä¸ªåƒç´ è¿›è¡Œåˆ†ç±»
    - ç¼–ç å™¨-è§£ç å™¨: å…ˆä¸‹é‡‡æ ·åä¸Šé‡‡æ ·
    - è·³è·ƒè¿æ¥: ä¿ç•™ç©ºé—´ç»†èŠ‚
    - Dice Loss: å¤„ç†ç±»åˆ«ä¸å¹³è¡¡

å‰ç½®çŸ¥è¯†ï¼š
    - Phase 5: CNN å·ç§¯ç¥ç»ç½‘ç»œ
    - 01-03: ç›®æ ‡æ£€æµ‹åŸºç¡€
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šåˆ†å‰²ä»»åŠ¡æ¦‚è¿° ====================


def introduction():
    """åˆ†å‰²ä»»åŠ¡æ¦‚è¿°"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šåˆ†å‰²ä»»åŠ¡æ¦‚è¿°")
    print("=" * 60)

    print("""
å›¾åƒåˆ†å‰²ä»»åŠ¡åˆ†ç±»ï¼š

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  è¯­ä¹‰åˆ†å‰² (Semantic Segmentation)                        â”‚
    â”‚  - å¯¹æ¯ä¸ªåƒç´ åˆ†ç±»                                        â”‚
    â”‚  - ä¸åŒºåˆ†åŒç±»ç‰©ä½“çš„ä¸åŒå®ä¾‹                               â”‚
    â”‚  - è¾“å‡º: HÃ—WÃ—C (C=ç±»åˆ«æ•°)                                â”‚
    â”‚                                                         â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
    â”‚  â”‚ ğŸŸ¦ğŸŸ¦ğŸŸ¦ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©  â”‚  è“è‰²=å¤©ç©º                         â”‚
    â”‚  â”‚ ğŸŸ©ğŸ•ğŸ•ğŸ•ğŸ•ğŸŸ©ğŸŸ©  â”‚  ğŸ•=ç‹— (ä¸åŒºåˆ†ä¸ªä½“)                â”‚
    â”‚  â”‚ ğŸŸ©ğŸŸ©ğŸ•ğŸ•ğŸŸ©ğŸŸ©ğŸŸ©  â”‚                                    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  å®ä¾‹åˆ†å‰² (Instance Segmentation)                        â”‚
    â”‚  - æ£€æµ‹ + åˆ†å‰²                                           â”‚
    â”‚  - åŒºåˆ†åŒç±»ç‰©ä½“çš„ä¸åŒå®ä¾‹                                 â”‚
    â”‚                                                         â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
    â”‚  â”‚ ğŸŸ¦ğŸŸ¦ğŸŸ¦ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©  â”‚                                    â”‚
    â”‚  â”‚ ğŸŸ©ğŸ”´ğŸ”´ğŸ”´ğŸŸ¡ğŸŸ©ğŸŸ©  â”‚  ğŸ”´=ç‹—1, ğŸŸ¡=ç‹—2                    â”‚
    â”‚  â”‚ ğŸŸ©ğŸŸ©ğŸ”´ğŸ”´ğŸŸ¡ğŸŸ¡ğŸŸ©  â”‚  (åŒºåˆ†ä¸åŒä¸ªä½“)                    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  å…¨æ™¯åˆ†å‰² (Panoptic Segmentation)                        â”‚
    â”‚  - è¯­ä¹‰åˆ†å‰² + å®ä¾‹åˆ†å‰²                                   â”‚
    â”‚  - å¯¹æ‰€æœ‰åƒç´ åˆ†ç±»ï¼Œå¹¶åŒºåˆ†å¯æ•°ç‰©ä½“çš„å®ä¾‹                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è¯­ä¹‰åˆ†å‰²åº”ç”¨ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. è‡ªåŠ¨é©¾é©¶: é“è·¯ã€è½¦è¾†ã€è¡Œäººåˆ†å‰²                         â”‚
    â”‚ 2. åŒ»å­¦å½±åƒ: å™¨å®˜ã€ç—…å˜åŒºåŸŸåˆ†å‰²                           â”‚
    â”‚ 3. å«æ˜Ÿå›¾åƒ: åœŸåœ°åˆ©ç”¨åˆ†ç±»                                â”‚
    â”‚ 4. å›¾åƒç¼–è¾‘: èƒŒæ™¯ç§»é™¤ã€ç‰©ä½“é€‰æ‹©                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šFCN æ¶æ„ ====================


def fcn_architecture():
    """FCN æ¶æ„"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šFCN (Fully Convolutional Network)")
    print("=" * 60)

    print("""
FCN æ ¸å¿ƒæ€æƒ³ï¼š

    å°†å…¨è¿æ¥å±‚æ›¿æ¢ä¸ºå·ç§¯å±‚ï¼Œå®ç°å¯†é›†é¢„æµ‹

    ä¼ ç»Ÿ CNN (ç”¨äºåˆ†ç±»):
    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”
    â”‚ Conv â”‚ â†’ â”‚ Conv â”‚ â†’ â”‚  FC  â”‚ â†’ ç±»åˆ«
    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜
                              â†‘
                           å±•å¹³ (ä¸§å¤±ç©ºé—´ä¿¡æ¯)

    FCN (ç”¨äºåˆ†å‰²):
    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”
    â”‚ Conv â”‚ â†’ â”‚ Conv â”‚ â†’ â”‚ Conv  â”‚ â†’ â”‚ä¸Šé‡‡æ ·â”‚ â†’ åˆ†å‰²å›¾
    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜
                           (1Ã—1 å·ç§¯)
                           ä¿ç•™ç©ºé—´ä¿¡æ¯

FCN å˜ä½“ï¼š

    FCN-32s: ç›´æ¥ 32 å€ä¸Šé‡‡æ · (ç²—ç³™)
    FCN-16s: èåˆ pool4 ç‰¹å¾ï¼Œ16 å€ä¸Šé‡‡æ ·
    FCN-8s:  èåˆ pool3+pool4 ç‰¹å¾ï¼Œ8 å€ä¸Šé‡‡æ · (æœ€ç²¾ç»†)

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  FCN-8s ç»“æ„:                                           â”‚
    â”‚                                                         â”‚
    â”‚  è¾“å…¥ â†’ Conv1 â†’ Pool1 â†’ Conv2 â†’ Pool2 â†’ Conv3 â†’ Pool3   â”‚
    â”‚                                              â†“   â”€â”€â”€â”€â†’  â”‚
    â”‚  Conv4 â†’ Pool4 â†’ Conv5 â†’ Pool5 â†’ FC6 â†’ FC7 â†’ èåˆ      â”‚
    â”‚           â†“â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’     â†“          â”‚
    â”‚                                           8å€ä¸Šé‡‡æ ·     â”‚
    â”‚                                              â†“          â”‚
    â”‚                                           è¾“å‡ºåˆ†å‰²å›¾     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    # FCN ç®€åŒ–å®ç°
    print("ç¤ºä¾‹: ç®€åŒ–çš„ FCN å®ç°\n")

    class SimpleFCN(nn.Module):
        """ç®€åŒ–çš„ FCN ç”¨äºç†è§£æ¦‚å¿µ"""

        def __init__(self, num_classes=21):
            super().__init__()

            # ç¼–ç å™¨ (ä½¿ç”¨ VGG é£æ ¼)
            self.conv1 = nn.Sequential(
                nn.Conv2d(3, 64, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(64, 64, 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2, 2),
            )

            self.conv2 = nn.Sequential(
                nn.Conv2d(64, 128, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(128, 128, 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2, 2),
            )

            self.conv3 = nn.Sequential(
                nn.Conv2d(128, 256, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(256, 256, 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2, 2),
            )

            # 1Ã—1 å·ç§¯æ›¿ä»£ FC
            self.classifier = nn.Conv2d(256, num_classes, 1)

            # ä¸Šé‡‡æ ·
            self.upsample = nn.Upsample(
                scale_factor=8, mode="bilinear", align_corners=True
            )

        def forward(self, x):
            x = self.conv1(x)  # 1/2
            x = self.conv2(x)  # 1/4
            x = self.conv3(x)  # 1/8
            x = self.classifier(x)  # åˆ†ç±»
            x = self.upsample(x)  # æ¢å¤åˆ†è¾¨ç‡
            return x

    model = SimpleFCN(num_classes=21)
    x = torch.randn(1, 3, 256, 256)
    out = model(x)
    print(f"è¾“å…¥: {x.shape}")
    print(f"è¾“å‡º: {out.shape}  (æ¯ä¸ªåƒç´  21 ç±»)")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šç¼–ç å™¨-è§£ç å™¨æ¶æ„ ====================


def encoder_decoder():
    """ç¼–ç å™¨-è§£ç å™¨æ¶æ„"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šç¼–ç å™¨-è§£ç å™¨æ¶æ„")
    print("=" * 60)

    print("""
ç¼–ç å™¨-è§£ç å™¨ (Encoder-Decoder)ï¼š

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                         â”‚
    â”‚  è¾“å…¥                                              è¾“å‡º  â”‚
    â”‚  HÃ—W                                               HÃ—W  â”‚
    â”‚    â”‚                                                â†‘   â”‚
    â”‚    â–¼                                                â”‚   â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”                                          â”Œâ”€â”€â”€â”€â” â”‚
    â”‚  â”‚    â”‚    ç¼–ç å™¨                      è§£ç å™¨    â”‚    â”‚ â”‚
    â”‚  â”‚    â”‚   (ä¸‹é‡‡æ ·)                   (ä¸Šé‡‡æ ·)    â”‚    â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”˜                                          â””â”€â”€â”€â”€â”˜ â”‚
    â”‚    â”‚                                                â†‘   â”‚
    â”‚    â–¼                                                â”‚   â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”                                          â”Œâ”€â”€â”€â”€â” â”‚
    â”‚  â”‚    â”‚                                          â”‚    â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”˜                                          â””â”€â”€â”€â”€â”˜ â”‚
    â”‚    â”‚                                                â†‘   â”‚
    â”‚    â–¼                                                â”‚   â”‚
    â”‚  â”Œâ”€â”€â”€â”€â” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”Œâ”€â”€â”€â”€â” â”‚
    â”‚  â”‚    â”‚              ç“¶é¢ˆå±‚                       â”‚    â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”˜                                          â””â”€â”€â”€â”€â”˜ â”‚
    â”‚                                                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç¼–ç å™¨ä½œç”¨:
    - é€æ­¥é™ä½ç©ºé—´åˆ†è¾¨ç‡
    - å¢åŠ é€šé“æ•°
    - æå–é«˜çº§è¯­ä¹‰ç‰¹å¾

è§£ç å™¨ä½œç”¨:
    - é€æ­¥æ¢å¤ç©ºé—´åˆ†è¾¨ç‡
    - å‡å°‘é€šé“æ•°
    - ç”Ÿæˆç²¾ç»†çš„åˆ†å‰²å›¾

ä¸Šé‡‡æ ·æ–¹æ³•ï¼š

    1. è½¬ç½®å·ç§¯ (Transposed Convolution)
       - å¯å­¦ä¹ çš„ä¸Šé‡‡æ ·
       - å¯èƒ½äº§ç”Ÿæ£‹ç›˜æ•ˆåº”

    2. åŒçº¿æ€§æ’å€¼ + å·ç§¯
       - å…ˆæ’å€¼æ”¾å¤§ï¼Œå†å·ç§¯
       - æ›´å¹³æ»‘

    3. åæ± åŒ– (Unpooling)
       - è®°å½•æ± åŒ–ä½ç½®ï¼Œåœ¨ç›¸åº”ä½ç½®æ¢å¤
    """)

    # è½¬ç½®å·ç§¯ç¤ºä¾‹
    print("ç¤ºä¾‹: è½¬ç½®å·ç§¯ä¸Šé‡‡æ ·\n")

    upsample = nn.ConvTranspose2d(
        in_channels=256,
        out_channels=128,
        kernel_size=2,
        stride=2,  # 2å€ä¸Šé‡‡æ ·
    )

    x = torch.randn(1, 256, 16, 16)
    out = upsample(x)
    print(f"è¾“å…¥: {x.shape}")
    print(f"è½¬ç½®å·ç§¯å: {out.shape}")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šåˆ†å‰²æŸå¤±å‡½æ•° ====================


def segmentation_losses():
    """åˆ†å‰²æŸå¤±å‡½æ•°"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šåˆ†å‰²æŸå¤±å‡½æ•°")
    print("=" * 60)

    print("""
å¸¸ç”¨åˆ†å‰²æŸå¤±å‡½æ•°ï¼š

    1. äº¤å‰ç†µæŸå¤± (Cross Entropy Loss)
       - é€åƒç´ åˆ†ç±»
       - é—®é¢˜: ç±»åˆ«ä¸å¹³è¡¡æ—¶æ•ˆæœå·®

    2. Dice Loss
       - åŸºäº Dice ç³»æ•°
       - å¯¹ç±»åˆ«ä¸å¹³è¡¡æ›´é²æ£’
       - å…¬å¼: Dice = 2|Aâˆ©B| / (|A|+|B|)

    3. ç»„åˆæŸå¤±
       - CE Loss + Dice Loss
       - å…¼é¡¾åƒç´ çº§å‡†ç¡®å’ŒåŒºåŸŸé‡å 
    """)

    # Dice Loss å®ç°
    print("ç¤ºä¾‹: Dice Loss å®ç°\n")

    class DiceLoss(nn.Module):
        """Dice Loss for segmentation"""

        def __init__(self, smooth=1e-5):
            super().__init__()
            self.smooth = smooth

        def forward(self, pred, target):
            """
            Args:
                pred: [B, C, H, W] é¢„æµ‹ (softmax å)
                target: [B, C, H, W] æ ‡ç­¾ (one-hot)
            """
            # å±•å¹³
            pred_flat = pred.view(-1)
            target_flat = target.view(-1)

            # è®¡ç®— Dice
            intersection = (pred_flat * target_flat).sum()
            union = pred_flat.sum() + target_flat.sum()

            dice = (2 * intersection + self.smooth) / (union + self.smooth)

            return 1 - dice

    class FocalLoss(nn.Module):
        """Focal Loss - å¤„ç†ç±»åˆ«ä¸å¹³è¡¡"""

        def __init__(self, alpha=0.25, gamma=2):
            super().__init__()
            self.alpha = alpha
            self.gamma = gamma

        def forward(self, pred, target):
            ce_loss = F.cross_entropy(pred, target, reduction="none")
            pt = torch.exp(-ce_loss)
            focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
            return focal_loss.mean()

    # æ¼”ç¤º
    pred = torch.softmax(torch.randn(2, 3, 64, 64), dim=1)
    target = torch.zeros(2, 3, 64, 64)
    target[:, 0, :32, :32] = 1
    target[:, 1, :32, 32:] = 1
    target[:, 2, 32:, :] = 1

    dice_loss = DiceLoss()
    loss = dice_loss(pred, target)
    print(f"Dice Loss: {loss.item():.4f}")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šé¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨ ====================


def pretrained_models():
    """é¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šä½¿ç”¨é¢„è®­ç»ƒåˆ†å‰²æ¨¡å‹")
    print("=" * 60)

    print("ç¤ºä¾‹: DeepLabV3\n")

    try:
        from torchvision.models.segmentation import deeplabv3_resnet50

        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model = deeplabv3_resnet50(pretrained=True)
        model.eval()

        print("DeepLabV3-ResNet50 åŠ è½½æˆåŠŸ!")

        # æ¨ç†
        x = torch.randn(1, 3, 512, 512)
        with torch.no_grad():
            output = model(x)

        print(f"\nè¾“å…¥: {x.shape}")
        print(f"è¾“å‡ºé”®: {output.keys()}")
        print(f"åˆ†å‰²å›¾: {output['out'].shape}")
        print("  â†’ 21 ç±» (PASCAL VOC)")

        # è·å–é¢„æµ‹ç±»åˆ«
        pred = output["out"].argmax(dim=1)
        print(f"é¢„æµ‹ç±»åˆ«å›¾: {pred.shape}")

    except Exception as e:
        print(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")

    print("""
å¸¸ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼š

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  æ¨¡å‹           Backbone      mIoU    ç‰¹ç‚¹              â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  FCN            VGG/ResNet    ~65%    ç»å…¸åŸºå‡†          â”‚
    â”‚  DeepLabV3      ResNet        ~78%    ç©ºæ´å·ç§¯+ASPP     â”‚
    â”‚  DeepLabV3+     Xception      ~82%    ç¼–ç å™¨-è§£ç å™¨     â”‚
    â”‚  PSPNet         ResNet        ~80%    é‡‘å­—å¡”æ± åŒ–        â”‚
    â”‚  UNet           -             ~76%    åŒ»å­¦å›¾åƒå¸¸ç”¨       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šè¯„ä¼°æŒ‡æ ‡ ====================


def evaluation_metrics():
    """è¯„ä¼°æŒ‡æ ‡"""
    print("\n" + "=" * 60)
    print("ç¬¬å…­éƒ¨åˆ†ï¼šåˆ†å‰²è¯„ä¼°æŒ‡æ ‡")
    print("=" * 60)

    print("""
å¸¸ç”¨è¯„ä¼°æŒ‡æ ‡ï¼š

    1. Pixel Accuracy (åƒç´ å‡†ç¡®ç‡)
       PA = æ­£ç¡®åˆ†ç±»çš„åƒç´ æ•° / æ€»åƒç´ æ•°

    2. Mean IoU (å¹³å‡äº¤å¹¶æ¯”)
       mIoU = (1/C) * Î£ (TP_i / (TP_i + FP_i + FN_i))

    3. Dice Score
       Dice = 2 * |Aâˆ©B| / (|A| + |B|)
    """)

    def compute_miou(pred, target, num_classes):
        """è®¡ç®— mIoU"""
        ious = []
        for cls in range(num_classes):
            pred_cls = (pred == cls).float()
            target_cls = (target == cls).float()

            intersection = (pred_cls * target_cls).sum()
            union = pred_cls.sum() + target_cls.sum() - intersection

            if union > 0:
                iou = intersection / union
                ious.append(iou.item())

        return np.mean(ious) if ious else 0

    # ç¤ºä¾‹
    pred = torch.randint(0, 5, (1, 256, 256))
    target = torch.randint(0, 5, (1, 256, 256))
    miou = compute_miou(pred, target, num_classes=5)
    print(f"mIoU: {miou:.4f}")


# ==================== ç¬¬ä¸ƒéƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    exercises_text = """
ç»ƒä¹  1ï¼šFCN å®ç°
    ä»»åŠ¡: å®ç°å®Œæ•´çš„ FCN-8s
    åŒ…å«: pool3, pool4 çš„è·³è·ƒè¿æ¥

ç»ƒä¹  1 ç­”æ¡ˆï¼š
    class FCN8s(nn.Module):
        def __init__(self, num_classes=21):
            super().__init__()
            # ä½¿ç”¨ VGG16 ä½œä¸º backbone
            vgg = torchvision.models.vgg16(pretrained=True)
            features = list(vgg.features.children())
            
            # åˆ†å‰²æˆä¸åŒé˜¶æ®µ
            self.pool3 = nn.Sequential(*features[:17])  # åˆ° pool3
            self.pool4 = nn.Sequential(*features[17:24])  # åˆ° pool4
            self.pool5 = nn.Sequential(*features[24:])  # åˆ° pool5
            
            # FC å±‚è½¬ä¸ºå·ç§¯
            self.fc6 = nn.Conv2d(512, 4096, 7, padding=3)
            self.fc7 = nn.Conv2d(4096, 4096, 1)
            self.score_fr = nn.Conv2d(4096, num_classes, 1)
            
            # è·³è·ƒè¿æ¥
            self.score_pool4 = nn.Conv2d(512, num_classes, 1)
            self.score_pool3 = nn.Conv2d(256, num_classes, 1)
            
            # ä¸Šé‡‡æ ·
            self.upscore2 = nn.ConvTranspose2d(num_classes, num_classes, 4, 2, 1)
            self.upscore4 = nn.ConvTranspose2d(num_classes, num_classes, 4, 2, 1)
            self.upscore8 = nn.ConvTranspose2d(num_classes, num_classes, 16, 8, 4)
        
        def forward(self, x):
            pool3 = self.pool3(x)          # 1/8
            pool4 = self.pool4(pool3)      # 1/16
            pool5 = self.pool5(pool4)      # 1/32
            
            fc = F.relu(self.fc6(pool5))
            fc = F.relu(self.fc7(fc))
            score = self.score_fr(fc)
            
            # èåˆ pool4
            upscore2 = self.upscore2(score)
            score_pool4 = self.score_pool4(pool4)
            fuse1 = upscore2 + score_pool4
            
            # èåˆ pool3
            upscore4 = self.upscore4(fuse1)
            score_pool3 = self.score_pool3(pool3)
            fuse2 = upscore4 + score_pool3
            
            # 8å€ä¸Šé‡‡æ ·åˆ°åŸå›¾
            out = self.upscore8(fuse2)
            return out

ç»ƒä¹  2ï¼šåˆ†å‰²å¯è§†åŒ–
    ä»»åŠ¡: ä½¿ç”¨ DeepLabV3 åˆ†å‰²å›¾åƒ
    è¦æ±‚: å°†åˆ†å‰²ç»“æœå½©è‰²å¯è§†åŒ–

ç»ƒä¹  2 ç­”æ¡ˆï¼š
    import torch
    import numpy as np
    import matplotlib.pyplot as plt
    from PIL import Image
    from torchvision import transforms
    from torchvision.models.segmentation import deeplabv3_resnet50
    
    # VOC è°ƒè‰²æ¿
    def get_voc_palette(num_classes=21):
        palette = np.zeros((num_classes, 3), dtype=np.uint8)
        for i in range(num_classes):
            r = g = b = 0
            c = i
            for j in range(8):
                r |= (((c >> 0) & 1) << (7 - j))
                g |= (((c >> 1) & 1) << (7 - j))
                b |= (((c >> 2) & 1) << (7 - j))
                c >>= 3
            palette[i] = [r, g, b]
        return palette
    
    # åŠ è½½æ¨¡å‹
    model = deeplabv3_resnet50(pretrained=True).eval()
    
    # é¢„å¤„ç†
    image = Image.open('image.jpg')
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    input_tensor = transform(image).unsqueeze(0)
    
    # æ¨ç†
    with torch.no_grad():
        output = model(input_tensor)['out']
    pred = output.argmax(1).squeeze().numpy()
    
    # å½©è‰²å¯è§†åŒ–
    palette = get_voc_palette()
    colored = palette[pred]
    
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(image)
    plt.title('Original')
    plt.subplot(1, 2, 2)
    plt.imshow(colored)
    plt.title('Segmentation')
    plt.savefig('segmentation_result.png')

ç»ƒä¹  3ï¼šè‡ªå®šä¹‰æ•°æ®é›†
    ä»»åŠ¡: åˆ¶ä½œä¸€ä¸ªç®€å•çš„åˆ†å‰²æ•°æ®é›†
    ä½¿ç”¨: æ ‡æ³¨å·¥å…·å¦‚ labelme

ç»ƒä¹  3 ç­”æ¡ˆï¼š
    # 1. ä½¿ç”¨ labelme æ ‡æ³¨
    # pip install labelme
    # labelme  # å¯åŠ¨ GUI
    
    # 2. å°† JSON è½¬æ¢ä¸ºæ©ç 
    import json
    import numpy as np
    from PIL import Image, ImageDraw
    
    def json_to_mask(json_path, output_path):
        with open(json_path) as f:
            data = json.load(f)
        
        h, w = data['imageHeight'], data['imageWidth']
        mask = np.zeros((h, w), dtype=np.uint8)
        
        for shape in data['shapes']:
            label = shape['label']
            points = shape['points']
            
            # åˆ›å»ºå¤šè¾¹å½¢æ©ç 
            img = Image.new('L', (w, h), 0)
            ImageDraw.Draw(img).polygon([tuple(p) for p in points],
                                         outline=1, fill=1)
            mask = np.maximum(mask, np.array(img) * label_to_id[label])
        
        Image.fromarray(mask).save(output_path)
    
    # 3. åˆ›å»ºæ•°æ®é›†ç±»
    class SegmentationDataset(torch.utils.data.Dataset):
        def __init__(self, image_dir, mask_dir, transform=None):
            self.images = sorted(glob.glob(f'{image_dir}/*.jpg'))
            self.masks = sorted(glob.glob(f'{mask_dir}/*.png'))
            self.transform = transform
        
        def __getitem__(self, idx):
            image = Image.open(self.images[idx]).convert('RGB')
            mask = Image.open(self.masks[idx])
            
            if self.transform:
                image = self.transform(image)
            mask = torch.from_numpy(np.array(mask)).long()
            
            return image, mask

ç»ƒä¹  4ï¼šæŸå¤±å‡½æ•°å¯¹æ¯”
    ä»»åŠ¡: å¯¹æ¯” CE Loss å’Œ Dice Loss
    åœºæ™¯: ç±»åˆ«æåº¦ä¸å¹³è¡¡çš„æ•°æ®

ç»ƒä¹  4 ç­”æ¡ˆï¼š
    import torch
    import torch.nn.functional as F
    
    # æ¨¡æ‹Ÿä¸å¹³è¡¡æ•°æ® (å‰æ™¯åªå  5%)
    pred = torch.randn(1, 2, 256, 256)  # 2 ç±»
    target = torch.zeros(1, 256, 256).long()
    target[0, 100:120, 100:120] = 1  # å°åŒºåŸŸå‰æ™¯
    
    # CE Loss
    ce_loss = F.cross_entropy(pred, target)
    
    # Dice Loss
    def dice_loss(pred, target, smooth=1e-5):
        pred = F.softmax(pred, dim=1)[:, 1]  # å‰æ™¯æ¦‚ç‡
        target_float = target.float()
        
        intersection = (pred * target_float).sum()
        union = pred.sum() + target_float.sum()
        
        dice = (2 * intersection + smooth) / (union + smooth)
        return 1 - dice
    
    dice = dice_loss(pred, target)
    
    # ç»„åˆæŸå¤±
    combined = 0.5 * ce_loss + 0.5 * dice
    
    print(f'CE Loss: {ce_loss:.4f}')
    print(f'Dice Loss: {dice:.4f}')
    
    # Dice Loss å¯¹ä¸å¹³è¡¡æ•°æ®æ›´æ•æ„Ÿ
    # å› ä¸ºå®ƒç›´æ¥ä¼˜åŒ–åŒºåŸŸé‡å 

ç»ƒä¹  5ï¼šè¯­ä¹‰åˆ†å‰²åº”ç”¨
    ä»»åŠ¡: å®ç°èƒŒæ™¯æ›¿æ¢åŠŸèƒ½
    æµç¨‹: åˆ†å‰²å‰æ™¯ â†’ æå– â†’ åˆæˆæ–°èƒŒæ™¯

ç»ƒä¹  5 ç­”æ¡ˆï¼š
    import torch
    import numpy as np
    from PIL import Image
    from torchvision import transforms
    from torchvision.models.segmentation import deeplabv3_resnet50
    
    def replace_background(image_path, bg_path, output_path):
        # åŠ è½½æ¨¡å‹
        model = deeplabv3_resnet50(pretrained=True).eval()
        
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        background = Image.open(bg_path).convert('RGB')
        background = background.resize(image.size)
        
        # é¢„å¤„ç†
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        # åˆ†å‰²
        with torch.no_grad():
            output = model(transform(image).unsqueeze(0))['out']
        mask = output.argmax(1).squeeze().numpy()
        
        # äººç‰©ç±»åˆ« = 15 (PASCAL VOC)
        person_mask = (mask == 15).astype(np.float32)
        
        # å¹³æ»‘è¾¹ç¼˜ (å¯é€‰)
        from scipy.ndimage import gaussian_filter
        person_mask = gaussian_filter(person_mask, sigma=2)
        
        # åˆæˆ
        image_np = np.array(image) / 255.0
        bg_np = np.array(background) / 255.0
        
        mask_3d = np.stack([person_mask] * 3, axis=-1)
        result = image_np * mask_3d + bg_np * (1 - mask_3d)
        
        result = (result * 255).astype(np.uint8)
        Image.fromarray(result).save(output_path)

æ€è€ƒé¢˜ 1ï¼šä¸ºä»€ä¹ˆéœ€è¦è·³è·ƒè¿æ¥ï¼Ÿ
    æ²¡æœ‰è·³è·ƒè¿æ¥ä¼šæ€æ ·ï¼Ÿ

æ€è€ƒé¢˜ 1 ç­”æ¡ˆï¼š
    ä¸ºä»€ä¹ˆéœ€è¦è·³è·ƒè¿æ¥ï¼š
    - ä¸‹é‡‡æ ·è¿‡ç¨‹ä¸­ä¸¢å¤±ç©ºé—´ç»†èŠ‚ä¿¡æ¯
    - æ·±å±‚ç‰¹å¾æœ‰è¯­ä¹‰ä¿¡æ¯ä½†åˆ†è¾¨ç‡ä½
    - æµ…å±‚ç‰¹å¾æœ‰ç»†èŠ‚ä¿¡æ¯ä½†è¯­ä¹‰å¼±
    
    æ²¡æœ‰è·³è·ƒè¿æ¥çš„é—®é¢˜ï¼š
    - è¾¹ç•Œæ¨¡ç³Šä¸æ¸…æ™°
    - å°ç‰©ä½“å®¹æ˜“ä¸¢å¤±
    - ç©ºé—´ä½ç½®ä¸ç²¾ç¡®
    
    è·³è·ƒè¿æ¥çš„ä½œç”¨ï¼š
    - å°†æµ…å±‚çš„é«˜åˆ†è¾¨ç‡ç‰¹å¾ä¼ é€’ç»™è§£ç å™¨
    - å¸®åŠ©æ¢å¤ç²¾ç¡®çš„è¾¹ç•Œ
    - èåˆå¤šå°ºåº¦ä¿¡æ¯

æ€è€ƒé¢˜ 2ï¼šç©ºæ´å·ç§¯ (Dilated Conv) çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ
    DeepLab ä¸ºä»€ä¹ˆä½¿ç”¨ç©ºæ´å·ç§¯ï¼Ÿ

æ€è€ƒé¢˜ 2 ç­”æ¡ˆï¼š
    ç©ºæ´å·ç§¯çš„ä½œç”¨ï¼š
    - åœ¨ä¸å¢åŠ å‚æ•°çš„æƒ…å†µä¸‹æ‰©å¤§æ„Ÿå—é‡
    - ä¿æŒç©ºé—´åˆ†è¾¨ç‡ä¸å˜
    
    æ™®é€šå·ç§¯ vs ç©ºæ´å·ç§¯ï¼š
    - 3x3 æ™®é€šå·ç§¯: æ„Ÿå—é‡ 3x3
    - 3x3 ç©ºæ´å·ç§¯ (rate=2): æ„Ÿå—é‡ 5x5
    - 3x3 ç©ºæ´å·ç§¯ (rate=3): æ„Ÿå—é‡ 7x7
    
    DeepLab ä½¿ç”¨ç©ºæ´å·ç§¯çš„åŸå› ï¼š
    1. å‡å°‘ä¸‹é‡‡æ ·æ¬¡æ•°ï¼Œä¿æŒé«˜åˆ†è¾¨ç‡
    2. ä¸éœ€è¦å¤§é‡ä¸Šé‡‡æ ·æ¢å¤åˆ†è¾¨ç‡
    3. ASPP ä½¿ç”¨ä¸åŒ rate æ•è·å¤šå°ºåº¦ä¸Šä¸‹æ–‡
    
    ASPP (Atrous Spatial Pyramid Pooling):
    - å¹¶è¡Œä½¿ç”¨ä¸åŒ rate çš„ç©ºæ´å·ç§¯
    - èåˆå¤šå°ºåº¦ç‰¹å¾

æ€è€ƒé¢˜ 3ï¼šè¯­ä¹‰åˆ†å‰²å’Œå®ä¾‹åˆ†å‰²çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ
    å¦‚ä½•ä»è¯­ä¹‰åˆ†å‰²æ‰©å±•åˆ°å®ä¾‹åˆ†å‰²ï¼Ÿ

æ€è€ƒé¢˜ 3 ç­”æ¡ˆï¼š
    è¯­ä¹‰åˆ†å‰² vs å®ä¾‹åˆ†å‰²ï¼š
    
    è¯­ä¹‰åˆ†å‰²ï¼š
    - åªåˆ†ç±»æ¯ä¸ªåƒç´ å±äºå“ªä¸ªç±»åˆ«
    - ä¸åŒºåˆ†åŒç±»çš„ä¸åŒå®ä¾‹
    - è¾“å‡º: HÃ—WÃ—C (one-hot) æˆ– HÃ—W (ç±»åˆ«ç´¢å¼•)
    
    å®ä¾‹åˆ†å‰²ï¼š
    - éœ€è¦åŒºåˆ†æ¯ä¸ªç‹¬ç«‹çš„å®ä¾‹
    - åŒç±»çš„ä¸åŒç‰©ä½“æœ‰ä¸åŒæ ‡ç­¾
    - è¾“å‡º: æ¯ä¸ªå®ä¾‹ä¸€ä¸ªæ©ç 
    
    ä»è¯­ä¹‰åˆ†å‰²æ‰©å±•åˆ°å®ä¾‹åˆ†å‰²ï¼š
    1. Mask R-CNN æ–¹æ³•
       - å…ˆæ£€æµ‹æ¯ä¸ªå®ä¾‹çš„è¾¹ç•Œæ¡†
       - å†å¯¹æ¯ä¸ª RoI è¿›è¡Œåˆ†å‰²
    
    2. è‡ªåº•å‘ä¸Šæ–¹æ³•
       - è¯­ä¹‰åˆ†å‰² + å®ä¾‹åµŒå…¥
       - èšç±»ç›¸è¿‘çš„åƒç´ å½¢æˆå®ä¾‹
    
    3. å…¨æ™¯åˆ†å‰²
       - ç»“åˆè¯­ä¹‰åˆ†å‰²å’Œå®ä¾‹åˆ†å‰²
       - å¯¹"stuff"ç”¨è¯­ä¹‰åˆ†å‰²
       - å¯¹"things"ç”¨å®ä¾‹åˆ†å‰²
    """
    print(exercises_text)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    introduction()
    fcn_architecture()
    encoder_decoder()
    segmentation_losses()
    pretrained_models()
    evaluation_metrics()
    exercises()

    print("\n" + "=" * 60)
    print("è¯¾ç¨‹å®Œæˆï¼")
    print("=" * 60)
    print("""
ä¸‹ä¸€æ­¥å­¦ä¹ ï¼š
    - 05-unet.py: U-Net æ¶æ„è¯¦è§£

å…³é”®è¦ç‚¹å›é¡¾ï¼š
    âœ“ è¯­ä¹‰åˆ†å‰²å¯¹æ¯ä¸ªåƒç´ è¿›è¡Œåˆ†ç±»
    âœ“ FCN ç”¨å·ç§¯æ›¿ä»£å…¨è¿æ¥ï¼Œä¿ç•™ç©ºé—´ä¿¡æ¯
    âœ“ ç¼–ç å™¨-è§£ç å™¨æ¶æ„å…ˆä¸‹é‡‡æ ·åä¸Šé‡‡æ ·
    âœ“ Dice Loss å¯¹ç±»åˆ«ä¸å¹³è¡¡æ›´é²æ£’
    âœ“ mIoU æ˜¯ä¸»è¦è¯„ä¼°æŒ‡æ ‡
    """)


if __name__ == "__main__":
    main()
