"""
äººè„¸è¯†åˆ« (Face Recognition)
============================

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£äººè„¸è¯†åˆ«ç³»ç»Ÿçš„å®Œæ•´æµç¨‹
    2. æŒæ¡äººè„¸æ£€æµ‹ã€å¯¹é½ã€ç‰¹å¾æå–
    3. äº†è§£å¸¸ç”¨çš„äººè„¸è¯†åˆ«æŸå¤±å‡½æ•°
    4. ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œäººè„¸è¯†åˆ«

æ ¸å¿ƒæ¦‚å¿µï¼š
    - äººè„¸æ£€æµ‹: å®šä½å›¾åƒä¸­çš„äººè„¸
    - äººè„¸å¯¹é½: æ ‡å‡†åŒ–äººè„¸å§¿æ€
    - ç‰¹å¾æå–: å°†äººè„¸æ˜ å°„ä¸ºç‰¹å¾å‘é‡
    - ç‰¹å¾åŒ¹é…: æ¯”è¾ƒä¸¤å¼ äººè„¸çš„ç›¸ä¼¼åº¦

å‰ç½®çŸ¥è¯†ï¼š
    - Phase 5: CNN
    - ç›®æ ‡æ£€æµ‹åŸºç¡€
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šäººè„¸è¯†åˆ«æ¦‚è¿° ====================


def introduction():
    """äººè„¸è¯†åˆ«æ¦‚è¿°"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šäººè„¸è¯†åˆ«æ¦‚è¿°")
    print("=" * 60)

    print("""
äººè„¸è¯†åˆ«ç³»ç»Ÿæµç¨‹ï¼š

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  è¾“å…¥å›¾åƒ â†’ äººè„¸æ£€æµ‹ â†’ äººè„¸å¯¹é½ â†’ ç‰¹å¾æå– â†’ ç‰¹å¾åŒ¹é…     â”‚
    â”‚      â†“          â†“          â†“          â†“          â†“     â”‚
    â”‚    ğŸ“·        ğŸ”²         ğŸ”„        ğŸ“Š        âœ“/âœ—    â”‚
    â”‚    å›¾åƒ    å®šä½äººè„¸    æ ‡å‡†åŒ–    512ç»´å‘é‡   å¯¹æ¯”å†³ç­–   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä»»åŠ¡åˆ†ç±»ï¼š

    1. äººè„¸éªŒè¯ (Face Verification) - 1:1
       é—®é¢˜: è¿™ä¸¤å¼ æ˜¯åŒä¸€ä¸ªäººå—ï¼Ÿ
       åº”ç”¨: æ‰‹æœºè§£é”ã€é—¨ç¦ç³»ç»Ÿ

    2. äººè„¸è¯†åˆ« (Face Identification) - 1:N
       é—®é¢˜: è¿™ä¸ªäººæ˜¯è°ï¼Ÿ
       åº”ç”¨: è€ƒå‹¤ç³»ç»Ÿã€å«Œç–‘äººæœç´¢

    3. äººè„¸èšç±» (Face Clustering)
       é—®é¢˜: è¿™äº›äººè„¸å¯ä»¥åˆ†æˆå‡ ç»„ï¼Ÿ
       åº”ç”¨: ç›¸å†Œæ•´ç†

ä¸»è¦æŒ‘æˆ˜ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. å…‰ç…§å˜åŒ–: ä¸åŒå…‰çº¿æ¡ä»¶ä¸‹å¤–è§‚å·®å¼‚å¤§                      â”‚
    â”‚ 2. å§¿æ€å˜åŒ–: æ­£é¢ã€ä¾§é¢å·®å¼‚å¤§                             â”‚
    â”‚ 3. è¡¨æƒ…å˜åŒ–: å¾®ç¬‘ã€å“­æ³£ç­‰è¡¨æƒ…å½±å“                         â”‚
    â”‚ 4. é®æŒ¡: çœ¼é•œã€å£ç½©ã€å¤´å‘é®æŒ¡                             â”‚
    â”‚ 5. å¹´é¾„å˜åŒ–: åŒä¸€äººä¸åŒå¹´é¾„å·®å¼‚å¤§                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šäººè„¸æ£€æµ‹ ====================


def face_detection():
    """äººè„¸æ£€æµ‹"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šäººè„¸æ£€æµ‹")
    print("=" * 60)

    print("""
å¸¸ç”¨äººè„¸æ£€æµ‹æ–¹æ³•ï¼š

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  æ–¹æ³•              ç‰¹ç‚¹                    é€Ÿåº¦/ç²¾åº¦       â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  Haar Cascade     ä¼ ç»Ÿæ–¹æ³•ï¼ŒCPUå¿«          â˜…â˜…â˜…/â˜…â˜…      â”‚
    â”‚  HOG + SVM        ä¼ ç»Ÿæ–¹æ³•                 â˜…â˜…â˜…/â˜…â˜…â˜…     â”‚
    â”‚  MTCNN            çº§è”CNNï¼Œæ£€æµ‹+å¯¹é½       â˜…â˜…/â˜…â˜…â˜…â˜…      â”‚
    â”‚  RetinaFace       å•é˜¶æ®µï¼Œç²¾åº¦é«˜           â˜…â˜…/â˜…â˜…â˜…â˜…â˜…     â”‚
    â”‚  YOLOv8-face      å¿«é€Ÿï¼Œé€‚åˆå®æ—¶           â˜…â˜…â˜…â˜…/â˜…â˜…â˜…â˜…   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MTCNN æµç¨‹ï¼š

    ä¸‰é˜¶æ®µçº§è”ç½‘ç»œ:

    è¾“å…¥å›¾åƒ
        â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   P-Net       â”‚ â†’ å¿«é€Ÿç­›é€‰å€™é€‰æ¡†
    â”‚  (Proposal)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   R-Net       â”‚ â†’ ç²¾ç»†ç­›é€‰
    â”‚  (Refine)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   O-Net       â”‚ â†’ è¾“å‡ºè¾¹ç•Œæ¡† + 5ä¸ªå…³é”®ç‚¹
    â”‚  (Output)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    5ä¸ªå…³é”®ç‚¹: å·¦çœ¼ã€å³çœ¼ã€é¼»å­ã€å·¦å˜´è§’ã€å³å˜´è§’
    """)

    print("ç¤ºä¾‹: ä½¿ç”¨ MTCNN æ£€æµ‹äººè„¸\n")
    print("""
# å®‰è£…: pip install facenet-pytorch

from facenet_pytorch import MTCNN

# åˆ›å»ºæ£€æµ‹å™¨
mtcnn = MTCNN(
    image_size=160,      # è¾“å‡ºäººè„¸å¤§å°
    margin=0,            # è¾¹ç¼˜æ‰©å±•
    keep_all=True,       # æ£€æµ‹æ‰€æœ‰äººè„¸
    device='cuda'
)

# æ£€æµ‹
boxes, probs, landmarks = mtcnn.detect(image, landmarks=True)

# boxes: [N, 4] è¾¹ç•Œæ¡†
# probs: [N] ç½®ä¿¡åº¦
# landmarks: [N, 5, 2] 5ä¸ªå…³é”®ç‚¹åæ ‡
    """)


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šäººè„¸å¯¹é½ ====================


def face_alignment():
    """äººè„¸å¯¹é½"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šäººè„¸å¯¹é½")
    print("=" * 60)

    print("""
äººè„¸å¯¹é½çš„ä½œç”¨ï¼š

    å°†ä¸åŒå§¿æ€çš„äººè„¸æ ‡å‡†åŒ–åˆ°ç»Ÿä¸€å§¿æ€

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  å¯¹é½å‰:                    å¯¹é½å:                      â”‚
    â”‚                                                         â”‚
    â”‚   ğŸ˜Š  ğŸ˜Š  ğŸ˜Š              ğŸ˜Š  ğŸ˜Š  ğŸ˜Š               â”‚
    â”‚  (å€¾æ–œ)(ä¾§é¢)(æ­£é¢)    â†’   (æ­£é¢)(æ­£é¢)(æ­£é¢)             â”‚
    â”‚                                                         â”‚
    â”‚  ä½¿ç”¨å…³é”®ç‚¹è¿›è¡Œä»¿å°„å˜æ¢                                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å¯¹é½æ­¥éª¤ï¼š

    1. æ£€æµ‹ 5 ä¸ªå…³é”®ç‚¹
       - å·¦çœ¼ä¸­å¿ƒã€å³çœ¼ä¸­å¿ƒã€é¼»å°–ã€å·¦å˜´è§’ã€å³å˜´è§’

    2. è®¡ç®—ç›®æ ‡ä½ç½®
       - æ ‡å‡†åŒ–çš„å…³é”®ç‚¹æ¨¡æ¿

    3. ä»¿å°„å˜æ¢
       - æ ¹æ®æºå’Œç›®æ ‡å…³é”®ç‚¹è®¡ç®—å˜æ¢çŸ©é˜µ
       - å¯¹å›¾åƒè¿›è¡Œå˜æ¢
    """)

    import cv2

    def align_face(image, landmarks, target_size=(112, 112)):
        """
        äººè„¸å¯¹é½

        Args:
            image: è¾“å…¥å›¾åƒ
            landmarks: 5ä¸ªå…³é”®ç‚¹ [(x1,y1), (x2,y2), ...]
            target_size: è¾“å‡ºå¤§å°
        """
        # æ ‡å‡†åŒ–çš„ç›®æ ‡å…³é”®ç‚¹ä½ç½® (112x112 å›¾åƒ)
        target_landmarks = np.float32(
            [
                [38.2946, 51.6963],  # å·¦çœ¼
                [73.5318, 51.5014],  # å³çœ¼
                [56.0252, 71.7366],  # é¼»å­
                [41.5493, 92.3655],  # å·¦å˜´è§’
                [70.7299, 92.2041],  # å³å˜´è§’
            ]
        )

        # æºå…³é”®ç‚¹
        src_landmarks = np.float32(landmarks)

        # è®¡ç®—ä»¿å°„å˜æ¢çŸ©é˜µ
        M = cv2.estimateAffinePartial2D(src_landmarks, target_landmarks)[0]

        # åº”ç”¨å˜æ¢
        aligned = cv2.warpAffine(image, M, target_size)

        return aligned

    print("äººè„¸å¯¹é½å‡½æ•°å®šä¹‰å®Œæˆ!")
    print("è¾“å…¥: å›¾åƒ + 5ä¸ªå…³é”®ç‚¹")
    print("è¾“å‡º: å¯¹é½åçš„ 112Ã—112 äººè„¸å›¾åƒ")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šç‰¹å¾æå– ====================


def feature_extraction():
    """ç‰¹å¾æå–"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šç‰¹å¾æå–")
    print("=" * 60)

    print("""
ç‰¹å¾æå–ç½‘ç»œï¼š

    å°†äººè„¸å›¾åƒæ˜ å°„ä¸ºå›ºå®šç»´åº¦çš„ç‰¹å¾å‘é‡ (embedding)

    è¾“å…¥: å¯¹é½åçš„äººè„¸å›¾åƒ (112Ã—112Ã—3)
    è¾“å‡º: ç‰¹å¾å‘é‡ (512ç»´)

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  å¸¸ç”¨ç½‘ç»œ:                                               â”‚
    â”‚                                                         â”‚
    â”‚  FaceNet (2015)                                         â”‚
    â”‚  - Inception-ResNet-v1                                  â”‚
    â”‚  - Triplet Loss è®­ç»ƒ                                    â”‚
    â”‚                                                         â”‚
    â”‚  ArcFace (2019)                                         â”‚
    â”‚  - ResNet å˜ä½“                                          â”‚
    â”‚  - ArcFace Loss è®­ç»ƒ                                    â”‚
    â”‚  - ç›®å‰æœ€ä½³æ€§èƒ½ä¹‹ä¸€                                      â”‚
    â”‚                                                         â”‚
    â”‚  CosFace (2018)                                         â”‚
    â”‚  - å¤§é—´éš”ä½™å¼¦æŸå¤±                                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç‰¹å¾å‘é‡ç‰¹ç‚¹ï¼š
    - å½’ä¸€åŒ–åˆ°å•ä½çƒé¢ä¸Š
    - åŒä¸€äººçš„ç‰¹å¾å‘é‡ç›¸ä¼¼
    - ä¸åŒäººçš„ç‰¹å¾å‘é‡åˆ†ç¦»
    """)

    print("ç¤ºä¾‹: ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æå–ç‰¹å¾\n")
    print("""
from facenet_pytorch import InceptionResnetV1

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ (vggface2 æˆ– casia-webface)
model = InceptionResnetV1(pretrained='vggface2').eval()

# æå–ç‰¹å¾
# face: [B, 3, 160, 160] å¯¹é½åçš„äººè„¸
embedding = model(face)  # [B, 512]

# L2 å½’ä¸€åŒ–
embedding = F.normalize(embedding, p=2, dim=1)
    """)


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šç‰¹å¾åŒ¹é… ====================


def feature_matching():
    """ç‰¹å¾åŒ¹é…"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šç‰¹å¾åŒ¹é…")
    print("=" * 60)

    print("""
ç‰¹å¾åŒ¹é…æ–¹æ³•ï¼š

    1. ä½™å¼¦ç›¸ä¼¼åº¦ (Cosine Similarity)
       sim = (a Â· b) / (||a|| Ã— ||b||)
       èŒƒå›´: [-1, 1]ï¼Œ1 è¡¨ç¤ºå®Œå…¨ç›¸åŒ

    2. æ¬§æ°è·ç¦» (Euclidean Distance)
       dist = ||a - b||â‚‚
       è·ç¦»è¶Šå°è¶Šç›¸ä¼¼

åŒ¹é…é˜ˆå€¼ï¼š
    - éªŒè¯: sim > threshold â†’ åŒä¸€äºº
    - å…¸å‹é˜ˆå€¼: 0.5-0.7 (æ ¹æ®åº”ç”¨è°ƒæ•´)
    """)

    def compare_faces(emb1, emb2, threshold=0.6):
        """æ¯”è¾ƒä¸¤å¼ äººè„¸"""
        # ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = F.cosine_similarity(emb1, emb2, dim=1)

        # æ¬§æ°è·ç¦»
        distance = torch.dist(emb1, emb2, p=2)

        is_same = similarity > threshold

        return {
            "similarity": similarity.item(),
            "distance": distance.item(),
            "is_same_person": is_same.item(),
        }

    def search_face(query_emb, database_embs, top_k=5):
        """
        åœ¨æ•°æ®åº“ä¸­æœç´¢æœ€ç›¸ä¼¼çš„äººè„¸

        Args:
            query_emb: [1, D] æŸ¥è¯¢ç‰¹å¾
            database_embs: [N, D] æ•°æ®åº“ç‰¹å¾
            top_k: è¿”å›å‰ k ä¸ªç»“æœ
        """
        # è®¡ç®—ä¸æ‰€æœ‰äººè„¸çš„ç›¸ä¼¼åº¦
        similarities = F.cosine_similarity(query_emb, database_embs)

        # è·å– top-k
        top_scores, top_indices = similarities.topk(top_k)

        return top_indices, top_scores

    # ç¤ºä¾‹
    print("ç¤ºä¾‹: äººè„¸åŒ¹é…\n")

    emb1 = F.normalize(torch.randn(1, 512), dim=1)
    emb2 = F.normalize(torch.randn(1, 512), dim=1)

    result = compare_faces(emb1, emb2)
    print(f"ä½™å¼¦ç›¸ä¼¼åº¦: {result['similarity']:.4f}")
    print(f"æ¬§æ°è·ç¦»: {result['distance']:.4f}")
    print(f"æ˜¯å¦åŒä¸€äºº: {result['is_same_person']}")


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šæŸå¤±å‡½æ•° ====================


def loss_functions():
    """æŸå¤±å‡½æ•°"""
    print("\n" + "=" * 60)
    print("ç¬¬å…­éƒ¨åˆ†ï¼šäººè„¸è¯†åˆ«æŸå¤±å‡½æ•°")
    print("=" * 60)

    print("""
ä¸»è¦æŸå¤±å‡½æ•°ï¼š

    1. Softmax Loss (äº¤å‰ç†µ)
       - ç®€å•åˆ†ç±»æŸå¤±
       - é—®é¢˜: ç‰¹å¾åˆ†ç¦»åº¦ä¸å¤Ÿ

    2. Triplet Loss
       - ä¸‰å…ƒç»„: (Anchor, Positive, Negative)
       - ç›®æ ‡: d(A,P) + margin < d(A,N)

       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚         Anchor (é”šç‚¹)                               â”‚
       â”‚           /     \\                                  â”‚
       â”‚          /       \\                                 â”‚
       â”‚    Positive      Negative                          â”‚
       â”‚     (åŒäºº)        (ä¸åŒäºº)                          â”‚
       â”‚                                                    â”‚
       â”‚  è®©åŒä¸€äººæ›´è¿‘ï¼Œä¸åŒäººæ›´è¿œ                            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    3. ArcFace Loss (SOTA)
       - åœ¨è§’åº¦ç©ºé—´æ·»åŠ  additive margin
       - å¢å¼ºç±»é—´å¯åˆ†æ€§
    """)

    # Triplet Loss å®ç°
    print("ç¤ºä¾‹: Triplet Loss\n")

    class TripletLoss(nn.Module):
        """Triplet Loss"""

        def __init__(self, margin=0.2):
            super().__init__()
            self.margin = margin

        def forward(self, anchor, positive, negative):
            # è·ç¦»è®¡ç®—
            pos_dist = F.pairwise_distance(anchor, positive)
            neg_dist = F.pairwise_distance(anchor, negative)

            # Triplet Loss
            loss = F.relu(pos_dist - neg_dist + self.margin)

            return loss.mean()

    # ArcFace Loss å®ç°
    class ArcFace(nn.Module):
        """ArcFace Loss"""

        def __init__(self, in_features, out_features, s=30.0, m=0.50):
            super().__init__()
            self.s = s  # ç¼©æ”¾å› å­
            self.m = m  # margin
            self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))
            nn.init.xavier_uniform_(self.weight)

        def forward(self, features, labels):
            # å½’ä¸€åŒ–
            features = F.normalize(features, dim=1)
            weight = F.normalize(self.weight, dim=1)

            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            cosine = F.linear(features, weight)

            # è½¬æ¢ä¸ºè§’åº¦
            theta = torch.acos(torch.clamp(cosine, -1 + 1e-7, 1 - 1e-7))

            # æ·»åŠ  margin
            target_logits = torch.cos(theta + self.m)

            # æ›¿æ¢ç›®æ ‡ç±»çš„ logits
            one_hot = F.one_hot(labels, cosine.size(1)).float()
            output = cosine * (1 - one_hot) + target_logits * one_hot

            # ç¼©æ”¾
            output *= self.s

            return output

    criterion = TripletLoss(margin=0.2)
    anchor = torch.randn(4, 512)
    positive = torch.randn(4, 512)
    negative = torch.randn(4, 512)
    loss = criterion(anchor, positive, negative)
    print(f"Triplet Loss: {loss.item():.4f}")


# ==================== ç¬¬ä¸ƒéƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    exercises_text = """
ç»ƒä¹  1ï¼šäººè„¸æ£€æµ‹
    ä»»åŠ¡: ä½¿ç”¨ MTCNN æ£€æµ‹å›¾åƒä¸­çš„äººè„¸
    è¦æ±‚: ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œ 5 ä¸ªå…³é”®ç‚¹

ç»ƒä¹  1 ç­”æ¡ˆï¼š
    # pip install facenet-pytorch
    from facenet_pytorch import MTCNN
    import cv2
    import matplotlib.pyplot as plt
    
    # åˆ›å»ºæ£€æµ‹å™¨
    mtcnn = MTCNN(keep_all=True, device='cuda')
    
    # åŠ è½½å›¾ç‰‡
    image = cv2.imread('group_photo.jpg')
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # æ£€æµ‹
    boxes, probs, landmarks = mtcnn.detect(image_rgb, landmarks=True)
    
    # å¯è§†åŒ–
    fig, ax = plt.subplots(1, figsize=(12, 8))
    ax.imshow(image_rgb)
    
    if boxes is not None:
        for box, prob, landmark in zip(boxes, probs, landmarks):
            if prob < 0.9:
                continue
            
            # è¾¹ç•Œæ¡†
            x1, y1, x2, y2 = box
            ax.add_patch(plt.Rectangle((x1, y1), x2-x1, y2-y1,
                                        fill=False, color='green', linewidth=2))
            ax.text(x1, y1-5, f'{prob:.2f}', color='green')
            
            # 5 ä¸ªå…³é”®ç‚¹
            colors = ['red', 'red', 'blue', 'green', 'green']
            for i, (x, y) in enumerate(landmark):
                ax.scatter([x], [y], c=colors[i], s=30)
    
    plt.savefig('mtcnn_result.png')

ç»ƒä¹  2ï¼šäººè„¸å¯¹é½
    ä»»åŠ¡: å®ç°åŸºäºå…³é”®ç‚¹çš„äººè„¸å¯¹é½
    æµ‹è¯•: å¯¹é½ä¸åŒå§¿æ€çš„äººè„¸

ç»ƒä¹  2 ç­”æ¡ˆï¼š
    import cv2
    import numpy as np
    
    def align_face(image, landmarks, target_size=(112, 112)):
        '''
        åŸºäº 5 ç‚¹çš„äººè„¸å¯¹é½
        
        Args:
            image: è¾“å…¥å›¾åƒ
            landmarks: 5 ä¸ªå…³é”®ç‚¹ [[x1,y1], [x2,y2], ...]
            target_size: è¾“å‡ºå¤§å°
        '''
        # æ ‡å‡†äººè„¸çš„å…³é”®ç‚¹ä½ç½® (åŸºäº 112Ã—112)
        target_landmarks = np.float32([
            [38.2946, 51.6963],  # å·¦çœ¼
            [73.5318, 51.5014],  # å³çœ¼  
            [56.0252, 71.7366],  # é¼»å­
            [41.5493, 92.3655],  # å·¦å˜´è§’
            [70.7299, 92.2041]   # å³å˜´è§’
        ])
        
        src = np.float32(landmarks)
        
        # è®¡ç®—ä»¿å°„å˜æ¢çŸ©é˜µ
        M = cv2.estimateAffinePartial2D(src, target_landmarks)[0]
        
        # åº”ç”¨å˜æ¢
        aligned = cv2.warpAffine(image, M, target_size)
        
        return aligned
    
    # ä½¿ç”¨ç¤ºä¾‹
    from facenet_pytorch import MTCNN
    mtcnn = MTCNN(keep_all=False)
    
    image = cv2.imread('face.jpg')
    _, _, landmarks = mtcnn.detect(image, landmarks=True)
    
    if landmarks is not None:
        aligned = align_face(image, landmarks[0])
        cv2.imwrite('aligned_face.jpg', aligned)

ç»ƒä¹  3ï¼šäººè„¸éªŒè¯ç³»ç»Ÿ
    ä»»åŠ¡: æ„å»º 1:1 äººè„¸éªŒè¯ç³»ç»Ÿ
    æµç¨‹: æ£€æµ‹ â†’ å¯¹é½ â†’ ç‰¹å¾æå– â†’ åŒ¹é…

ç»ƒä¹  3 ç­”æ¡ˆï¼š
    import torch
    import torch.nn.functional as F
    from facenet_pytorch import MTCNN, InceptionResnetV1
    import cv2
    import numpy as np
    
    class FaceVerifier:
        def __init__(self, threshold=0.6):
            self.mtcnn = MTCNN(keep_all=False, image_size=160)
            self.model = InceptionResnetV1(pretrained='vggface2').eval()
            self.threshold = threshold
        
        def get_embedding(self, image):
            '''æå–äººè„¸ç‰¹å¾'''
            # æ£€æµ‹å¹¶å¯¹é½
            face = self.mtcnn(image)
            if face is None:
                return None
            
            # æå–ç‰¹å¾
            with torch.no_grad():
                embedding = self.model(face.unsqueeze(0))
            
            # å½’ä¸€åŒ–
            embedding = F.normalize(embedding, p=2, dim=1)
            return embedding
        
        def verify(self, image1, image2):
            '''éªŒè¯ä¸¤å¼ å›¾ç‰‡æ˜¯å¦ä¸ºåŒä¸€äºº'''
            emb1 = self.get_embedding(image1)
            emb2 = self.get_embedding(image2)
            
            if emb1 is None or emb2 is None:
                return None, 'Face not detected'
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = F.cosine_similarity(emb1, emb2).item()
            is_same = similarity > self.threshold
            
            return is_same, similarity
    
    # ä½¿ç”¨
    verifier = FaceVerifier(threshold=0.6)
    is_same, score = verifier.verify(image1, image2)
    print(f'åŒä¸€äºº: {is_same}, ç›¸ä¼¼åº¦: {score:.4f}')

ç»ƒä¹  4ï¼šäººè„¸æœç´¢ç³»ç»Ÿ
    ä»»åŠ¡: æ„å»º 1:N äººè„¸æœç´¢ç³»ç»Ÿ
    åŒ…å«: äººè„¸åº“æ„å»ºã€ç‰¹å¾ç´¢å¼•ã€ç›¸ä¼¼åº¦æœç´¢

ç»ƒä¹  4 ç­”æ¡ˆï¼š
    import numpy as np
    import torch
    import torch.nn.functional as F
    from collections import defaultdict
    
    class FaceDatabase:
        def __init__(self):
            self.embeddings = []
            self.identities = []
        
        def add_face(self, embedding, identity):
            '''æ·»åŠ äººè„¸åˆ°æ•°æ®åº“'''
            self.embeddings.append(embedding)
            self.identities.append(identity)
        
        def build_index(self):
            '''æ„å»ºç´¢å¼•'''
            self.db_tensor = torch.cat(self.embeddings, dim=0)
        
        def search(self, query_emb, top_k=5):
            '''æœç´¢æœ€ç›¸ä¼¼çš„äººè„¸'''
            # è®¡ç®—ä¸æ‰€æœ‰äººè„¸çš„ç›¸ä¼¼åº¦
            similarities = F.cosine_similarity(
                query_emb, self.db_tensor
            )
            
            # è·å– top-k
            scores, indices = similarities.topk(top_k)
            
            results = []
            for score, idx in zip(scores.tolist(), indices.tolist()):
                results.append({
                    'identity': self.identities[idx],
                    'score': score
                })
            
            return results
    
    # ä½¿ç”¨
    db = FaceDatabase()
    
    # æ³¨å†Œäººè„¸
    for name, image in registered_faces:
        emb = get_embedding(image)
        db.add_face(emb, name)
    
    db.build_index()
    
    # æœç´¢
    query_emb = get_embedding(query_image)
    results = db.search(query_emb, top_k=3)

ç»ƒä¹  5ï¼šTriplet Mining
    ä»»åŠ¡: å®ç° Hard/Semi-Hard Triplet Mining
    æ¯”è¾ƒ: ä¸åŒæŒ–æ˜ç­–ç•¥å¯¹è®­ç»ƒçš„å½±å“

ç»ƒä¹  5 ç­”æ¡ˆï¼š
    import torch
    import torch.nn.functional as F
    
    def batch_hard_triplet_mining(embeddings, labels, margin=0.2):
        '''
        Batch Hard Triplet Mining
        é€‰æ‹©æœ€éš¾çš„æ­£ä¾‹å’Œè´Ÿä¾‹
        '''
        device = embeddings.device
        n = embeddings.size(0)
        
        # è®¡ç®—è·ç¦»çŸ©é˜µ
        dist_matrix = torch.cdist(embeddings, embeddings, p=2)
        
        # åˆ›å»ºæ ‡ç­¾æ©ç 
        labels = labels.unsqueeze(0)
        mask_pos = (labels == labels.T).float()  # åŒç±»
        mask_neg = (labels != labels.T).float()  # ä¸åŒç±»
        
        # å¯¹è§’çº¿ç½®é›¶ (æ’é™¤è‡ªå·±)
        mask_pos = mask_pos - torch.eye(n, device=device)
        
        # Hard Positive: åŒç±»ä¸­æœ€è¿œçš„
        hardest_pos = (dist_matrix * mask_pos).max(dim=1)[0]
        
        # Hard Negative: ä¸åŒç±»ä¸­æœ€è¿‘çš„
        # å°†åŒç±»è·ç¦»è®¾ä¸ºå¾ˆå¤§
        dist_neg = dist_matrix + mask_pos * 1e9
        hardest_neg = dist_neg.min(dim=1)[0]
        
        # Triplet Loss
        loss = F.relu(hardest_pos - hardest_neg + margin)
        
        return loss.mean()
    
    def semi_hard_triplet_mining(embeddings, labels, margin=0.2):
        '''
        Semi-Hard Triplet Mining
        é€‰æ‹©æ¯”æ­£ä¾‹è¿œä½†åœ¨ margin å†…çš„è´Ÿä¾‹
        '''
        # ... ç±»ä¼¼å®ç°
        # æ¡ä»¶: d(a,p) < d(a,n) < d(a,p) + margin
        pass

æ€è€ƒé¢˜ 1ï¼šä¸ºä»€ä¹ˆéœ€è¦äººè„¸å¯¹é½ï¼Ÿ
    ä¸å¯¹é½ä¼šæœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ

æ€è€ƒé¢˜ 1 ç­”æ¡ˆï¼š
    ä¸ºä»€ä¹ˆéœ€è¦å¯¹é½:
    
    1. å‡å°‘å§¿æ€å˜åŒ–
       - ä¾§è„¸vsæ­£è„¸å·®å¼‚å¤§
       - å¯¹é½åç»Ÿä¸€ä¸ºæ­£è„¸
       - ç½‘ç»œæ›´å®¹æ˜“å­¦ä¹ 
    
    2. æ ‡å‡†åŒ–è¾“å…¥
       - çœ¼ç›ã€å˜´å·´ä½ç½®å›ºå®š
       - ç½‘ç»œåªéœ€å…³æ³¨èº«ä»½ç‰¹å¾
       - ä¸éœ€è¦å­¦ä¹ ä½ç½®ä¸å˜æ€§
    
    ä¸å¯¹é½çš„é—®é¢˜:
    - åŒä¸€äººä¸åŒå§¿æ€ç‰¹å¾å·®å¼‚å¤§
    - éœ€è¦æ›´å¤šæ•°æ®è¦†ç›–å„ç§å§¿æ€
    - ç½‘ç»œéœ€è¦å­¦ä¹ å§¿æ€ä¸å˜æ€§
    - è¯†åˆ«å‡†ç¡®ç‡ä¸‹é™

æ€è€ƒé¢˜ 2ï¼šArcFace ä¸ºä»€ä¹ˆæ¯” Softmax æ•ˆæœå¥½ï¼Ÿ
    è§’åº¦ margin çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ

æ€è€ƒé¢˜ 2 ç­”æ¡ˆï¼š
    Softmax çš„é—®é¢˜:
    - åªè¦æ±‚æ­£ç¡®åˆ†ç±»
    - ä¸å¼ºåˆ¶ç±»é—´åˆ†ç¦»
    - ç‰¹å¾åˆ†å¸ƒå¯èƒ½ç´§å¯†
    
    ArcFace çš„æ”¹è¿›:
    
    1. è§’åº¦ç©ºé—´
       - å°†ç‰¹å¾å½’ä¸€åŒ–åˆ°è¶…çƒé¢
       - è·ç¦»å˜æˆè§’åº¦
       - æ›´ç¬¦åˆäººè„¸åˆ†å¸ƒ
    
    2. Additive Angular Margin
       - å…¬å¼: cos(Î¸ + m)
       - å¼ºåˆ¶åŒç±»æ›´è¿‘ (è§’åº¦æ›´å°)
       - å¼ºåˆ¶å¼‚ç±»æ›´è¿œ (è§’åº¦æ›´å¤§)
    
    3. å‡ ä½•è§£é‡Š
       - å†³ç­–è¾¹ç•Œæ›´ä¸¥æ ¼
       - ç±»é—´éœ€è¦æ›´å¤§é—´éš”
       - æ³›åŒ–èƒ½åŠ›æ›´å¼º
    
    æ•ˆæœå¯¹æ¯”:
    - Softmax: ~95% (LFW)
    - ArcFace: ~99.8% (LFW)

æ€è€ƒé¢˜ 3ï¼šå¦‚ä½•å¤„ç†å¤§è§„æ¨¡äººè„¸åº“çš„å¿«é€Ÿæœç´¢ï¼Ÿ
    æç¤º: è€ƒè™‘ ANN (è¿‘ä¼¼æœ€è¿‘é‚») ç®—æ³•

æ€è€ƒé¢˜ 3 ç­”æ¡ˆï¼š
    å¤§è§„æ¨¡äººè„¸æœç´¢æŒ‘æˆ˜:
    - ç™¾ä¸‡/äº¿çº§äººè„¸åº“
    - æš´åŠ›æœç´¢å¤ªæ…¢
    - éœ€è¦è¿‘ä¼¼æœç´¢
    
    ANN (Approximate Nearest Neighbor) ç®—æ³•:
    
    1. Faiss (Facebook)
       - IVF: å€’æ’ç´¢å¼•
       - PQ: ä¹˜ç§¯é‡åŒ–
       - GPU åŠ é€Ÿ
       
       import faiss
       index = faiss.IndexFlatIP(512)  # ä½™å¼¦ç›¸ä¼¼åº¦
       index.add(db_embeddings)
       D, I = index.search(query, k=5)
    
    2. Annoy (Spotify)
       - åŸºäºæ ‘çš„ç»“æ„
       - å†…å­˜æ˜ å°„ï¼Œæ”¯æŒå¤§æ•°æ®
    
    3. HNSW
       - åˆ†å±‚å¯å¯¼èˆªå°ä¸–ç•Œ
       - é«˜å¬å›ç‡
    
    4. èšç±»åˆ†å±‚
       - å…ˆæŒ‰èšç±»ç­›é€‰
       - å†åœ¨å€™é€‰ä¸­ç²¾ç¡®æœç´¢
    
    å…¸å‹æ€§èƒ½:
    - ç™¾ä¸‡çº§äººè„¸: ~10ms
    - äº¿çº§äººè„¸: ~100ms
    """
    print(exercises_text)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    introduction()
    face_detection()
    face_alignment()
    feature_extraction()
    feature_matching()
    loss_functions()
    exercises()

    print("\n" + "=" * 60)
    print("è¯¾ç¨‹å®Œæˆï¼")
    print("=" * 60)
    print("""
Phase 10 å­¦ä¹ å®Œæˆï¼

å…³é”®è¦ç‚¹å›é¡¾ï¼š
    âœ“ äººè„¸è¯†åˆ«æµç¨‹: æ£€æµ‹ â†’ å¯¹é½ â†’ ç‰¹å¾æå– â†’ åŒ¹é…
    âœ“ MTCNN: å¤šä»»åŠ¡çº§è” CNN äººè„¸æ£€æµ‹
    âœ“ äººè„¸å¯¹é½: ä½¿ç”¨å…³é”®ç‚¹è¿›è¡Œä»¿å°„å˜æ¢
    âœ“ ç‰¹å¾æå–: å°†äººè„¸æ˜ å°„ä¸º 512 ç»´å‘é‡
    âœ“ ArcFace: å½“å‰æœ€ä½³äººè„¸è¯†åˆ«æŸå¤±å‡½æ•°

æ­å–œä½ å®Œæˆäº†è®¡ç®—æœºè§†è§‰åº”ç”¨é˜¶æ®µï¼
ä¸‹ä¸€é˜¶æ®µ: Phase 11 - è‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨
    """)


if __name__ == "__main__":
    main()
