import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

plt.rcParams["font.sans-serif"] = ["Arial Unicode MS"]
plt.rcParams["axes.unicode_minus"] = False

print("=" * 60)
print("ç¬¬1èŠ‚: RNN åŸºç¡€ç»“æ„ä¸å‰å‘ä¼ æ’­")
print("=" * 60)


class SimpleRNN:
    def __init__(self, input_size, hidden_size, output_size):
        self.hidden_size = hidden_size

        # åˆå§‹åŒ–æƒé‡ (Xavier)
        scale = np.sqrt(2.0 / (input_size + hidden_size))
        self.Wxh = np.random.randn(hidden_size, input_size) * scale  # è¾“å…¥åˆ°éšè—
        self.Whh = np.random.randn(hidden_size, hidden_size) * scale  # éšè—åˆ°éšè—
        self.Why = np.random.randn(output_size, hidden_size) * scale  # éšè—åˆ°è¾“å‡º

        self.bh = np.zeros((hidden_size, 1))
        self.by = np.zeros((output_size, 1))

    def forward(self, inputs, h_prev=None):
        seq_len = len(inputs)

        if h_prev is None:
            h_prev = np.zeros((self.hidden_size, 1))

        hidden_states = []
        outputs = []

        h = h_prev
        for t in range(seq_len):
            x = inputs[t].reshape(-1, 1)

            h = np.tanh(self.Wxh @ x + self.Whh @ h + self.bh)

            y = self.Why @ h + self.by

            hidden_states.append(h)
            outputs.append(y)

        return outputs, hidden_states


# æµ‹è¯•æ‰‹åŠ¨å®ç°
print("\næµ‹è¯•æ‰‹åŠ¨å®ç°çš„ RNN:")
input_size = 4
hidden_size = 8
output_size = 3
seq_len = 5

rnn = SimpleRNN(input_size, hidden_size, output_size)

# åˆ›å»ºéšæœºè¾“å…¥åºåˆ—
inputs = [np.random.randn(input_size) for _ in range(seq_len)]

outputs, hidden_states = rnn.forward(inputs)

print(f"  è¾“å…¥ç»´åº¦: {input_size}")
print(f"  éšè—å±‚ç»´åº¦: {hidden_size}")
print(f"  è¾“å‡ºç»´åº¦: {output_size}")
print(f"  åºåˆ—é•¿åº¦: {seq_len}")
print(f"  è¾“å‡ºå½¢çŠ¶: {len(outputs)} Ã— {outputs[0].shape}")
print(f"  éšè—çŠ¶æ€å½¢çŠ¶: {len(hidden_states)} Ã— {hidden_states[0].shape}")

print("\n" + "=" * 60)
print("ğŸ“Œ 4. PyTorch RNN ä½¿ç”¨")
print("-" * 60)

rnn_pytorch = nn.RNN(
    input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True
)

batch_size = 2
x = torch.randn(batch_size, seq_len, input_size)

# åˆå§‹éšè—çŠ¶æ€: [num_layers, batch_size, hidden_size]
h0 = torch.zeros(1, batch_size, hidden_size)

# å‰å‘ä¼ æ’­
output, hn = rnn_pytorch(x, h0)

print(f"\nPyTorch RNN:")
print(f"  è¾“å…¥å½¢çŠ¶: {x.shape}")
print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")
print(f"  æœ€ç»ˆéšè—çŠ¶æ€å½¢çŠ¶: {hn.shape}")

# æŸ¥çœ‹å‚æ•°
print(f"\nRNN å‚æ•°:")
for name, param in rnn_pytorch.named_parameters():
    print(f"  {name}: {param.shape}")
