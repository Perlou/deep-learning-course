# Phase 4 å®žæˆ˜é¡¹ç›®ï¼šæˆ¿ä»·é¢„æµ‹ï¼ˆå›žå½’ä»»åŠ¡ï¼‰

## ðŸ“‹ é¡¹ç›®æ¦‚è¿°

ä½¿ç”¨å¤šå±‚æ„ŸçŸ¥æœº (MLP) é¢„æµ‹æˆ¿å±‹ä»·æ ¼ï¼Œç»¼åˆè¿ç”¨ Phase 4 æ‰€å­¦çš„ç¥žç»ç½‘ç»œåŸºç¡€çŸ¥è¯†ã€‚

## ðŸŽ¯ å­¦ä¹ ç›®æ ‡

- å…¨è¿žæŽ¥ç½‘ç»œåœ¨å›žå½’ä»»åŠ¡ä¸­çš„åº”ç”¨
- MSE æŸå¤±å‡½æ•°å’Œå›žå½’è¯„ä¼°æŒ‡æ ‡
- æ­£åˆ™åŒ–æŠ€æœ¯å®žè·µï¼ˆDropoutã€BatchNormã€L2ï¼‰
- æƒé‡åˆå§‹åŒ–ï¼ˆHe åˆå§‹åŒ–ï¼‰
- ç‰¹å¾æ ‡å‡†åŒ–çš„é‡è¦æ€§

## ðŸ“Š æ•°æ®é›†

**California Housing Dataset**ï¼ˆScikit-learn å†…ç½®ï¼‰

- æ ·æœ¬æ•°ï¼š~20,000
- ç‰¹å¾æ•°ï¼š8ï¼ˆæ”¶å…¥ã€æˆ¿é¾„ã€æˆ¿é—´æ•°ç­‰ï¼‰
- ç›®æ ‡ï¼šæˆ¿ä»·ä¸­ä½æ•°ï¼ˆå•ä½ï¼š$100,000ï¼‰

## ðŸ—ï¸ æ¨¡åž‹æž¶æž„

```
è¾“å…¥: (8,)  # 8 ä¸ªæˆ¿å±‹ç‰¹å¾
    â†“
Linear(8â†’128) + BatchNorm + ReLU + Dropout(0.2)
    â†“
Linear(128â†’64) + BatchNorm + ReLU + Dropout(0.2)
    â†“
Linear(64â†’32) + ReLU
    â†“
Linear(32â†’1)  # æ— æ¿€æ´»ï¼Œçº¿æ€§è¾“å‡º
    â†“
è¾“å‡º: (1,)  # é¢„æµ‹ä»·æ ¼
```

## ðŸš€ è¿è¡Œæ–¹å¼

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd projects/phase-4-regression

# æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒ
source ../../.venv/bin/activate

# è¿è¡Œé¡¹ç›®
python house_price_mlp.py
```

## ðŸ“ ç”Ÿæˆæ–‡ä»¶

| æ–‡ä»¶                             | è¯´æ˜Ž              |
| -------------------------------- | ----------------- |
| `outputs/training_curves.png`    | è®­ç»ƒ/éªŒè¯æŸå¤±æ›²çº¿ |
| `outputs/predictions.png`        | é¢„æµ‹ vs çœŸå®žå€¼    |
| `outputs/feature_importance.png` | ç‰¹å¾é‡è¦æ€§åˆ†æž    |
| `outputs/residuals.png`          | æ®‹å·®åˆ†æž          |
| `outputs/best_model.pth`         | æœ€ä½³æ¨¡åž‹æƒé‡      |

## ðŸ“ˆ é¢„æœŸç»“æžœ

- æµ‹è¯•é›† RÂ² > 0.6
- æµ‹è¯•é›† RMSE < 0.8
- è®­ç»ƒæ—¶é—´: ~30 ç§’

## âœ… æ ¸å¿ƒçŸ¥è¯†ç‚¹

### å›žå½’ vs åˆ†ç±»

| å¯¹æ¯”é¡¹     | åˆ†ç±»ä»»åŠ¡        | å›žå½’ä»»åŠ¡      |
| ---------- | --------------- | ------------- |
| è¾“å‡ºå±‚æ¿€æ´» | Softmax/Sigmoid | æ— ï¼ˆçº¿æ€§ï¼‰    |
| æŸå¤±å‡½æ•°   | CrossEntropy    | MSE/MAE       |
| è¯„ä¼°æŒ‡æ ‡   | Accuracy, F1    | RMSE, MAE, RÂ² |

### ç‰¹å¾æ ‡å‡†åŒ–

```python
# å›žå½’ä»»åŠ¡ä¸­ç‰¹å¾æ ‡å‡†åŒ–éžå¸¸é‡è¦
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

### L2 æ­£åˆ™åŒ– (Weight Decay)

```python
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
```
