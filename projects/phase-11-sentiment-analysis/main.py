"""
æƒ…æ„Ÿåˆ†æç³»ç»Ÿ - ä¸»å…¥å£
====================

Phase 11 å®æˆ˜é¡¹ç›®ï¼šå¤šæ¨¡å‹æƒ…æ„Ÿåˆ†æã€‚
"""

import sys
import argparse
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ğŸ“ æƒ…æ„Ÿåˆ†æç³»ç»Ÿ (TextCNN / BiLSTM / BERT)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¿«é€Ÿæ¼”ç¤º
  python main.py demo

  # å¿«é€Ÿè®­ç»ƒ (TextCNN)
  python main.py train --model textcnn --quick

  # è®­ç»ƒ BiLSTM
  python main.py train --model lstm --epochs 10

  # è¯„ä¼°æ¨¡å‹
  python main.py eval --model textcnn

  # æ¨ç†
  python main.py predict --text "I love this movie!"

  # äº¤äº’æ¨¡å¼
  python main.py predict --interactive

  # ç³»ç»Ÿä¿¡æ¯
  python main.py info
        """,
    )

    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # demo
    demo_parser = subparsers.add_parser("demo", help="å¿«é€Ÿæ¼”ç¤º")

    # train
    train_parser = subparsers.add_parser("train", help="è®­ç»ƒæ¨¡å‹")
    train_parser.add_argument(
        "--model",
        type=str,
        default="textcnn",
        choices=["textcnn", "lstm", "bert"],
        help="æ¨¡å‹ç±»å‹",
    )
    train_parser.add_argument("--epochs", type=int, default=10, help="è®­ç»ƒè½®æ•°")
    train_parser.add_argument("--batch-size", type=int, default=32, help="æ‰¹é‡å¤§å°")
    train_parser.add_argument("--lr", type=float, default=None, help="å­¦ä¹ ç‡")
    train_parser.add_argument("--quick", action="store_true", help="å¿«é€Ÿè®­ç»ƒ")

    # eval
    eval_parser = subparsers.add_parser("eval", help="è¯„ä¼°æ¨¡å‹")
    eval_parser.add_argument(
        "--model",
        type=str,
        default="textcnn",
        choices=["textcnn", "lstm", "bert"],
        help="æ¨¡å‹ç±»å‹",
    )
    eval_parser.add_argument("--model-path", type=str, default=None, help="æ¨¡å‹è·¯å¾„")

    # predict
    predict_parser = subparsers.add_parser("predict", help="æ¨ç†é¢„æµ‹")
    predict_parser.add_argument(
        "--model",
        type=str,
        default="textcnn",
        choices=["textcnn", "lstm", "bert"],
        help="æ¨¡å‹ç±»å‹",
    )
    predict_parser.add_argument("--text", type=str, default=None, help="è¾“å…¥æ–‡æœ¬")
    predict_parser.add_argument(
        "--interactive", "-i", action="store_true", help="äº¤äº’æ¨¡å¼"
    )

    # info
    info_parser = subparsers.add_parser("info", help="æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯")

    args = parser.parse_args()

    if args.command == "demo":
        run_demo()
    elif args.command == "train":
        run_train(args)
    elif args.command == "eval":
        run_eval(args)
    elif args.command == "predict":
        run_predict(args)
    elif args.command == "info":
        show_info()
    else:
        parser.print_help()


def run_demo():
    """è¿è¡Œæ¼”ç¤º"""
    print("=" * 60)
    print("ğŸ“ æƒ…æ„Ÿåˆ†æç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)

    try:
        from config import DEVICE, LABELS
        from model import TextCNN, BiLSTMClassifier, count_parameters
        from dataset import prepare_dataset

        # è®¾å¤‡ä¿¡æ¯
        print("\n1ï¸âƒ£  ç³»ç»Ÿç¯å¢ƒ")
        print("-" * 40)
        import torch

        print(f"PyTorch: {torch.__version__}")
        print(f"è®¾å¤‡: {DEVICE}")

        # æ•°æ®é›†
        print("\n2ï¸âƒ£  å‡†å¤‡æ•°æ®é›†")
        print("-" * 40)
        train_data, val_data, vocab = prepare_dataset(num_samples=500)

        # æ¨¡å‹ä¿¡æ¯
        print("\n3ï¸âƒ£  æ¨¡å‹ä¿¡æ¯")
        print("-" * 40)

        textcnn = TextCNN(vocab_size=len(vocab))
        lstm = BiLSTMClassifier(vocab_size=len(vocab))

        print(f"TextCNN å‚æ•°é‡: {count_parameters(textcnn):,}")
        print(f"BiLSTM å‚æ•°é‡: {count_parameters(lstm):,}")

        # æ ‡ç­¾
        print("\n4ï¸âƒ£  æƒ…æ„Ÿæ ‡ç­¾")
        print("-" * 40)
        for idx, label in LABELS.items():
            print(f"  {idx}: {label}")

        print("\n5ï¸âƒ£  å¯ç”¨å‘½ä»¤")
        print("-" * 40)
        print("""
  ğŸš€ è®­ç»ƒ TextCNN:
     python main.py train --model textcnn --quick

  ğŸš€ è®­ç»ƒ BiLSTM:
     python main.py train --model lstm --quick

  ğŸ“Š è¯„ä¼°æ¨¡å‹:
     python main.py eval --model textcnn

  ğŸ’¬ æƒ…æ„Ÿé¢„æµ‹:
     python main.py predict --text "I love this movie!"
        """)

        print("\n" + "=" * 60)
        print("âœ… æ¼”ç¤ºå®Œæˆ!")
        print("=" * 60)

    except ImportError as e:
        print(f"\nâŒ å¯¼å…¥é”™è¯¯: {e}")


def run_train(args):
    """è¿è¡Œè®­ç»ƒ"""
    from train import train, quick_train

    if args.quick:
        quick_train(model_type=args.model)
    else:
        train(
            model_type=args.model,
            epochs=args.epochs,
            batch_size=args.batch_size,
            learning_rate=args.lr,
        )


def run_eval(args):
    """è¿è¡Œè¯„ä¼°"""
    from evaluate import evaluate

    evaluate(model_type=args.model, model_path=args.model_path)


def run_predict(args):
    """è¿è¡Œæ¨ç†"""
    from inference import predict_interactive, demo_inference, load_model, predict
    from config import LABELS

    if args.interactive:
        predict_interactive(model_type=args.model)
    elif args.text:
        model, vocab, tokenizer = load_model(args.model)
        if model is not None:
            label, confidence = predict(args.text, model, vocab, tokenizer, args.model)
            print(f"æ–‡æœ¬: {args.text}")
            print(f"æƒ…æ„Ÿ: {LABELS[label]}")
            print(f"ç½®ä¿¡åº¦: {confidence:.2%}")
    else:
        demo_inference()


def show_info():
    """æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯"""
    import torch
    from config import MODELS_DIR

    print("=" * 60)
    print("ğŸ“Š ç³»ç»Ÿä¿¡æ¯")
    print("=" * 60)

    print(f"\nPyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")

    if hasattr(torch.backends, "mps"):
        print(f"MPS å¯ç”¨: {torch.backends.mps.is_available()}")

    print("\né¡¹ç›®è·¯å¾„:")
    print(f"  {Path(__file__).parent}")

    print("\nå·²ä¿å­˜æ¨¡å‹:")
    for model_type in ["textcnn", "lstm", "bert"]:
        model_path = MODELS_DIR / f"best_{model_type}.pth"
        if model_path.exists():
            print(f"  âœ“ best_{model_type}.pth")

    if not any(
        (MODELS_DIR / f"best_{m}.pth").exists() for m in ["textcnn", "lstm", "bert"]
    ):
        print("  âš  æš‚æ— æ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒ")


if __name__ == "__main__":
    main()
