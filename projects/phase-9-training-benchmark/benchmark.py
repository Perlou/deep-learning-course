"""
åŸºå‡†æµ‹è¯• - å¯¹æ¯”å¤šç§ä¼˜åŒ–é…ç½®
"""

import time
import matplotlib.pyplot as plt
import numpy as np

from config import CONFIGS, TrainConfig
from model import get_model
from dataset import get_dataloaders
from trainer import Trainer


def run_benchmark(config_names=None, epochs=20):
    """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
    if config_names is None:
        config_names = [
            "baseline",
            "adamw_cosine",
            "adamw_onecycle",
            "full_optimization",
        ]

    print("=" * 60)
    print("Phase 9 åŸºå‡†æµ‹è¯•: ä¼˜åŒ–ç­–ç•¥å¯¹æ¯”")
    print("=" * 60)

    # æ•°æ® (æ‰€æœ‰é…ç½®å…±äº«)
    train_loader, test_loader = get_dataloaders(batch_size=128)

    results = {}

    for name in config_names:
        print(f"\n{'=' * 60}")
        print(f"é…ç½®: {name}")
        print("=" * 60)

        # è·å–é…ç½®
        config = CONFIGS.get(name, TrainConfig())
        config.epochs = epochs  # ç»Ÿä¸€ epochs
        config.output_dir = f"projects/phase-9-training-benchmark/outputs/{name}"

        # æ¨¡å‹
        model = get_model(config.model_name, config.num_classes)

        # è®­ç»ƒå™¨
        trainer = Trainer(model, config, train_loader, test_loader)

        # è®¡æ—¶
        start_time = time.time()

        # è®­ç»ƒ
        history = trainer.train()

        # ç»“æœ
        elapsed_time = time.time() - start_time
        results[name] = {
            "history": history,
            "best_acc": trainer.best_acc,
            "time": elapsed_time,
            "config": config,
        }

        print(
            f"\n{name}: æœ€ä½³å‡†ç¡®ç‡={trainer.best_acc:.2f}%, ç”¨æ—¶={elapsed_time / 60:.2f}åˆ†é’Ÿ"
        )

    return results


def plot_comparison(
    results, save_path="projects/phase-9-training-benchmark/outputs/logs/benchmark.png"
):
    """ç»˜åˆ¶å¯¹æ¯”å›¾"""
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    colors = plt.cm.tab10(np.linspace(0, 1, len(results)))

    # Loss å¯¹æ¯”
    for i, (name, data) in enumerate(results.items()):
        axes[0, 0].plot(data["history"]["test_loss"], label=name, color=colors[i])
    axes[0, 0].set_xlabel("Epoch")
    axes[0, 0].set_ylabel("Test Loss")
    axes[0, 0].set_title("æµ‹è¯•æŸå¤±å¯¹æ¯”")
    axes[0, 0].legend()
    axes[0, 0].grid(True)

    # Accuracy å¯¹æ¯”
    for i, (name, data) in enumerate(results.items()):
        axes[0, 1].plot(data["history"]["test_acc"], label=name, color=colors[i])
    axes[0, 1].set_xlabel("Epoch")
    axes[0, 1].set_ylabel("Test Accuracy (%)")
    axes[0, 1].set_title("æµ‹è¯•å‡†ç¡®ç‡å¯¹æ¯”")
    axes[0, 1].legend()
    axes[0, 1].grid(True)

    # Learning Rate å¯¹æ¯”
    for i, (name, data) in enumerate(results.items()):
        axes[1, 0].plot(data["history"]["lr"], label=name, color=colors[i])
    axes[1, 0].set_xlabel("Epoch")
    axes[1, 0].set_ylabel("Learning Rate")
    axes[1, 0].set_title("å­¦ä¹ ç‡å˜åŒ–å¯¹æ¯”")
    axes[1, 0].legend()
    axes[1, 0].grid(True)

    # æœ€ç»ˆç»“æœæŸ±çŠ¶å›¾
    names = list(results.keys())
    accs = [results[n]["best_acc"] for n in names]
    times = [results[n]["time"] / 60 for n in names]

    x = np.arange(len(names))
    width = 0.35

    ax2 = axes[1, 1]
    bars1 = ax2.bar(x - width / 2, accs, width, label="å‡†ç¡®ç‡ (%)", color="steelblue")
    ax2.set_ylabel("å‡†ç¡®ç‡ (%)")
    ax2.set_xlabel("é…ç½®")
    ax2.set_title("æœ€ç»ˆç»“æœå¯¹æ¯”")
    ax2.set_xticks(x)
    ax2.set_xticklabels(names, rotation=15)

    ax3 = ax2.twinx()
    bars2 = ax3.bar(x + width / 2, times, width, label="æ—¶é—´ (åˆ†é’Ÿ)", color="coral")
    ax3.set_ylabel("æ—¶é—´ (åˆ†é’Ÿ)")

    ax2.legend(loc="upper left")
    ax3.legend(loc="upper right")

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, acc in zip(bars1, accs):
        ax2.text(
            bar.get_x() + bar.get_width() / 2,
            bar.get_height() + 0.5,
            f"{acc:.1f}",
            ha="center",
            fontsize=9,
        )

    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches="tight")
    print(f"\nå¯¹æ¯”å›¾å·²ä¿å­˜åˆ° {save_path}")


def print_summary(results):
    """æ‰“å°ç»“æœæ‘˜è¦"""
    print("\n" + "=" * 60)
    print("åŸºå‡†æµ‹è¯•ç»“æœæ‘˜è¦")
    print("=" * 60)

    print(f"\n{'é…ç½®':<25} {'å‡†ç¡®ç‡':<12} {'æ—¶é—´':<12} {'ä¼˜åŒ–å™¨':<10} {'è°ƒåº¦å™¨':<12}")
    print("-" * 75)

    baseline_time = results.get("baseline", {}).get("time", 1)

    for name, data in results.items():
        config = data["config"]
        acc = data["best_acc"]
        time_min = data["time"] / 60
        speedup = baseline_time / data["time"]

        print(
            f"{name:<25} {acc:.2f}%       {time_min:.2f}åˆ†       {config.optimizer:<10} {config.scheduler:<12}"
        )

    # æ‰¾å‡ºæœ€ä½³é…ç½®
    best_name = max(results, key=lambda x: results[x]["best_acc"])
    print(f"\nğŸ† æœ€ä½³é…ç½®: {best_name} (å‡†ç¡®ç‡: {results[best_name]['best_acc']:.2f}%)")


def main():
    # å¿«é€Ÿæµ‹è¯• (å‡å°‘ epochs)
    results = run_benchmark(
        config_names=["baseline", "adamw_cosine", "full_optimization"],
        epochs=10,  # å¿«é€Ÿæµ‹è¯•ç”¨ 10 ä¸ª epoch
    )

    # ç»˜åˆ¶å¯¹æ¯”å›¾
    plot_comparison(results)

    # æ‰“å°æ‘˜è¦
    print_summary(results)


if __name__ == "__main__":
    main()
