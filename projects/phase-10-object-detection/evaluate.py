"""
è¯„ä¼°è„šæœ¬
========

è¯„ä¼° YOLOv8 ç›®æ ‡æ£€æµ‹æ¨¡å‹æ€§èƒ½ã€‚
"""

import sys
from pathlib import Path
from typing import Optional, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from config import InferenceConfig, RESULT_DIR


def evaluate(
    model_path: str,
    data_yaml: str = "coco128.yaml",
    image_size: int = 640,
    batch_size: int = 16,
    conf: float = 0.001,
    iou: float = 0.6,
    device: str = "auto",
    save_dir: Optional[str] = None,
    plots: bool = True,
    verbose: bool = True,
) -> Dict[str, Any]:
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½

    Args:
        model_path: æ¨¡å‹æƒé‡è·¯å¾„
        data_yaml: æ•°æ®é›†é…ç½®æ–‡ä»¶
        image_size: è¾“å…¥å›¾åƒå°ºå¯¸
        batch_size: æ‰¹é‡å¤§å°
        conf: ç½®ä¿¡åº¦é˜ˆå€¼ (è¯„ä¼°æ—¶é€šå¸¸è®¾è¾ƒä½)
        iou: IoU é˜ˆå€¼
        device: è¯„ä¼°è®¾å¤‡
        save_dir: ç»“æœä¿å­˜ç›®å½•
        plots: æ˜¯å¦ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        è¯„ä¼°æŒ‡æ ‡å­—å…¸
    """
    try:
        from ultralytics import YOLO
    except ImportError:
        raise ImportError("è¯·å®‰è£… ultralytics: pip install ultralytics")

    print("=" * 60)
    print("YOLOv8 æ¨¡å‹è¯„ä¼°")
    print("=" * 60)

    # åŠ è½½æ¨¡å‹
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    model = YOLO(model_path)

    # è®¾ç½®ä¿å­˜ç›®å½•
    if save_dir is None:
        save_dir = str(RESULT_DIR / "eval")

    # æ‰“å°é…ç½®
    print(f"\nè¯„ä¼°é…ç½®:")
    print(f"  æ•°æ®é›†: {data_yaml}")
    print(f"  å›¾åƒå°ºå¯¸: {image_size}")
    print(f"  ç½®ä¿¡åº¦é˜ˆå€¼: {conf}")
    print(f"  IoU é˜ˆå€¼: {iou}")
    print(f"  è®¾å¤‡: {device}")

    # æ‰§è¡Œè¯„ä¼°
    print("\nå¼€å§‹è¯„ä¼°...")
    print("-" * 60)

    metrics = model.val(
        data=data_yaml,
        imgsz=image_size,
        batch=batch_size,
        conf=conf,
        iou=iou,
        device=device if device != "auto" else None,
        plots=plots,
        save_dir=save_dir,
        verbose=verbose,
    )

    print("-" * 60)
    print("è¯„ä¼°å®Œæˆ!")
    print("=" * 60)

    # è§£æç»“æœ
    results = {
        "mAP50": float(metrics.box.map50),
        "mAP50-95": float(metrics.box.map),
        "mAP75": float(metrics.box.map75),
        "precision": float(metrics.box.mp),
        "recall": float(metrics.box.mr),
        "per_class_ap50": metrics.box.ap50.tolist()
        if hasattr(metrics.box, "ap50")
        else [],
    }

    # æ‰“å°ç»“æœ
    print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
    print(f"  mAP@0.5: {results['mAP50']:.4f}")
    print(f"  mAP@0.5:0.95: {results['mAP50-95']:.4f}")
    print(f"  mAP@0.75: {results['mAP75']:.4f}")
    print(f"  Precision: {results['precision']:.4f}")
    print(f"  Recall: {results['recall']:.4f}")

    if plots:
        print(f"\nå¯è§†åŒ–ç»“æœä¿å­˜åœ¨: {save_dir}")
        print("  - confusion_matrix.png (æ··æ·†çŸ©é˜µ)")
        print("  - PR_curve.png (PR æ›²çº¿)")
        print("  - F1_curve.png (F1 æ›²çº¿)")
        print("  - results.png (è®­ç»ƒæ›²çº¿)")

    return results


def compare_models(
    model_paths: list, data_yaml: str = "coco128.yaml", device: str = "auto"
) -> None:
    """
    å¯¹æ¯”å¤šä¸ªæ¨¡å‹çš„æ€§èƒ½

    Args:
        model_paths: æ¨¡å‹è·¯å¾„åˆ—è¡¨
        data_yaml: æ•°æ®é›†é…ç½®æ–‡ä»¶
        device: è¯„ä¼°è®¾å¤‡
    """
    print("=" * 60)
    print("æ¨¡å‹å¯¹æ¯”è¯„ä¼°")
    print("=" * 60)

    results = []
    for path in model_paths:
        print(f"\nè¯„ä¼°æ¨¡å‹: {path}")
        result = evaluate(
            model_path=path,
            data_yaml=data_yaml,
            device=device,
            plots=False,
            verbose=False,
        )
        result["model"] = path
        results.append(result)

    # æ‰“å°å¯¹æ¯”ç»“æœ
    print("\n" + "=" * 60)
    print("å¯¹æ¯”ç»“æœ")
    print("=" * 60)
    print(f"{'æ¨¡å‹':<40} {'mAP50':>10} {'mAP50-95':>10}")
    print("-" * 60)
    for r in results:
        model_name = Path(r["model"]).stem
        print(f"{model_name:<40} {r['mAP50']:>10.4f} {r['mAP50-95']:>10.4f}")


def analyze_predictions(
    model_path: str, image_dir: str, conf: float = 0.25, save_dir: Optional[str] = None
) -> Dict[str, Any]:
    """
    åˆ†ææ¨¡å‹é¢„æµ‹ç»“æœ

    Args:
        model_path: æ¨¡å‹æƒé‡è·¯å¾„
        image_dir: å›¾åƒç›®å½•
        conf: ç½®ä¿¡åº¦é˜ˆå€¼
        save_dir: ç»“æœä¿å­˜ç›®å½•

    Returns:
        åˆ†æç»“æœå­—å…¸
    """
    try:
        from ultralytics import YOLO
    except ImportError:
        raise ImportError("è¯·å®‰è£… ultralytics: pip install ultralytics")

    import numpy as np
    from collections import Counter

    print("=" * 60)
    print("é¢„æµ‹ç»“æœåˆ†æ")
    print("=" * 60)

    # åŠ è½½æ¨¡å‹
    model = YOLO(model_path)

    # è·å–å›¾åƒæ–‡ä»¶
    from utils import get_image_files

    image_files = get_image_files(image_dir)
    print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")

    # ç»Ÿè®¡ä¿¡æ¯
    total_detections = 0
    class_counts = Counter()
    confidence_scores = []

    # å¤„ç†æ¯å¼ å›¾åƒ
    for img_path in image_files:
        results = model.predict(str(img_path), conf=conf, verbose=False)

        for result in results:
            boxes = result.boxes
            total_detections += len(boxes)

            for box in boxes:
                cls_id = int(box.cls[0])
                cls_name = model.names[cls_id]
                class_counts[cls_name] += 1
                confidence_scores.append(float(box.conf[0]))

    # åˆ†æç»“æœ
    analysis = {
        "total_images": len(image_files),
        "total_detections": total_detections,
        "avg_detections_per_image": total_detections / len(image_files)
        if image_files
        else 0,
        "class_distribution": dict(class_counts),
        "avg_confidence": np.mean(confidence_scores) if confidence_scores else 0,
        "min_confidence": np.min(confidence_scores) if confidence_scores else 0,
        "max_confidence": np.max(confidence_scores) if confidence_scores else 0,
    }

    # æ‰“å°ç»“æœ
    print(f"\nğŸ“Š åˆ†æç»“æœ:")
    print(f"  å›¾åƒæ€»æ•°: {analysis['total_images']}")
    print(f"  æ£€æµ‹æ€»æ•°: {analysis['total_detections']}")
    print(f"  å¹³å‡æ¯å¼ å›¾åƒæ£€æµ‹æ•°: {analysis['avg_detections_per_image']:.2f}")
    print(f"  å¹³å‡ç½®ä¿¡åº¦: {analysis['avg_confidence']:.4f}")

    print(f"\nç±»åˆ«åˆ†å¸ƒ (å‰ 10):")
    for cls, count in class_counts.most_common(10):
        print(f"  {cls}: {count}")

    return analysis


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="YOLOv8 æ¨¡å‹è¯„ä¼°")
    parser.add_argument("--model", type=str, required=True, help="æ¨¡å‹æƒé‡è·¯å¾„")
    parser.add_argument(
        "--data", type=str, default="coco128.yaml", help="æ•°æ®é›†é…ç½®æ–‡ä»¶"
    )
    parser.add_argument("--imgsz", type=int, default=640, help="å›¾åƒå°ºå¯¸")
    parser.add_argument("--batch", type=int, default=16, help="æ‰¹é‡å¤§å°")
    parser.add_argument(
        "--device", type=str, default="auto", help="è®¾å¤‡ (auto/cuda/cpu/mps)"
    )
    parser.add_argument("--no-plots", action="store_true", help="ä¸ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")

    args = parser.parse_args()

    evaluate(
        model_path=args.model,
        data_yaml=args.data,
        image_size=args.imgsz,
        batch_size=args.batch,
        device=args.device,
        plots=not args.no_plots,
    )
