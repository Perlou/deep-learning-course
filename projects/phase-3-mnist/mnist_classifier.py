"""
MNIST æ‰‹å†™æ•°å­—åˆ†ç±»å™¨
Phase 3 å®æˆ˜é¡¹ç›®

å­¦ä¹ ç›®æ ‡ï¼š
1. å®Œæ•´çš„æ·±åº¦å­¦ä¹ é¡¹ç›®æµç¨‹
2. CNN æ¨¡å‹æ„å»ºå’Œè®­ç»ƒ
3. æ¨¡å‹è¯„ä¼°å’Œå¯è§†åŒ–
4. æ¨¡å‹ä¿å­˜å’Œæ¨ç†
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
import os
from tqdm import tqdm
import time

# ä¸­æ–‡å­—ä½“è®¾ç½®
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

print("=" * 60)
print("Phase 3 å®æˆ˜é¡¹ç›®ï¼šMNIST æ‰‹å†™æ•°å­—åˆ†ç±»")
print("=" * 60)

# =============================================================================
# 1. é…ç½®
# =============================================================================
class Config:
    # è·¯å¾„
    data_dir = './data'
    save_dir = './outputs'
    
    # è®­ç»ƒå‚æ•°
    batch_size = 64
    learning_rate = 0.001
    num_epochs = 10
    
    # æ¨¡å‹å‚æ•°
    num_classes = 10
    
    # è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() 
                          else 'mps' if torch.backends.mps.is_available() 
                          else 'cpu')

config = Config()
os.makedirs(config.save_dir, exist_ok=True)
print(f"\nä½¿ç”¨è®¾å¤‡: {config.device}")

# =============================================================================
# 2. æ•°æ®å‡†å¤‡
# =============================================================================
print("\n" + "=" * 60)
print("ã€1. æ•°æ®å‡†å¤‡ã€‘")

# æ•°æ®å˜æ¢
train_transform = transforms.Compose([
    transforms.RandomRotation(10),           # éšæœºæ—‹è½¬
    transforms.RandomAffine(0, translate=(0.1, 0.1)),  # éšæœºå¹³ç§»
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

# ä¸‹è½½å’ŒåŠ è½½æ•°æ®é›†
train_dataset = datasets.MNIST(
    root=config.data_dir,
    train=True,
    download=True,
    transform=train_transform
)

test_dataset = datasets.MNIST(
    root=config.data_dir,
    train=False,
    download=True,
    transform=test_transform
)

# åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
train_size = int(0.9 * len(train_dataset))
val_size = len(train_dataset) - train_size
train_dataset, val_dataset = torch.utils.data.random_split(
    train_dataset, [train_size, val_size]
)

print(f"è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
print(f"éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
print(f"æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")

# åˆ›å»º DataLoader
train_loader = DataLoader(
    train_dataset, 
    batch_size=config.batch_size, 
    shuffle=True,
    num_workers=0,
    pin_memory=True if config.device.type == 'cuda' else False
)

val_loader = DataLoader(
    val_dataset, 
    batch_size=config.batch_size, 
    shuffle=False
)

test_loader = DataLoader(
    test_dataset, 
    batch_size=config.batch_size, 
    shuffle=False
)

# =============================================================================
# 3. å¯è§†åŒ–æ ·æœ¬
# =============================================================================
print("\n" + "=" * 60)
print("ã€2. å¯è§†åŒ–æ ·æœ¬ã€‘")

def visualize_samples(dataset, num_samples=16):
    """å¯è§†åŒ–æ•°æ®æ ·æœ¬"""
    fig, axes = plt.subplots(4, 4, figsize=(8, 8))
    for i, ax in enumerate(axes.flat):
        if i < num_samples:
            img, label = dataset.dataset[dataset.indices[i]] if hasattr(dataset, 'indices') else dataset[i]
            # åå½’ä¸€åŒ–
            img = img * 0.3081 + 0.1307
            ax.imshow(img.squeeze(), cmap='gray')
            ax.set_title(f'æ ‡ç­¾: {label}')
        ax.axis('off')
    plt.suptitle('MNIST æ ·æœ¬ç¤ºä¾‹', fontsize=14)
    plt.tight_layout()
    plt.savefig(os.path.join(config.save_dir, 'samples.png'), dpi=100)
    plt.close()
    print(f"æ ·æœ¬å›¾ç‰‡å·²ä¿å­˜: {config.save_dir}/samples.png")

visualize_samples(train_dataset)

# =============================================================================
# 4. æ¨¡å‹å®šä¹‰
# =============================================================================
print("\n" + "=" * 60)
print("ã€3. æ¨¡å‹å®šä¹‰ã€‘")

class CNN(nn.Module):
    """å·ç§¯ç¥ç»ç½‘ç»œåˆ†ç±»å™¨"""
    def __init__(self, num_classes=10):
        super().__init__()
        
        # å·ç§¯å±‚
        self.conv_layers = nn.Sequential(
            # ç¬¬ä¸€ä¸ªå·ç§¯å—: (1, 28, 28) -> (32, 14, 14)
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
            
            # ç¬¬äºŒä¸ªå·ç§¯å—: (32, 14, 14) -> (64, 7, 7)
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
            
            # ç¬¬ä¸‰ä¸ªå·ç§¯å—: (64, 7, 7) -> (128, 3, 3)
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
        )
        
        # å…¨è¿æ¥å±‚
        self.fc_layers = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 3 * 3, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        x = self.conv_layers(x)
        x = self.fc_layers(x)
        return x

# åˆ›å»ºæ¨¡å‹
model = CNN(num_classes=config.num_classes).to(config.device)
print(f"\næ¨¡å‹ç»“æ„:\n{model}")

# ç»Ÿè®¡å‚æ•°é‡
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"\næ€»å‚æ•°é‡: {total_params:,}")
print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

# =============================================================================
# 5. è®­ç»ƒè®¾ç½®
# =============================================================================
print("\n" + "=" * 60)
print("ã€4. è®­ç»ƒè®¾ç½®ã€‘")

criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=0.01)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.num_epochs)

print(f"æŸå¤±å‡½æ•°: CrossEntropyLoss")
print(f"ä¼˜åŒ–å™¨: AdamW (lr={config.learning_rate})")
print(f"å­¦ä¹ ç‡è°ƒåº¦: CosineAnnealing")

# =============================================================================
# 6. è®­ç»ƒå’ŒéªŒè¯å‡½æ•°
# =============================================================================

def train_epoch(model, loader, criterion, optimizer, device):
    """è®­ç»ƒä¸€ä¸ª epoch"""
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    
    pbar = tqdm(loader, desc='è®­ç»ƒä¸­', leave=False)
    for images, labels in pbar:
        images, labels = images.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        
        total_loss += loss.item() * images.size(0)
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
        
        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{correct/total:.4f}'})
    
    return total_loss / total, correct / total


@torch.no_grad()
def evaluate(model, loader, criterion, device):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    
    for images, labels in loader:
        images, labels = images.to(device), labels.to(device)
        
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        total_loss += loss.item() * images.size(0)
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
    
    return total_loss / total, correct / total

# =============================================================================
# 7. è®­ç»ƒå¾ªç¯
# =============================================================================
print("\n" + "=" * 60)
print("ã€5. å¼€å§‹è®­ç»ƒã€‘")

history = {
    'train_loss': [], 'train_acc': [],
    'val_loss': [], 'val_acc': [],
    'lr': []
}

best_val_acc = 0
best_model_state = None
start_time = time.time()

for epoch in range(config.num_epochs):
    print(f"\nEpoch {epoch+1}/{config.num_epochs}")
    
    # è®­ç»ƒ
    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, config.device)
    
    # éªŒè¯
    val_loss, val_acc = evaluate(model, val_loader, criterion, config.device)
    
    # æ›´æ–°å­¦ä¹ ç‡
    scheduler.step()
    current_lr = optimizer.param_groups[0]['lr']
    
    # è®°å½•å†å²
    history['train_loss'].append(train_loss)
    history['train_acc'].append(train_acc)
    history['val_loss'].append(val_loss)
    history['val_acc'].append(val_acc)
    history['lr'].append(current_lr)
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        best_model_state = model.state_dict().copy()
        print(f"  âœ“ æ–°çš„æœ€ä½³æ¨¡å‹ï¼")
    
    print(f"  è®­ç»ƒ - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}")
    print(f"  éªŒè¯ - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}")
    print(f"  å­¦ä¹ ç‡: {current_lr:.6f}")

elapsed_time = time.time() - start_time
print(f"\nè®­ç»ƒå®Œæˆ! ç”¨æ—¶: {elapsed_time:.2f}s")
print(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")

# =============================================================================
# 8. ä¿å­˜æ¨¡å‹
# =============================================================================
print("\n" + "=" * 60)
print("ã€6. ä¿å­˜æ¨¡å‹ã€‘")

# ä¿å­˜æœ€ä½³æ¨¡å‹
model_path = os.path.join(config.save_dir, 'mnist_cnn_best.pth')
torch.save(best_model_state, model_path)
print(f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {model_path}")

# ä¿å­˜å®Œæ•´ checkpoint
checkpoint_path = os.path.join(config.save_dir, 'mnist_checkpoint.pth')
torch.save({
    'epoch': config.num_epochs,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'scheduler_state_dict': scheduler.state_dict(),
    'best_val_acc': best_val_acc,
    'history': history,
}, checkpoint_path)
print(f"Checkpoint å·²ä¿å­˜: {checkpoint_path}")

# =============================================================================
# 9. æµ‹è¯•è¯„ä¼°
# =============================================================================
print("\n" + "=" * 60)
print("ã€7. æµ‹è¯•è¯„ä¼°ã€‘")

# åŠ è½½æœ€ä½³æ¨¡å‹
model.load_state_dict(best_model_state)

# æµ‹è¯•
test_loss, test_acc = evaluate(model, test_loader, criterion, config.device)
print(f"æµ‹è¯•é›† Loss: {test_loss:.4f}")
print(f"æµ‹è¯•é›† Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)")

# =============================================================================
# 10. æ··æ·†çŸ©é˜µå’Œåˆ†ç±»æŠ¥å‘Š
# =============================================================================
print("\n" + "=" * 60)
print("ã€8. è¯¦ç»†è¯„ä¼°ã€‘")

@torch.no_grad()
def get_predictions(model, loader, device):
    """è·å–æ‰€æœ‰é¢„æµ‹ç»“æœ"""
    model.eval()
    all_preds = []
    all_labels = []
    all_probs = []
    
    for images, labels in loader:
        images = images.to(device)
        outputs = model(images)
        probs = torch.softmax(outputs, dim=1)
        _, preds = outputs.max(1)
        
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.numpy())
        all_probs.extend(probs.cpu().numpy())
    
    return np.array(all_preds), np.array(all_labels), np.array(all_probs)

preds, labels, probs = get_predictions(model, test_loader, config.device)

# æ··æ·†çŸ©é˜µ
from collections import Counter

def plot_confusion_matrix(preds, labels, num_classes):
    """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
    cm = np.zeros((num_classes, num_classes), dtype=int)
    for p, l in zip(preds, labels):
        cm[l, p] += 1
    
    fig, ax = plt.subplots(figsize=(10, 8))
    im = ax.imshow(cm, cmap='Blues')
    
    # æ ‡ç­¾
    ax.set_xticks(np.arange(num_classes))
    ax.set_yticks(np.arange(num_classes))
    ax.set_xlabel('é¢„æµ‹æ ‡ç­¾')
    ax.set_ylabel('çœŸå®æ ‡ç­¾')
    ax.set_title('æ··æ·†çŸ©é˜µ')
    
    # æ·»åŠ æ•°å€¼
    for i in range(num_classes):
        for j in range(num_classes):
            color = 'white' if cm[i, j] > cm.max() / 2 else 'black'
            ax.text(j, i, cm[i, j], ha='center', va='center', color=color)
    
    plt.colorbar(im)
    plt.tight_layout()
    plt.savefig(os.path.join(config.save_dir, 'confusion_matrix.png'), dpi=100)
    plt.close()
    print(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜: {config.save_dir}/confusion_matrix.png")

plot_confusion_matrix(preds, labels, config.num_classes)

# æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
print("\næ¯ä¸ªæ•°å­—çš„åˆ†ç±»å‡†ç¡®ç‡:")
for i in range(config.num_classes):
    mask = labels == i
    acc = (preds[mask] == labels[mask]).mean()
    print(f"  æ•°å­— {i}: {acc:.4f} ({acc*100:.2f}%)")

# =============================================================================
# 11. è®­ç»ƒæ›²çº¿
# =============================================================================
print("\n" + "=" * 60)
print("ã€9. è®­ç»ƒæ›²çº¿ã€‘")

def plot_training_curves(history):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    fig, axes = plt.subplots(1, 3, figsize=(15, 4))
    
    # Loss
    axes[0].plot(history['train_loss'], label='è®­ç»ƒ')
    axes[0].plot(history['val_loss'], label='éªŒè¯')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].set_title('æŸå¤±æ›²çº¿')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # Accuracy
    axes[1].plot(history['train_acc'], label='è®­ç»ƒ')
    axes[1].plot(history['val_acc'], label='éªŒè¯')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Accuracy')
    axes[1].set_title('å‡†ç¡®ç‡æ›²çº¿')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    # Learning Rate
    axes[2].plot(history['lr'])
    axes[2].set_xlabel('Epoch')
    axes[2].set_ylabel('Learning Rate')
    axes[2].set_title('å­¦ä¹ ç‡å˜åŒ–')
    axes[2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(os.path.join(config.save_dir, 'training_curves.png'), dpi=100)
    plt.close()
    print(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {config.save_dir}/training_curves.png")

plot_training_curves(history)

# =============================================================================
# 12. å¯è§†åŒ–é¢„æµ‹ç»“æœ
# =============================================================================
print("\n" + "=" * 60)
print("ã€10. é¢„æµ‹å¯è§†åŒ–ã€‘")

def visualize_predictions(model, dataset, device, num_samples=16):
    """å¯è§†åŒ–é¢„æµ‹ç»“æœ"""
    model.eval()
    fig, axes = plt.subplots(4, 4, figsize=(10, 10))
    
    indices = np.random.choice(len(dataset), num_samples, replace=False)
    
    for i, (ax, idx) in enumerate(zip(axes.flat, indices)):
        img, label = dataset[idx]
        
        # é¢„æµ‹
        with torch.no_grad():
            output = model(img.unsqueeze(0).to(device))
            prob = torch.softmax(output, dim=1)
            pred = output.argmax(1).item()
            confidence = prob[0, pred].item()
        
        # æ˜¾ç¤ºå›¾ç‰‡
        img_show = img * 0.3081 + 0.1307
        ax.imshow(img_show.squeeze(), cmap='gray')
        
        # æ ‡é¢˜ (æ­£ç¡®ä¸ºç»¿è‰²ï¼Œé”™è¯¯ä¸ºçº¢è‰²)
        color = 'green' if pred == label else 'red'
        ax.set_title(f'é¢„æµ‹: {pred} ({confidence:.2%})\nçœŸå®: {label}', 
                     color=color, fontsize=10)
        ax.axis('off')
    
    plt.suptitle('æ¨¡å‹é¢„æµ‹ç»“æœ', fontsize=14)
    plt.tight_layout()
    plt.savefig(os.path.join(config.save_dir, 'predictions.png'), dpi=100)
    plt.close()
    print(f"é¢„æµ‹ç»“æœå·²ä¿å­˜: {config.save_dir}/predictions.png")

visualize_predictions(model, test_dataset, config.device)

# =============================================================================
# 13. é”™è¯¯åˆ†æ
# =============================================================================
print("\n" + "=" * 60)
print("ã€11. é”™è¯¯åˆ†æã€‘")

def analyze_errors(model, dataset, device, num_samples=16):
    """åˆ†æé”™è¯¯é¢„æµ‹"""
    model.eval()
    errors = []
    
    for idx in range(len(dataset)):
        img, label = dataset[idx]
        with torch.no_grad():
            output = model(img.unsqueeze(0).to(device))
            pred = output.argmax(1).item()
        
        if pred != label:
            prob = torch.softmax(output, dim=1)
            errors.append({
                'idx': idx,
                'true': label,
                'pred': pred,
                'confidence': prob[0, pred].item()
            })
    
    print(f"æ€»é”™è¯¯æ•°: {len(errors)} / {len(dataset)} ({len(errors)/len(dataset)*100:.2f}%)")
    
    # æœ€å®¹æ˜“æ··æ·†çš„æ•°å­—å¯¹
    confusion_pairs = Counter()
    for e in errors:
        pair = (e['true'], e['pred'])
        confusion_pairs[pair] += 1
    
    print("\næœ€å®¹æ˜“æ··æ·†çš„æ•°å­—å¯¹:")
    for (true, pred), count in confusion_pairs.most_common(5):
        print(f"  {true} -> {pred}: {count}æ¬¡")
    
    # å¯è§†åŒ–ä¸€äº›é”™è¯¯æ ·æœ¬
    if errors:
        fig, axes = plt.subplots(2, 4, figsize=(12, 6))
        for i, ax in enumerate(axes.flat):
            if i < len(errors):
                e = errors[i]
                img, _ = dataset[e['idx']]
                img_show = img * 0.3081 + 0.1307
                ax.imshow(img_show.squeeze(), cmap='gray')
                ax.set_title(f"çœŸå®: {e['true']}, é¢„æµ‹: {e['pred']}\nç½®ä¿¡åº¦: {e['confidence']:.2%}", 
                            color='red', fontsize=9)
            ax.axis('off')
        plt.suptitle('é”™è¯¯é¢„æµ‹æ ·æœ¬', fontsize=14)
        plt.tight_layout()
        plt.savefig(os.path.join(config.save_dir, 'error_samples.png'), dpi=100)
        plt.close()
        print(f"é”™è¯¯æ ·æœ¬å·²ä¿å­˜: {config.save_dir}/error_samples.png")

analyze_errors(model, test_dataset, config.device)

# =============================================================================
# 14. æ€»ç»“
# =============================================================================
print("\n" + "=" * 60)
print("ã€é¡¹ç›®æ€»ç»“ã€‘")
print("=" * 60)

print(f"""
ğŸ“Š è®­ç»ƒç»“æœ:
   - è®­ç»ƒé›†å‡†ç¡®ç‡: {history['train_acc'][-1]:.4f} ({history['train_acc'][-1]*100:.2f}%)
   - éªŒè¯é›†å‡†ç¡®ç‡: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)
   - æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.4f} ({test_acc*100:.2f}%)

ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:
   - {config.save_dir}/samples.png           (æ•°æ®æ ·æœ¬)
   - {config.save_dir}/training_curves.png   (è®­ç»ƒæ›²çº¿)
   - {config.save_dir}/confusion_matrix.png  (æ··æ·†çŸ©é˜µ)
   - {config.save_dir}/predictions.png       (é¢„æµ‹ç»“æœ)
   - {config.save_dir}/error_samples.png     (é”™è¯¯åˆ†æ)
   - {config.save_dir}/mnist_cnn_best.pth    (æœ€ä½³æ¨¡å‹)
   - {config.save_dir}/mnist_checkpoint.pth  (å®Œæ•´æ£€æŸ¥ç‚¹)

âœ… Phase 3 å®æˆ˜é¡¹ç›®å®Œæˆï¼
""")
