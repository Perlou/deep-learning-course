"""
æ¨ç†è„šæœ¬
========

å¯¹æ–°å›¾åƒè¿›è¡Œåˆ†å‰²æ¨ç†ã€‚
"""

import argparse
from pathlib import Path

import numpy as np
from PIL import Image
import torch
import torchvision.transforms.functional as TF
import matplotlib.pyplot as plt

from config import DEVICE, MODELS_DIR, RESULTS_DIR, MODEL_CONFIG, DATASET_CONFIG
from model import create_model
from utils import postprocess_mask, normalize_image


def load_model(model_path=None, device=None):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    device = device or DEVICE

    if model_path is None:
        model_path = MODELS_DIR / "best_model.pth"
    model_path = Path(model_path)

    if not model_path.exists():
        print(f"âš  æ¨¡å‹ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹: python train.py")
        return None

    # åˆ›å»ºæ¨¡å‹
    model = create_model(
        model_name=MODEL_CONFIG["name"],
        n_channels=MODEL_CONFIG["in_channels"],
        n_classes=MODEL_CONFIG["out_channels"],
        bilinear=MODEL_CONFIG["bilinear"],
        features=MODEL_CONFIG["features"],
    )

    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, weights_only=False, map_location=device)
    model.load_state_dict(checkpoint["model_state_dict"])
    model = model.to(device)
    model.eval()

    print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path.name}")

    return model


def preprocess_image(image_path, image_size=(256, 256)):
    """
    é¢„å¤„ç†è¾“å…¥å›¾åƒ

    Args:
        image_path: å›¾åƒè·¯å¾„
        image_size: ç›®æ ‡å¤§å°

    Returns:
        tensor: é¢„å¤„ç†åçš„å›¾åƒå¼ é‡ [1, 1, H, W]
        original: åŸå§‹å›¾åƒ (ç”¨äºå¯è§†åŒ–)
    """
    # åŠ è½½å›¾åƒ
    image = Image.open(image_path).convert("L")
    original_size = image.size

    # è°ƒæ•´å¤§å°
    image_resized = image.resize(image_size, Image.Resampling.BILINEAR)

    # è½¬æ¢ä¸º tensor
    tensor = TF.to_tensor(image_resized).unsqueeze(0)

    return tensor, np.array(image), original_size


@torch.no_grad()
def predict(
    image_path,
    model=None,
    model_path=None,
    device=None,
    threshold=0.5,
    postprocess=True,
):
    """
    å¯¹å•å¼ å›¾åƒè¿›è¡Œåˆ†å‰²é¢„æµ‹

    Args:
        image_path: è¾“å…¥å›¾åƒè·¯å¾„
        model: å·²åŠ è½½çš„æ¨¡å‹ (å¯é€‰)
        model_path: æ¨¡å‹æƒé‡è·¯å¾„ (å¯é€‰)
        device: è®¾å¤‡
        threshold: äºŒå€¼åŒ–é˜ˆå€¼
        postprocess: æ˜¯å¦åº”ç”¨åå¤„ç†

    Returns:
        mask: é¢„æµ‹æ©ç  (numpy array)
        prob: æ¦‚ç‡å›¾ (numpy array)
    """
    device = device or DEVICE

    # åŠ è½½æ¨¡å‹
    if model is None:
        model = load_model(model_path, device)
        if model is None:
            return None, None

    # é¢„å¤„ç†å›¾åƒ
    tensor, original, original_size = preprocess_image(
        image_path, image_size=DATASET_CONFIG["image_size"]
    )
    tensor = tensor.to(device)

    # é¢„æµ‹
    output = model(tensor)
    prob = torch.sigmoid(output).squeeze().cpu().numpy()

    # äºŒå€¼åŒ–
    mask = (prob > threshold).astype(np.uint8)

    # åå¤„ç†
    if postprocess:
        mask = postprocess_mask(mask)

    # è°ƒæ•´å›åŸå§‹å¤§å°
    mask_pil = Image.fromarray(mask * 255)
    mask_pil = mask_pil.resize(original_size, Image.Resampling.NEAREST)
    mask = np.array(mask_pil) // 255

    prob_pil = Image.fromarray((prob * 255).astype(np.uint8))
    prob_pil = prob_pil.resize(original_size, Image.Resampling.BILINEAR)
    prob = np.array(prob_pil) / 255.0

    return mask, prob


def predict_and_visualize(
    image_path,
    output_path=None,
    model=None,
    model_path=None,
    show=False,
):
    """
    é¢„æµ‹å¹¶å¯è§†åŒ–ç»“æœ

    Args:
        image_path: è¾“å…¥å›¾åƒè·¯å¾„
        output_path: è¾“å‡ºä¿å­˜è·¯å¾„
        model: å·²åŠ è½½çš„æ¨¡å‹
        model_path: æ¨¡å‹æƒé‡è·¯å¾„
        show: æ˜¯å¦æ˜¾ç¤ºå›¾åƒ

    Returns:
        mask: é¢„æµ‹æ©ç 
    """
    image_path = Path(image_path)

    if not image_path.exists():
        print(f"âš  å›¾åƒä¸å­˜åœ¨: {image_path}")
        return None

    print(f"\nğŸ” å¤„ç†å›¾åƒ: {image_path.name}")

    # åŠ è½½åŸå›¾
    original = np.array(Image.open(image_path).convert("L"))

    # é¢„æµ‹
    mask, prob = predict(image_path, model=model, model_path=model_path)

    if mask is None:
        return None

    # å¯è§†åŒ–
    fig, axes = plt.subplots(1, 4, figsize=(16, 4))

    # åŸå›¾
    axes[0].imshow(original, cmap="gray")
    axes[0].set_title("Original Image")
    axes[0].axis("off")

    # æ¦‚ç‡å›¾
    axes[1].imshow(prob, cmap="jet")
    axes[1].set_title("Probability Map")
    axes[1].axis("off")

    # åˆ†å‰²æ©ç 
    axes[2].imshow(mask, cmap="gray")
    axes[2].set_title("Segmentation Mask")
    axes[2].axis("off")

    # å åŠ å›¾
    axes[3].imshow(original, cmap="gray")
    axes[3].imshow(mask, cmap="Reds", alpha=0.5)
    axes[3].set_title("Overlay")
    axes[3].axis("off")

    plt.tight_layout()

    # ä¿å­˜
    if output_path is None:
        output_path = RESULTS_DIR / f"{image_path.stem}_segmented.png"

    plt.savefig(output_path, dpi=150, bbox_inches="tight")
    print(f"âœ“ ç»“æœä¿å­˜äº: {output_path}")

    if show:
        plt.show()
    else:
        plt.close()

    return mask


def predict_batch(
    input_dir,
    output_dir=None,
    model_path=None,
):
    """
    æ‰¹é‡é¢„æµ‹ç›®å½•ä¸­çš„æ‰€æœ‰å›¾åƒ

    Args:
        input_dir: è¾“å…¥ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        model_path: æ¨¡å‹æƒé‡è·¯å¾„
    """
    input_dir = Path(input_dir)

    if output_dir is None:
        output_dir = RESULTS_DIR / "batch_predictions"
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # æŸ¥æ‰¾æ‰€æœ‰å›¾åƒ
    image_files = list(input_dir.glob("*.png")) + list(input_dir.glob("*.jpg"))

    if len(image_files) == 0:
        print(f"âš  åœ¨ {input_dir} ä¸­æ‰¾ä¸åˆ°å›¾åƒæ–‡ä»¶")
        return

    print(f"\nğŸ“‚ æ‰¹é‡å¤„ç† {len(image_files)} ä¸ªå›¾åƒ...")

    # åŠ è½½æ¨¡å‹
    model = load_model(model_path)
    if model is None:
        return

    for image_path in image_files:
        output_path = output_dir / f"{image_path.stem}_segmented.png"
        predict_and_visualize(
            image_path,
            output_path=output_path,
            model=model,
            show=False,
        )

    print(f"\nâœ“ æ‰¹é‡å¤„ç†å®Œæˆ! ç»“æœä¿å­˜äº: {output_dir}")


def demo_inference():
    """æ¨ç†æ¼”ç¤º"""
    print("=" * 60)
    print("ğŸ¥ åˆ†å‰²æ¨ç†æ¼”ç¤º")
    print("=" * 60)

    # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
    model_path = MODELS_DIR / "best_model.pth"

    if not model_path.exists():
        print("\nâš  æ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·å…ˆè®­ç»ƒ:")
        print("   python main.py train --quick")
        return

    # ä½¿ç”¨éªŒè¯é›†ä¸­çš„å›¾åƒè¿›è¡Œæ¼”ç¤º
    from dataset import download_montgomery_dataset

    data_dir = download_montgomery_dataset()
    image_dir = data_dir / "CXR_png"

    images = list(image_dir.glob("*.png"))
    if len(images) > 0:
        # éšæœºé€‰æ‹©ä¸€å¼ å›¾ç‰‡
        import random

        image_path = random.choice(images)

        predict_and_visualize(
            image_path,
            output_path=RESULTS_DIR / "demo_inference.png",
            model_path=model_path,
            show=False,
        )
    else:
        print("âš  æ‰¾ä¸åˆ°å›¾åƒæ–‡ä»¶")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="åˆ†å‰²æ¨ç†")
    parser.add_argument("--source", type=str, default=None, help="è¾“å…¥å›¾åƒè·¯å¾„æˆ–ç›®å½•")
    parser.add_argument("--model", type=str, default=None, help="æ¨¡å‹æƒé‡è·¯å¾„")
    parser.add_argument("--output", type=str, default=None, help="è¾“å‡ºè·¯å¾„")
    parser.add_argument("--show", action="store_true", help="æ˜¾ç¤ºç»“æœ")
    parser.add_argument("--demo", action="store_true", help="è¿è¡Œæ¼”ç¤º")

    args = parser.parse_args()

    if args.demo:
        demo_inference()
    elif args.source:
        source = Path(args.source)
        if source.is_dir():
            predict_batch(source, args.output, args.model)
        else:
            predict_and_visualize(
                source,
                output_path=args.output,
                model_path=args.model,
                show=args.show,
            )
    else:
        print("ç”¨æ³•:")
        print("  python inference.py --demo")
        print("  python inference.py --source image.png")
        print("  python inference.py --source image_dir/")
