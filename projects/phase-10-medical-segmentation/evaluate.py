"""
è¯„ä¼°è„šæœ¬
========

è¯„ä¼°åˆ†å‰²æ¨¡å‹çš„æ€§èƒ½ã€‚
"""

import argparse
from pathlib import Path

import torch
import numpy as np
from tqdm import tqdm

from config import DEVICE, MODELS_DIR, RESULTS_DIR, MODEL_CONFIG, DATASET_CONFIG
from model import create_model
from dataset import get_dataloaders
from utils import (
    dice_coefficient,
    iou_score,
    load_checkpoint,
    visualize_batch,
    postprocess_mask,
)


@torch.no_grad()
def evaluate(
    model_path=None,
    data_dir=None,
    device=None,
    save_visualization=True,
):
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½

    Args:
        model_path: æ¨¡å‹æƒé‡è·¯å¾„
        data_dir: æ•°æ®ç›®å½•
        device: è®¾å¤‡
        save_visualization: æ˜¯å¦ä¿å­˜å¯è§†åŒ–ç»“æœ

    Returns:
        è¯„ä¼°æŒ‡æ ‡å­—å…¸
    """
    device = device or DEVICE

    if model_path is None:
        model_path = MODELS_DIR / "best_model.pth"
    model_path = Path(model_path)

    if not model_path.exists():
        print(f"âš  æ¨¡å‹ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹: python train.py")
        return None

    print("=" * 60)
    print("ğŸ“Š æ¨¡å‹è¯„ä¼°")
    print("=" * 60)
    print(f"æ¨¡å‹: {model_path}")
    print(f"è®¾å¤‡: {device}")
    print("=" * 60)

    # åŠ è½½æ•°æ®
    print("\nğŸ“Š åŠ è½½æ•°æ®...")
    _, val_loader = get_dataloaders(
        data_dir=data_dir,
        image_size=DATASET_CONFIG["image_size"],
        batch_size=8,
        num_workers=4,
        augmentation=False,
    )

    # åŠ è½½æ¨¡å‹
    print("\nğŸ”§ åŠ è½½æ¨¡å‹...")
    model = create_model(
        model_name=MODEL_CONFIG["name"],
        n_channels=MODEL_CONFIG["in_channels"],
        n_classes=MODEL_CONFIG["out_channels"],
        bilinear=MODEL_CONFIG["bilinear"],
        features=MODEL_CONFIG["features"],
    )

    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, weights_only=False, map_location=device)
    model.load_state_dict(checkpoint["model_state_dict"])
    model = model.to(device)
    model.eval()

    print(f"åŠ è½½ epoch {checkpoint.get('epoch', 'N/A')} çš„æƒé‡")

    # è¯„ä¼°æŒ‡æ ‡
    all_dice = []
    all_iou = []
    all_precision = []
    all_recall = []

    sample_images = []
    sample_masks_true = []
    sample_masks_pred = []

    print("\nğŸ” è¯„ä¼°ä¸­...")
    for batch_idx, (images, masks) in enumerate(tqdm(val_loader)):
        images = images.to(device)
        masks = masks.to(device)

        # é¢„æµ‹
        outputs = model(images)
        preds = torch.sigmoid(outputs)
        preds_binary = (preds > 0.5).float()

        # é€æ ·æœ¬è®¡ç®—æŒ‡æ ‡
        for i in range(images.size(0)):
            pred = preds_binary[i]
            target = masks[i]

            # Dice
            dice = dice_coefficient(pred, target)
            all_dice.append(dice.item())

            # IoU
            iou = iou_score(pred, target)
            all_iou.append(iou.item())

            # Precision & Recall
            pred_flat = pred.view(-1)
            target_flat = target.view(-1)

            tp = (pred_flat * target_flat).sum()
            fp = (pred_flat * (1 - target_flat)).sum()
            fn = ((1 - pred_flat) * target_flat).sum()

            precision = (tp / (tp + fp + 1e-7)).item()
            recall = (tp / (tp + fn + 1e-7)).item()

            all_precision.append(precision)
            all_recall.append(recall)

        # ä¿å­˜ä¸€äº›æ ·æœ¬ç”¨äºå¯è§†åŒ–
        if batch_idx == 0:
            sample_images = images.cpu()
            sample_masks_true = masks.cpu()
            sample_masks_pred = preds_binary.cpu()

    # è®¡ç®—å¹³å‡æŒ‡æ ‡
    metrics = {
        "dice": np.mean(all_dice),
        "dice_std": np.std(all_dice),
        "iou": np.mean(all_iou),
        "iou_std": np.std(all_iou),
        "precision": np.mean(all_precision),
        "recall": np.mean(all_recall),
        "f1": 2
        * np.mean(all_precision)
        * np.mean(all_recall)
        / (np.mean(all_precision) + np.mean(all_recall) + 1e-7),
    }

    # æ‰“å°ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“ˆ è¯„ä¼°ç»“æœ")
    print("=" * 60)
    print(f"Dice Coefficient: {metrics['dice']:.4f} Â± {metrics['dice_std']:.4f}")
    print(f"IoU (Jaccard):    {metrics['iou']:.4f} Â± {metrics['iou_std']:.4f}")
    print(f"Precision:        {metrics['precision']:.4f}")
    print(f"Recall:           {metrics['recall']:.4f}")
    print(f"F1 Score:         {metrics['f1']:.4f}")
    print("=" * 60)

    # ä¿å­˜å¯è§†åŒ–
    if save_visualization and len(sample_images) > 0:
        save_path = RESULTS_DIR / "evaluation_samples.png"
        visualize_batch(
            sample_images,
            sample_masks_true,
            sample_masks_pred,
            save_path=save_path,
            max_samples=4,
        )
        print(f"\nğŸ“¸ å¯è§†åŒ–ç»“æœä¿å­˜äº: {save_path}")

    return metrics


def evaluate_with_postprocess(model_path=None, data_dir=None, device=None):
    """è¯„ä¼°å¸¦åå¤„ç†çš„ç»“æœ"""
    device = device or DEVICE

    if model_path is None:
        model_path = MODELS_DIR / "best_model.pth"
    model_path = Path(model_path)

    if not model_path.exists():
        print(f"âš  æ¨¡å‹ä¸å­˜åœ¨: {model_path}")
        return None

    print("\nğŸ” è¯„ä¼° (å¸¦åå¤„ç†)...")

    # åŠ è½½æ•°æ®å’Œæ¨¡å‹
    _, val_loader = get_dataloaders(
        data_dir=data_dir,
        image_size=DATASET_CONFIG["image_size"],
        batch_size=8,
        num_workers=4,
        augmentation=False,
    )

    model = create_model(
        model_name=MODEL_CONFIG["name"],
        n_channels=MODEL_CONFIG["in_channels"],
        n_classes=MODEL_CONFIG["out_channels"],
    )

    checkpoint = torch.load(model_path, weights_only=False, map_location=device)
    model.load_state_dict(checkpoint["model_state_dict"])
    model = model.to(device)
    model.eval()

    all_dice = []
    all_dice_post = []

    with torch.no_grad():
        for images, masks in tqdm(val_loader):
            images = images.to(device)
            masks = masks.to(device)

            outputs = model(images)
            preds = torch.sigmoid(outputs)

            for i in range(images.size(0)):
                pred = preds[i].squeeze().cpu().numpy()
                target = masks[i].squeeze().cpu().numpy()

                # æ— åå¤„ç†
                pred_binary = (pred > 0.5).astype(np.float32)
                dice = dice_coefficient(
                    torch.from_numpy(pred_binary), torch.from_numpy(target)
                )
                all_dice.append(dice.item())

                # æœ‰åå¤„ç†
                pred_post = postprocess_mask(pred).astype(np.float32)
                dice_post = dice_coefficient(
                    torch.from_numpy(pred_post), torch.from_numpy(target)
                )
                all_dice_post.append(dice_post.item())

    print("\n" + "=" * 60)
    print("ğŸ“ˆ åå¤„ç†å¯¹æ¯”")
    print("=" * 60)
    print(f"æ— åå¤„ç† Dice: {np.mean(all_dice):.4f}")
    print(f"æœ‰åå¤„ç† Dice: {np.mean(all_dice_post):.4f}")
    print(f"æå‡: {(np.mean(all_dice_post) - np.mean(all_dice)) * 100:.2f}%")
    print("=" * 60)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è¯„ä¼°åˆ†å‰²æ¨¡å‹")
    parser.add_argument("--model", type=str, default=None, help="æ¨¡å‹æƒé‡è·¯å¾„")
    parser.add_argument("--data", type=str, default=None, help="æ•°æ®ç›®å½•")
    parser.add_argument("--postprocess", action="store_true", help="è¯„ä¼°åå¤„ç†æ•ˆæœ")

    args = parser.parse_args()

    if args.postprocess:
        evaluate_with_postprocess(model_path=args.model, data_dir=args.data)
    else:
        evaluate(model_path=args.model, data_dir=args.data)
