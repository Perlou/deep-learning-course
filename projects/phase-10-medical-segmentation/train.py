"""
è®­ç»ƒè„šæœ¬
========

è®­ç»ƒ U-Net è¿›è¡Œè‚ºéƒ¨åˆ†å‰²ã€‚
"""

import sys
import argparse
from pathlib import Path

import torch
import torch.nn as nn
from torch.optim import Adam
from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, StepLR
from tqdm import tqdm

from config import (
    DEVICE,
    MODELS_DIR,
    RESULTS_DIR,
    LOGS_DIR,
    MODEL_CONFIG,
    TRAIN_CONFIG,
    DATASET_CONFIG,
)
from model import create_model, CombinedLoss, count_parameters
from dataset import get_dataloaders
from utils import (
    save_checkpoint,
    dice_coefficient,
    iou_score,
    plot_training_history,
    visualize_batch,
)


def train_one_epoch(model, train_loader, criterion, optimizer, device):
    """è®­ç»ƒä¸€ä¸ª epoch"""
    model.train()
    total_loss = 0
    total_dice = 0

    pbar = tqdm(train_loader, desc="Training", leave=False)
    for images, masks in pbar:
        images = images.to(device)
        masks = masks.to(device)

        # å‰å‘ä¼ æ’­
        outputs = model(images)
        loss = criterion(outputs, masks)

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # è®¡ç®—æŒ‡æ ‡
        with torch.no_grad():
            preds = torch.sigmoid(outputs)
            dice = dice_coefficient(preds, masks)

        total_loss += loss.item()
        total_dice += dice.item()

        pbar.set_postfix({"loss": f"{loss.item():.4f}", "dice": f"{dice.item():.4f}"})

    avg_loss = total_loss / len(train_loader)
    avg_dice = total_dice / len(train_loader)

    return avg_loss, avg_dice


@torch.no_grad()
def validate(model, val_loader, criterion, device):
    """éªŒè¯"""
    model.eval()
    total_loss = 0
    total_dice = 0
    total_iou = 0

    for images, masks in val_loader:
        images = images.to(device)
        masks = masks.to(device)

        outputs = model(images)
        loss = criterion(outputs, masks)

        preds = torch.sigmoid(outputs)
        dice = dice_coefficient(preds, masks)
        iou = iou_score(preds, masks)

        total_loss += loss.item()
        total_dice += dice.item()
        total_iou += iou.item()

    avg_loss = total_loss / len(val_loader)
    avg_dice = total_dice / len(val_loader)
    avg_iou = total_iou / len(val_loader)

    return avg_loss, avg_dice, avg_iou


def train(
    data_dir=None,
    model_name="unet",
    epochs=None,
    batch_size=None,
    learning_rate=None,
    device=None,
    save_dir=None,
):
    """
    å®Œæ•´è®­ç»ƒæµç¨‹

    Args:
        data_dir: æ•°æ®ç›®å½•
        model_name: æ¨¡å‹åç§° ("unet" æˆ– "attention_unet")
        epochs: è®­ç»ƒè½®æ•°
        batch_size: æ‰¹é‡å¤§å°
        learning_rate: å­¦ä¹ ç‡
        device: è®¾å¤‡
        save_dir: æ¨¡å‹ä¿å­˜ç›®å½•
    """
    # ä½¿ç”¨é»˜è®¤é…ç½®
    epochs = epochs or TRAIN_CONFIG["epochs"]
    batch_size = batch_size or TRAIN_CONFIG["batch_size"]
    learning_rate = learning_rate or TRAIN_CONFIG["learning_rate"]
    device = device or DEVICE
    save_dir = Path(save_dir) if save_dir else MODELS_DIR

    print("=" * 60)
    print("ğŸ¥ åŒ»å­¦å›¾åƒåˆ†å‰²è®­ç»ƒ")
    print("=" * 60)
    print(f"æ¨¡å‹: {model_name}")
    print(f"è®¾å¤‡: {device}")
    print(f"è®­ç»ƒè½®æ•°: {epochs}")
    print(f"æ‰¹é‡å¤§å°: {batch_size}")
    print(f"å­¦ä¹ ç‡: {learning_rate}")
    print("=" * 60)

    # æ•°æ®åŠ è½½
    print("\nğŸ“Š åŠ è½½æ•°æ®...")
    train_loader, val_loader = get_dataloaders(
        data_dir=data_dir,
        image_size=DATASET_CONFIG["image_size"],
        batch_size=batch_size,
        num_workers=4,
        augmentation=TRAIN_CONFIG["augmentation"],
    )

    # åˆ›å»ºæ¨¡å‹
    print("\nğŸ”§ åˆ›å»ºæ¨¡å‹...")
    model = create_model(
        model_name=model_name,
        n_channels=MODEL_CONFIG["in_channels"],
        n_classes=MODEL_CONFIG["out_channels"],
        bilinear=MODEL_CONFIG["bilinear"],
        features=MODEL_CONFIG["features"],
    )
    model = model.to(device)
    print(f"å‚æ•°é‡: {count_parameters(model):,}")

    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = CombinedLoss(
        bce_weight=TRAIN_CONFIG["bce_weight"], dice_weight=TRAIN_CONFIG["dice_weight"]
    )

    optimizer = Adam(
        model.parameters(), lr=learning_rate, weight_decay=TRAIN_CONFIG["weight_decay"]
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    if TRAIN_CONFIG["scheduler"] == "cosine":
        scheduler = CosineAnnealingLR(optimizer, T_max=epochs)
    elif TRAIN_CONFIG["scheduler"] == "step":
        scheduler = StepLR(optimizer, step_size=epochs // 3, gamma=0.1)
    else:
        scheduler = ReduceLROnPlateau(optimizer, mode="min", patience=5)

    # è®­ç»ƒå†å²
    history = {
        "train_loss": [],
        "train_dice": [],
        "val_loss": [],
        "val_dice": [],
    }

    # æ—©åœ
    best_dice = 0
    patience = TRAIN_CONFIG["early_stopping_patience"]
    patience_counter = 0

    # è®­ç»ƒå¾ªç¯
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    for epoch in range(epochs):
        print(f"\nEpoch {epoch + 1}/{epochs}")
        print("-" * 40)

        # è®­ç»ƒ
        train_loss, train_dice = train_one_epoch(
            model, train_loader, criterion, optimizer, device
        )

        # éªŒè¯
        val_loss, val_dice, val_iou = validate(model, val_loader, criterion, device)

        # æ›´æ–°å­¦ä¹ ç‡
        if isinstance(scheduler, ReduceLROnPlateau):
            scheduler.step(val_loss)
        else:
            scheduler.step()

        # è®°å½•å†å²
        history["train_loss"].append(train_loss)
        history["train_dice"].append(train_dice)
        history["val_loss"].append(val_loss)
        history["val_dice"].append(val_dice)

        # æ‰“å°ç»“æœ
        current_lr = optimizer.param_groups[0]["lr"]
        print(f"Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}")
        print(
            f"Val   Loss: {val_loss:.4f}, Val   Dice: {val_dice:.4f}, Val IoU: {val_iou:.4f}"
        )
        print(f"Learning Rate: {current_lr:.6f}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_dice > best_dice:
            best_dice = val_dice
            patience_counter = 0

            save_checkpoint(
                model, optimizer, epoch, val_loss, val_dice, save_dir / "best_model.pth"
            )
            print(f"âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (Dice: {best_dice:.4f})")
        else:
            patience_counter += 1

        # æ—©åœ
        if patience_counter >= patience:
            print(f"\nâš  æ—©åœè§¦å‘ (è¿ç»­ {patience} è½®æœªæå‡)")
            break

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    save_checkpoint(
        model, optimizer, epoch, val_loss, val_dice, save_dir / "final_model.pth"
    )

    # ä¿å­˜è®­ç»ƒæ›²çº¿
    plot_training_history(history, RESULTS_DIR / "training_history.png")

    print("\n" + "=" * 60)
    print("âœ“ è®­ç»ƒå®Œæˆ!")
    print(f"æœ€ä½³éªŒè¯ Dice: {best_dice:.4f}")
    print(f"æ¨¡å‹ä¿å­˜äº: {save_dir}")
    print("=" * 60)

    return model, history


def quick_train(data_dir=None, epochs=5, model_name="unet"):
    """å¿«é€Ÿè®­ç»ƒï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
    print("\nâš¡ å¿«é€Ÿè®­ç»ƒæ¨¡å¼")
    return train(
        data_dir=data_dir,
        model_name=model_name,
        epochs=epochs,
        batch_size=4,
    )


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è®­ç»ƒè‚ºéƒ¨åˆ†å‰²æ¨¡å‹")
    parser.add_argument("--data", type=str, default=None, help="æ•°æ®ç›®å½•")
    parser.add_argument(
        "--model",
        type=str,
        default="unet",
        choices=["unet", "attention_unet"],
        help="æ¨¡å‹ç±»å‹",
    )
    parser.add_argument("--epochs", type=int, default=50, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch-size", type=int, default=8, help="æ‰¹é‡å¤§å°")
    parser.add_argument("--lr", type=float, default=1e-4, help="å­¦ä¹ ç‡")
    parser.add_argument("--quick", action="store_true", help="å¿«é€Ÿè®­ç»ƒæ¨¡å¼ (5 è½®)")

    args = parser.parse_args()

    if args.quick:
        quick_train(data_dir=args.data, model_name=args.model)
    else:
        train(
            data_dir=args.data,
            model_name=args.model,
            epochs=args.epochs,
            batch_size=args.batch_size,
            learning_rate=args.lr,
        )
